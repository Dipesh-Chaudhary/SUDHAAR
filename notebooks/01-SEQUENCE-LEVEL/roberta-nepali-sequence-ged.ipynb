{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "97fde6d7",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (4.57.1)\n",
            "Requirement already satisfied: datasets in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (4.4.1)\n",
            "Requirement already satisfied: accelerate in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (1.11.0)\n",
            "Requirement already satisfied: evaluate in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (0.4.6)\n",
            "Requirement already satisfied: scikit-learn in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (1.3.2)\n",
            "Requirement already satisfied: wandb in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (0.22.3)\n",
            "Requirement already satisfied: huggingface_hub in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (0.36.0)\n",
            "Requirement already satisfied: filelock in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from transformers) (2.32.5)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from huggingface_hub) (2025.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from huggingface_hub) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from huggingface_hub) (1.2.0)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from datasets) (22.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from datasets) (0.4.0)\n",
            "Requirement already satisfied: pandas in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: httpx<1.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: xxhash in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.19 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from datasets) (0.70.18)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: anyio in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
            "Requirement already satisfied: certifi in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: idna in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: psutil in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from accelerate) (7.1.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from accelerate) (2.8.0+cu128)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: click>=8.0.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from wandb) (8.3.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from wandb) (4.23.4)\n",
            "Requirement already satisfied: pydantic<3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from wandb) (2.12.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from wandb) (2.43.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pydantic<3->wandb) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pydantic<3->wandb) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: setuptools in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.4.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers datasets accelerate evaluate scikit-learn wandb huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "59b650f6",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import (\n",
        "    AutoTokenizer, \n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    EarlyStoppingCallback,\n",
        "    AutoConfig\n",
        ")\n",
        "from datasets import load_dataset, DatasetDict\n",
        "import evaluate\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from huggingface_hub import login, HfApi\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "291d855d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# hf_token = \"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "c284d6e6",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "login(token=hf_token)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "c7924760",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU available: True\n",
            "GPU device: NVIDIA H100 80GB HBM3\n",
            "GPU memory: 85.0 GB\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset structure: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['sentence', 'label'],\n",
            "        num_rows: 10082804\n",
            "    })\n",
            "    valid: Dataset({\n",
            "        features: ['sentence', 'label'],\n",
            "        num_rows: 771511\n",
            "    })\n",
            "})\n",
            "\n",
            "Sample from train: {'sentence': 'ठेक्कालगायत प्रक्रिया छोट्याएर छ इजलास सञ्चालन गर्न सकिने गरी भवन निर्माण गर्न लागिएको समितिले जनाएको छ।', 'label': 0}\n",
            "\n",
            "Sample from validation: {'sentence': 'यी दुई हातहरू मिल्दा विश्वमै शान्तिको सुमधुर ध्वनि गुञ्जिनेछ ।', 'label': 0}\n"
          ]
        }
      ],
      "source": [
        "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU device: {torch.cuda.get_device_name()}\")\n",
        "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "\n",
        "dataset = load_dataset(\"sumitaryal/nepali_grammatical_error_detection\")\n",
        "print(\"Dataset structure:\", dataset)\n",
        "print(\"\\nSample from train:\", dataset['train'][0])\n",
        "print(\"\\nSample from validation:\", dataset['valid'][0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "bfc07c69",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original config: RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"dtype\": \"float32\",\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.57.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50256\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at IRIIS-RESEARCH/RoBERTa_Nepali_125M and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model architecture: RobertaForSequenceClassification\n",
            "Number of labels: 2\n"
          ]
        }
      ],
      "source": [
        "model_name = \"IRIIS-RESEARCH/RoBERTa_Nepali_125M\"\n",
        "\n",
        "config = AutoConfig.from_pretrained(model_name)\n",
        "print(\"Original config:\", config)\n",
        "\n",
        "config.update({\n",
        "    \"num_labels\": 2,\n",
        "    \"id2label\": {0: \"correct\", 1: \"incorrect\"},\n",
        "    \"label2id\": {\"correct\": 0, \"incorrect\": 1},\n",
        "    \"problem_type\": \"single_label_classification\"\n",
        "})\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    config=config\n",
        ")\n",
        "\n",
        "print(f\"Model architecture: {model.__class__.__name__}\")\n",
        "print(f\"Number of labels: {model.num_labels}\")\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    tokenized = tokenizer(\n",
        "        examples['sentence'],\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=256,  # Optimal for Nepali text based on model card\n",
        "        return_attention_mask=True,\n",
        "        return_tensors=None\n",
        "    )\n",
        "    return tokenized\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "cca5346f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import multiprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "932fea12",
      "metadata": {},
      "outputs": [],
      "source": [
        "num_cpus = min(26, multiprocessing.cpu_count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "997cfd63",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "TOKENIZING DATASET (Parallel Processing)\n",
            "============================================================\n",
            "Train samples: 10,082,804\n",
            "Validation samples: 771,511\n"
          ]
        }
      ],
      "source": [
        "# CTokenizing with maximum parallelization\n",
        "print(\"=\" * 60)\n",
        "print(\"TOKENIZING DATASET (Parallel Processing)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples['sentence'],\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=256,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors=None\n",
        "    )\n",
        "\n",
        "\n",
        "# Tokenize with all CPUs and larger batches\n",
        "tokenized_datasets = DatasetDict({\n",
        "    'train': dataset['train'].map(\n",
        "        tokenize_function, \n",
        "        batched=True, \n",
        "        batch_size=5000,  # Larger batch for faster processing\n",
        "        num_proc=num_cpus,      # Use all CPUs\n",
        "        remove_columns=['sentence'],\n",
        "        desc=\"Tokenizing train\"\n",
        "    ),\n",
        "    'validation': dataset['valid'].map(\n",
        "        tokenize_function, \n",
        "        batched=True, \n",
        "        batch_size=5000,\n",
        "        num_proc=num_cpus,\n",
        "        remove_columns=['sentence'],\n",
        "        desc=\"Tokenizing validation\"\n",
        "    )\n",
        "})\n",
        "\n",
        "# Set format for PyTorch with pin memory for faster GPU transfer\n",
        "tokenized_datasets.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "# print(f\"\\n✅ Tokenization completed in {elapsed:.2f} seconds\")\n",
        "print(f\"Train samples: {len(tokenized_datasets['train']):,}\")\n",
        "print(f\"Validation samples: {len(tokenized_datasets['validation']):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "e0f27bb0",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    \n",
        "    # Overall metrics\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        labels, predictions, average='binary', zero_division=0\n",
        "    )\n",
        "    \n",
        "    # Class-wise metrics\n",
        "    precision_class, recall_class, f1_class, support_class = precision_recall_fscore_support(\n",
        "        labels, predictions, average=None, zero_division=0\n",
        "    )\n",
        "    \n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'precision_correct': precision_class[0],\n",
        "        'recall_correct': recall_class[0],\n",
        "        'f1_correct': f1_class[0],\n",
        "        'precision_incorrect': precision_class[1],\n",
        "        'recall_incorrect': recall_class[1],\n",
        "        'f1_incorrect': f1_class[1],\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "50b981fa",
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "349cabc1",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "17d1a29c",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "hub_model_id = \"DipeshChaudhary/roberta-nepali-sequence-ged\"\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./nepali_grammar_detector\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=512,  \n",
        "    per_device_eval_batch_size=1024,\n",
        "    learning_rate=2e-5,\n",
        "    warmup_steps=1000,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=500,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=1000,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=1000,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True,\n",
        "    dataloader_num_workers=26,\n",
        "    # Hugging Face Hub integration\n",
        "    push_to_hub=True,\n",
        "    hub_model_id=hub_model_id,\n",
        "    hub_token=hf_token,\n",
        "    hub_strategy=\"every_save\",  # Push at every save\n",
        "    \n",
        "    # Optimization\n",
        "    dataloader_pin_memory=True,\n",
        "    fp16=True,  \n",
        "    tf32=True,\n",
        "    gradient_accumulation_steps=2,  # Effective batch size =  512* 2 = 1024\n",
        "    report_to=\"none\",\n",
        "    save_total_limit=3,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "4378944f",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training with Hugging Face Hub integration...\n",
            "Model will be saved to: DipeshChaudhary/roberta-nepali-sequence-ged\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    compute_metrics=compute_metrics,\n",
        "    # callbacks=[\n",
        "    #     EarlyStoppingCallback(early_stopping_patience=6),\n",
        "    # ],\n",
        ")\n",
        "\n",
        "print(\"Starting training with Hugging Face Hub integration...\")\n",
        "print(f\"Model will be saved to: {hub_model_id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "2e081bcc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Running initial evaluation (Step 0) ---\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1508' max='754' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [754/754 16:06]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial Metrics: {'eval_loss': 0.704161524772644, 'eval_model_preparation_time': 0.002, 'eval_accuracy': 0.5061820246244059, 'eval_precision': 0.5250124967127121, 'eval_recall': 0.6443010063931215, 'eval_f1': 0.5785720922618125, 'eval_precision_correct': 0.47187065622942426, 'eval_recall_correct': 0.35283884837776186, 'eval_f1_correct': 0.4037647147198843, 'eval_precision_incorrect': 0.5250124967127121, 'eval_recall_incorrect': 0.6443010063931215, 'eval_f1_incorrect': 0.5785720922618125, 'eval_runtime': 134.1919, 'eval_samples_per_second': 5749.31, 'eval_steps_per_second': 5.619}\n"
          ]
        }
      ],
      "source": [
        "print(\"--- Running initial evaluation (Step 0) ---\")\n",
        "initial_metrics = trainer.evaluate()\n",
        "print(f\"Initial Metrics: {initial_metrics}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "cf4fd4a0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eval_loss                      : 0.704162\n",
            "eval_model_preparation_time    : 0.002000\n",
            "eval_accuracy                  : 0.506182\n",
            "eval_precision                 : 0.525012\n",
            "eval_recall                    : 0.644301\n",
            "eval_f1                        : 0.578572\n",
            "eval_precision_correct         : 0.471871\n",
            "eval_recall_correct            : 0.352839\n",
            "eval_f1_correct                : 0.403765\n",
            "eval_precision_incorrect       : 0.525012\n",
            "eval_recall_incorrect          : 0.644301\n",
            "eval_f1_incorrect              : 0.578572\n",
            "eval_runtime                   : 134.191900\n",
            "eval_samples_per_second        : 5749.310000\n",
            "eval_steps_per_second          : 5.619000\n"
          ]
        }
      ],
      "source": [
        "for key, value in initial_metrics.items():\n",
        "    print(f\"{key:<30} : {value:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "647a5f3d",
      "metadata": {},
      "source": [
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "dc48cfa6",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='19694' max='19694' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [19694/19694 3:59:19, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Model Preparation Time</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision Correct</th>\n",
              "      <th>Recall Correct</th>\n",
              "      <th>F1 Correct</th>\n",
              "      <th>Precision Incorrect</th>\n",
              "      <th>Recall Incorrect</th>\n",
              "      <th>F1 Incorrect</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.273400</td>\n",
              "      <td>0.274769</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.889394</td>\n",
              "      <td>0.895093</td>\n",
              "      <td>0.894621</td>\n",
              "      <td>0.894857</td>\n",
              "      <td>0.883074</td>\n",
              "      <td>0.883591</td>\n",
              "      <td>0.883332</td>\n",
              "      <td>0.895093</td>\n",
              "      <td>0.894621</td>\n",
              "      <td>0.894857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.230200</td>\n",
              "      <td>0.245544</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.902629</td>\n",
              "      <td>0.904888</td>\n",
              "      <td>0.910642</td>\n",
              "      <td>0.907756</td>\n",
              "      <td>0.900087</td>\n",
              "      <td>0.893733</td>\n",
              "      <td>0.896898</td>\n",
              "      <td>0.904888</td>\n",
              "      <td>0.910642</td>\n",
              "      <td>0.907756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.216900</td>\n",
              "      <td>0.246174</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.901567</td>\n",
              "      <td>0.891754</td>\n",
              "      <td>0.925214</td>\n",
              "      <td>0.908176</td>\n",
              "      <td>0.913362</td>\n",
              "      <td>0.875314</td>\n",
              "      <td>0.893933</td>\n",
              "      <td>0.891754</td>\n",
              "      <td>0.925214</td>\n",
              "      <td>0.908176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.210100</td>\n",
              "      <td>0.231506</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.908607</td>\n",
              "      <td>0.904717</td>\n",
              "      <td>0.923554</td>\n",
              "      <td>0.914038</td>\n",
              "      <td>0.913119</td>\n",
              "      <td>0.892012</td>\n",
              "      <td>0.902442</td>\n",
              "      <td>0.904717</td>\n",
              "      <td>0.923554</td>\n",
              "      <td>0.914038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.205200</td>\n",
              "      <td>0.223447</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.912417</td>\n",
              "      <td>0.913064</td>\n",
              "      <td>0.921245</td>\n",
              "      <td>0.917136</td>\n",
              "      <td>0.911686</td>\n",
              "      <td>0.902616</td>\n",
              "      <td>0.907128</td>\n",
              "      <td>0.913064</td>\n",
              "      <td>0.921245</td>\n",
              "      <td>0.917136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.200300</td>\n",
              "      <td>0.224824</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.910003</td>\n",
              "      <td>0.902447</td>\n",
              "      <td>0.929407</td>\n",
              "      <td>0.915729</td>\n",
              "      <td>0.918937</td>\n",
              "      <td>0.888459</td>\n",
              "      <td>0.903441</td>\n",
              "      <td>0.902447</td>\n",
              "      <td>0.929407</td>\n",
              "      <td>0.915729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.198700</td>\n",
              "      <td>0.218661</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.913126</td>\n",
              "      <td>0.907373</td>\n",
              "      <td>0.929794</td>\n",
              "      <td>0.918446</td>\n",
              "      <td>0.919857</td>\n",
              "      <td>0.894622</td>\n",
              "      <td>0.907064</td>\n",
              "      <td>0.907373</td>\n",
              "      <td>0.929794</td>\n",
              "      <td>0.918446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.196500</td>\n",
              "      <td>0.210453</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.918018</td>\n",
              "      <td>0.918852</td>\n",
              "      <td>0.925951</td>\n",
              "      <td>0.922387</td>\n",
              "      <td>0.917077</td>\n",
              "      <td>0.909211</td>\n",
              "      <td>0.913127</td>\n",
              "      <td>0.918852</td>\n",
              "      <td>0.925951</td>\n",
              "      <td>0.922387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.193900</td>\n",
              "      <td>0.212911</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.916568</td>\n",
              "      <td>0.912589</td>\n",
              "      <td>0.930550</td>\n",
              "      <td>0.921482</td>\n",
              "      <td>0.921173</td>\n",
              "      <td>0.901044</td>\n",
              "      <td>0.910997</td>\n",
              "      <td>0.912589</td>\n",
              "      <td>0.930550</td>\n",
              "      <td>0.921482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.189600</td>\n",
              "      <td>0.205506</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.919829</td>\n",
              "      <td>0.920567</td>\n",
              "      <td>0.927663</td>\n",
              "      <td>0.924101</td>\n",
              "      <td>0.918996</td>\n",
              "      <td>0.911131</td>\n",
              "      <td>0.915047</td>\n",
              "      <td>0.920567</td>\n",
              "      <td>0.927663</td>\n",
              "      <td>0.924101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.179600</td>\n",
              "      <td>0.206544</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.918848</td>\n",
              "      <td>0.916880</td>\n",
              "      <td>0.930067</td>\n",
              "      <td>0.923427</td>\n",
              "      <td>0.921099</td>\n",
              "      <td>0.906391</td>\n",
              "      <td>0.913686</td>\n",
              "      <td>0.916880</td>\n",
              "      <td>0.930067</td>\n",
              "      <td>0.923427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.178800</td>\n",
              "      <td>0.205817</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.919182</td>\n",
              "      <td>0.916358</td>\n",
              "      <td>0.931403</td>\n",
              "      <td>0.923819</td>\n",
              "      <td>0.922428</td>\n",
              "      <td>0.905614</td>\n",
              "      <td>0.913944</td>\n",
              "      <td>0.916358</td>\n",
              "      <td>0.931403</td>\n",
              "      <td>0.923819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>0.178700</td>\n",
              "      <td>0.201835</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.921201</td>\n",
              "      <td>0.920374</td>\n",
              "      <td>0.930750</td>\n",
              "      <td>0.925533</td>\n",
              "      <td>0.922142</td>\n",
              "      <td>0.910600</td>\n",
              "      <td>0.916335</td>\n",
              "      <td>0.920374</td>\n",
              "      <td>0.930750</td>\n",
              "      <td>0.925533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>0.177400</td>\n",
              "      <td>0.203836</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.920641</td>\n",
              "      <td>0.917731</td>\n",
              "      <td>0.932780</td>\n",
              "      <td>0.925194</td>\n",
              "      <td>0.923987</td>\n",
              "      <td>0.907165</td>\n",
              "      <td>0.915499</td>\n",
              "      <td>0.917731</td>\n",
              "      <td>0.932780</td>\n",
              "      <td>0.925194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>0.176700</td>\n",
              "      <td>0.194032</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.925051</td>\n",
              "      <td>0.930933</td>\n",
              "      <td>0.926264</td>\n",
              "      <td>0.928592</td>\n",
              "      <td>0.918589</td>\n",
              "      <td>0.923705</td>\n",
              "      <td>0.921140</td>\n",
              "      <td>0.930933</td>\n",
              "      <td>0.926264</td>\n",
              "      <td>0.928592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16000</td>\n",
              "      <td>0.178500</td>\n",
              "      <td>0.194306</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.924513</td>\n",
              "      <td>0.928320</td>\n",
              "      <td>0.928190</td>\n",
              "      <td>0.928255</td>\n",
              "      <td>0.920287</td>\n",
              "      <td>0.920431</td>\n",
              "      <td>0.920359</td>\n",
              "      <td>0.928320</td>\n",
              "      <td>0.928190</td>\n",
              "      <td>0.928255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17000</td>\n",
              "      <td>0.176100</td>\n",
              "      <td>0.195717</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.923707</td>\n",
              "      <td>0.925264</td>\n",
              "      <td>0.930117</td>\n",
              "      <td>0.927684</td>\n",
              "      <td>0.921959</td>\n",
              "      <td>0.916591</td>\n",
              "      <td>0.919267</td>\n",
              "      <td>0.925264</td>\n",
              "      <td>0.930117</td>\n",
              "      <td>0.927684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18000</td>\n",
              "      <td>0.176000</td>\n",
              "      <td>0.195962</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.923971</td>\n",
              "      <td>0.925253</td>\n",
              "      <td>0.930676</td>\n",
              "      <td>0.927957</td>\n",
              "      <td>0.922531</td>\n",
              "      <td>0.916528</td>\n",
              "      <td>0.919519</td>\n",
              "      <td>0.925253</td>\n",
              "      <td>0.930676</td>\n",
              "      <td>0.927957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19000</td>\n",
              "      <td>0.176100</td>\n",
              "      <td>0.197347</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.923147</td>\n",
              "      <td>0.922230</td>\n",
              "      <td>0.932566</td>\n",
              "      <td>0.927369</td>\n",
              "      <td>0.924189</td>\n",
              "      <td>0.912690</td>\n",
              "      <td>0.918404</td>\n",
              "      <td>0.922230</td>\n",
              "      <td>0.932566</td>\n",
              "      <td>0.927369</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_result = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "b0efee85",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Saving final model...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6becb7f05ec94eba90e9c25341f165be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2956f03d11fa446d9dc373a68365c84e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "New Data Upload: |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b89259d2150b41c99fa01512461a6e04",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "acc7ce434d1c4f1482134fc6a2d645e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "New Data Upload: |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Final evaluation results:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='754' max='754' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [754/754 02:13]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FINAL MODEL PERFORMANCE\n",
            "==================================================\n",
            "eval_loss: 0.1940\n",
            "eval_model_preparation_time: 0.0020\n",
            "eval_accuracy: 0.9251\n",
            "eval_precision: 0.9309\n",
            "eval_recall: 0.9263\n",
            "eval_f1: 0.9286\n",
            "eval_precision_correct: 0.9186\n",
            "eval_recall_correct: 0.9237\n",
            "eval_f1_correct: 0.9211\n",
            "eval_precision_incorrect: 0.9309\n",
            "eval_recall_incorrect: 0.9263\n",
            "eval_f1_incorrect: 0.9286\n",
            "eval_runtime: 134.1899\n",
            "eval_samples_per_second: 5749.3950\n",
            "eval_steps_per_second: 5.6190\n",
            "epoch: 2.0000\n",
            "\n",
            "==================================================\n",
            "TRAINING SUMMARY\n",
            "==================================================\n",
            "Training completed in 14361.42 seconds\n",
            "Training samples per second: 1404.15\n",
            "Final train loss: 0.1998\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nSaving final model...\")\n",
        "trainer.save_model()\n",
        "tokenizer.save_pretrained(\"./roberta-nepali-sequence-ged\")\n",
        "\n",
        "trainer.push_to_hub(commit_message=\"Final model training completed\")\n",
        "\n",
        "print(\"\\nFinal evaluation results:\")\n",
        "final_metrics = trainer.evaluate()\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"FINAL MODEL PERFORMANCE\")\n",
        "print(\"=\"*50)\n",
        "for key, value in final_metrics.items():\n",
        "    if isinstance(value, float):\n",
        "        print(f\"{key}: {value:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"TRAINING SUMMARY\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Training completed in {train_result.metrics['train_runtime']:.2f} seconds\")\n",
        "print(f\"Training samples per second: {train_result.metrics['train_samples_per_second']:.2f}\")\n",
        "print(f\"Final train loss: {train_result.metrics['train_loss']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "de69d739",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "MODEL PREDICTIONS ON TEST SENTENCES (FROM TRAINING CORPUS)\n",
            "================================================================================\n",
            "\n",
            "1. Sentence: बाबाले सर्प बारे अरू केही बोल्छ।\n",
            "   Prediction: INCORRECT (confidence: 0.5968)\n",
            "   Probabilities → Correct: 0.4032 | Incorrect: 0.5968\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "2. Sentence: बाबाले सर्प बारे अरू केही बोल्नुभएन।\n",
            "   Prediction: CORRECT (confidence: 0.8601)\n",
            "   Probabilities → Correct: 0.8601 | Incorrect: 0.1399\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "3. Sentence: दुर्गमक्षेत्रका अरू जनताले पनि उनीहरूबाट पात सिक्नुपर्छ।\n",
            "   Prediction: INCORRECT (confidence: 0.9988)\n",
            "   Probabilities → Correct: 0.0012 | Incorrect: 0.9988\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "4. Sentence: दुर्गमक्षेत्रका अरू जनताले पनि उनीहरूबाट पाठ सिक्नुपर्छ।\n",
            "   Prediction: CORRECT (confidence: 0.9392)\n",
            "   Probabilities → Correct: 0.9392 | Incorrect: 0.0608\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "5. Sentence: तर यसका लागि निजी स्कूलहरू मात्रमा दोषी छैनन् ?\n",
            "   Prediction: INCORRECT (confidence: 0.9757)\n",
            "   Probabilities → Correct: 0.0243 | Incorrect: 0.9757\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "6. Sentence: तर यसका लागि निजी स्कूलहरू मात्रमा दोषी छैनन्।\n",
            "   Prediction: INCORRECT (confidence: 0.9328)\n",
            "   Probabilities → Correct: 0.0672 | Incorrect: 0.9328\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "7. Sentence: एकै कोठामा सुत्ने दाजुभाइ पनि बीच कुराकानी हुन छाडेको छ।\n",
            "   Prediction: INCORRECT (confidence: 0.9974)\n",
            "   Probabilities → Correct: 0.0026 | Incorrect: 0.9974\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "8. Sentence: एकै कोठामा सुत्ने दाजुभाइ बीच पनि कुराकानी हुन छाडेको छ।\n",
            "   Prediction: CORRECT (confidence: 0.9481)\n",
            "   Probabilities → Correct: 0.9481 | Incorrect: 0.0519\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "9. Sentence: सूचना क्रान्तिको दुनियाँमा मख्ख परेर ठूलो भ्रान्ति पालिरहेका छौं।\n",
            "   Prediction: INCORRECT (confidence: 0.7917)\n",
            "   Probabilities → Correct: 0.2083 | Incorrect: 0.7917\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "10. Sentence: हामी सूचना क्रान्तिको दुनियाँमा मख्ख परेर ठूलो भ्रान्ति पालिरहेका छौं।\n",
            "   Prediction: CORRECT (confidence: 0.9310)\n",
            "   Probabilities → Correct: 0.9310 | Incorrect: 0.0690\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "11. Sentence: यो टेक्निक पनि भाववादसँग सम्बद्ध।\n",
            "   Prediction: INCORRECT (confidence: 0.8275)\n",
            "   Probabilities → Correct: 0.1725 | Incorrect: 0.8275\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "12. Sentence: यो टेक्निक पनि भाववादसँग सम्बद्ध छ।\n",
            "   Prediction: CORRECT (confidence: 0.6656)\n",
            "   Probabilities → Correct: 0.6656 | Incorrect: 0.3344\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "13. Sentence: खाद्यान्नकै हकमा पनि सकेसम्म खेर गरी खाना नै नबनाए हुने।\n",
            "   Prediction: INCORRECT (confidence: 0.9992)\n",
            "   Probabilities → Correct: 0.0008 | Incorrect: 0.9992\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "14. Sentence: खाद्यान्नकै हकमा पनि सकेसम्म खेर जाने गरी खाना नै नबनाए हुने।\n",
            "   Prediction: CORRECT (confidence: 0.9413)\n",
            "   Probabilities → Correct: 0.9413 | Incorrect: 0.0587\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def predict_grammar(sentences):\n",
        "    \"\"\"\n",
        "    Enhanced prediction function with proper preprocessing\n",
        "    \"\"\"\n",
        "    if isinstance(sentences, str):\n",
        "        sentences = [sentences]\n",
        "    \n",
        "    # Get the device the model is on\n",
        "    device = next(model.parameters()).device\n",
        "    \n",
        "    inputs = tokenizer(\n",
        "        sentences,  # Use as-is since training data is already in garbled format\n",
        "        padding=True, \n",
        "        truncation=True, \n",
        "        max_length=256, \n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    \n",
        "    # Move inputs to the same device as model\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "    \n",
        "    results = []\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        predicted_class = predictions[i].argmax().item()\n",
        "        confidence = predictions[i][predicted_class].item()\n",
        "        label = \"incorrect\" if predicted_class == 1 else \"correct\"\n",
        "        \n",
        "        results.append({\n",
        "            'sentence': sentence,\n",
        "            'prediction': label,\n",
        "            'confidence': confidence,\n",
        "            'correct_prob': predictions[i][0].item(),\n",
        "            'incorrect_prob': predictions[i][1].item()\n",
        "        })\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Test sentences matching the 7 error types from your training corpus\n",
        "test_sentences = [\n",
        "    # 1. Verb Form Error\n",
        "    \"बाबाले सर्प बारे अरू केही बोल्छ।\",  # Incorrect\n",
        "    \"बाबाले सर्प बारे अरू केही बोल्नुभएन।\",  # Correct\n",
        "\n",
        "    # 2. Homophone Error\n",
        "    \"दुर्गमक्षेत्रका अरू जनताले पनि उनीहरूबाट पात सिक्नुपर्छ।\",  # Incorrect\n",
        "    \"दुर्गमक्षेत्रका अरू जनताले पनि उनीहरूबाट पाठ सिक्नुपर्छ।\",  # Correct\n",
        "\n",
        "    # 3. Punctuation Error\n",
        "    \"तर यसका लागि निजी स्कूलहरू मात्रमा दोषी छैनन् ?\",  # Incorrect\n",
        "    \"तर यसका लागि निजी स्कूलहरू मात्रमा दोषी छैनन्।\",  # Correct\n",
        "\n",
        "    # 4. Sentence Structure Error\n",
        "    \"एकै कोठामा सुत्ने दाजुभाइ पनि बीच कुराकानी हुन छाडेको छ।\",  # Incorrect\n",
        "    \"एकै कोठामा सुत्ने दाजुभाइ बीच पनि कुराकानी हुन छाडेको छ।\",  # Correct\n",
        "\n",
        "    # 5. Pronoun Missing Error\n",
        "    \"सूचना क्रान्तिको दुनियाँमा मख्ख परेर ठूलो भ्रान्ति पालिरहेका छौं।\",  # Incorrect\n",
        "    \"हामी सूचना क्रान्तिको दुनियाँमा मख्ख परेर ठूलो भ्रान्ति पालिरहेका छौं।\",  # Correct\n",
        "\n",
        "    # 6. Main Verb Missing\n",
        "    \"यो टेक्निक पनि भाववादसँग सम्बद्ध।\",  # Incorrect\n",
        "    \"यो टेक्निक पनि भाववादसँग सम्बद्ध छ।\",  # Correct\n",
        "\n",
        "    # 7. Auxiliary Verb Missing\n",
        "    \"खाद्यान्नकै हकमा पनि सकेसम्म खेर गरी खाना नै नबनाए हुने।\",  # Incorrect\n",
        "    \"खाद्यान्नकै हकमा पनि सकेसम्म खेर जाने गरी खाना नै नबनाए हुने।\",  # Correct\n",
        "\n",
        "]\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MODEL PREDICTIONS ON TEST SENTENCES (FROM TRAINING CORPUS)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "predictions = predict_grammar(test_sentences)\n",
        "for i, pred in enumerate(predictions, 1):\n",
        "    print(f\"\\n{i}. Sentence: {pred['sentence']}\")\n",
        "    print(f\"   Prediction: {pred['prediction'].upper()} (confidence: {pred['confidence']:.4f})\")\n",
        "    print(f\"   Probabilities → Correct: {pred['correct_prob']:.4f} | Incorrect: {pred['incorrect_prob']:.4f}\")\n",
        "    print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "482228ac",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model card generated successfully!\n",
            "Length: 14730 characters\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def generate_model_card(train_result, final_metrics):\n",
        "    \"\"\"\n",
        "    Generate a model card with proper string handling to avoid formatting issues.\n",
        "    Uses triple-quoted strings and raw strings where needed.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Calculate training hours and cost\n",
        "    train_hours = train_result.metrics['train_runtime'] / 3600\n",
        "    train_cost = train_hours * 2.99\n",
        "    \n",
        "    # Build the model card in sections to avoid complex nesting\n",
        "    model_card = f\"\"\"---\n",
        "language: ne\n",
        "license: apache-2.0\n",
        "tags:\n",
        "- nepali\n",
        "- grammatical-error-detection\n",
        "- text-classification\n",
        "- roberta\n",
        "- sequence-classification\n",
        "- nlp\n",
        "datasets:\n",
        "- sumitaryal/nepali_grammatical_error_detection\n",
        "base_model: IRIIS-RESEARCH/RoBERTa_Nepali_125M\n",
        "metrics:\n",
        "- accuracy\n",
        "- f1\n",
        "- precision\n",
        "- recall\n",
        "pipeline_tag: text-classification\n",
        "widget:\n",
        "- text: \"म विद्यालय जान्छु।\"\n",
        "  example_title: \"Correct Nepali\"\n",
        "- text: \"म विद्यालय जान्छ।\"\n",
        "  example_title: \"Grammatical Error\"\n",
        "---\n",
        "\n",
        "# RoBERTa Nepali Grammatical Error Detection (H100-Optimized)\n",
        "\n",
        "This model is a fine-tuned version of [IRIIS-RESEARCH/RoBERTa_Nepali_125M](https://huggingface.co/IRIIS-RESEARCH/RoBERTa_Nepali_125M) specifically trained for detecting grammatical errors in Nepali text. The model was optimized and trained on NVIDIA H100 GPU with advanced optimization techniques.\n",
        "\n",
        "## Model Description\n",
        "\n",
        "- **Model Type:** Binary Text Classification (Sequence Classification)\n",
        "- **Language:** Nepali (ne)\n",
        "- **Base Model:** IRIIS-RESEARCH/RoBERTa_Nepali_125M (125M parameters)\n",
        "- **License:** Apache 2.0\n",
        "- **Training Infrastructure:** NVIDIA H100 (80GB)\n",
        "- **Training Time:** ~{train_hours:.2f} hours\n",
        "- **Fine-tuning Dataset:** [sumitaryal/nepali_grammatical_error_detection](https://huggingface.co/datasets/sumitaryal/nepali_grammatical_error_detection)\n",
        "\n",
        "## Performance Metrics\n",
        "\n",
        "Evaluated on validation set of 771,511 samples:\n",
        "\n",
        "| Metric | Score |\n",
        "|--------|-------|\n",
        "| Accuracy | {final_metrics['eval_accuracy']:.4f} |\n",
        "| F1 Score | {final_metrics['eval_f1']:.4f} |\n",
        "| Precision | {final_metrics['eval_precision']:.4f} |\n",
        "| Recall | {final_metrics['eval_recall']:.4f} |\n",
        "\n",
        "### Class-wise Performance\n",
        "\n",
        "| Class | Precision | Recall | F1-Score |\n",
        "|-------|-----------|--------|----------|\n",
        "| Correct | {final_metrics['eval_precision_correct']:.4f} | {final_metrics['eval_recall_correct']:.4f} | {final_metrics['eval_f1_correct']:.4f} |\n",
        "| Incorrect | {final_metrics['eval_precision_incorrect']:.4f} | {final_metrics['eval_recall_incorrect']:.4f} | {final_metrics['eval_f1_incorrect']:.4f} |\n",
        "\n",
        "## Training Details\n",
        "\n",
        "### Training Data\n",
        "\n",
        "- **Training Samples:** 10,082,804\n",
        "- **Validation Samples:** 771,511\n",
        "- **Total Dataset Size:** ~10.8M Nepali sentences\n",
        "- **Label Distribution:** Balanced mix of grammatically correct and incorrect sentences\n",
        "\n",
        "### Training Configuration\n",
        "\n",
        "- **GPU:** NVIDIA H100 (80GB VRAM)\n",
        "- **Precision:** BF16 (Brain Floating Point 16-bit)\n",
        "- **Batch Size:** 128 per device\n",
        "- **Gradient Accumulation:** 2 steps (effective batch size: 256)\n",
        "- **Learning Rate:** 2e-5 with 10% warmup\n",
        "- **Optimizer:** AdamW (Fused)\n",
        "- **Weight Decay:** 0.01\n",
        "- **Epochs:** 3\n",
        "- **Max Sequence Length:** 256 tokens\n",
        "- **Parallel Processing:** 26 CPU cores\n",
        "\n",
        "### Optimization Techniques\n",
        "\n",
        "- BF16 mixed precision training\n",
        "- Fused AdamW optimizer for faster updates\n",
        "- Group-by-length batching to minimize padding\n",
        "- Pin memory and prefetching for faster data loading\n",
        "- Multi-process tokenization (26 workers)\n",
        "\n",
        "## Usage\n",
        "\n",
        "### Quick Start\n",
        "\n",
        "```python\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# Load model and tokenizer\n",
        "model_name = \"DipeshChaudhary/roberta-nepali-sequence-ged\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "# Function to check grammar\n",
        "def check_grammar(sentence):\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, max_length=256)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        probs = torch.softmax(outputs.logits, dim=-1)\n",
        "    \n",
        "    pred_class = probs.argmax().item()\n",
        "    confidence = probs[0][pred_class].item()\n",
        "    \n",
        "    return {{\n",
        "        \"label\": \"correct\" if pred_class == 0 else \"incorrect\",\n",
        "        \"confidence\": confidence,\n",
        "        \"probabilities\": {{\n",
        "            \"correct\": probs[0][0].item(),\n",
        "            \"incorrect\": probs[0][1].item()\n",
        "        }}\n",
        "    }}\n",
        "\n",
        "# Example usage\n",
        "result = check_grammar(\"म विद्यालय जान्छु।\")\n",
        "print(result)\n",
        "# Output: {{'label': 'correct', 'confidence': 0.9876, 'probabilities': {{'correct': 0.9876, 'incorrect': 0.0124}}}}\n",
        "\n",
        "result = check_grammar(\"म विद्यालय जान्छ।\")\n",
        "print(result)\n",
        "# Output: {{'label': 'incorrect', 'confidence': 0.9543, 'probabilities': {{'correct': 0.0457, 'incorrect': 0.9543}}}}\n",
        "```\n",
        "\n",
        "### Batch Processing\n",
        "\n",
        "```python\n",
        "def check_grammar_batch(sentences):\n",
        "    inputs = tokenizer(sentences, return_tensors=\"pt\", truncation=True, \n",
        "                      max_length=256, padding=True)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        probs = torch.softmax(outputs.logits, dim=-1)\n",
        "    \n",
        "    results = []\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        pred_class = probs[i].argmax().item()\n",
        "        results.append({{\n",
        "            \"sentence\": sentence,\n",
        "            \"label\": \"correct\" if pred_class == 0 else \"incorrect\",\n",
        "            \"confidence\": probs[i][pred_class].item()\n",
        "        }})\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Process multiple sentences\n",
        "sentences = [\n",
        "    \"तिमी कस्तो छौ?\",\n",
        "    \"नेपाल सुन्दर देश हो।\",\n",
        "    \"उनीहरू काम गर्दछन्।\"\n",
        "]\n",
        "\n",
        "results = check_grammar_batch(sentences)\n",
        "for result in results:\n",
        "    print(f\"{{result['sentence']}} → {{result['label']}} ({{result['confidence']:.4f}})\")\n",
        "```\n",
        "\n",
        "### Using Pipeline API\n",
        "\n",
        "```python\n",
        "from transformers import pipeline\n",
        "\n",
        "# Create classifier pipeline\n",
        "classifier = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=\"DipeshChaudhary/roberta-nepali-sequence-ged-h100\",\n",
        "    device=0  # Use GPU if available\n",
        ")\n",
        "\n",
        "# Check grammar\n",
        "result = classifier(\"म विद्यालय जान्छु।\")\n",
        "print(result)\n",
        "# Output: [{{'label': 'correct', 'score': 0.9876}}]\n",
        "```\n",
        "\n",
        "## Use Cases\n",
        "\n",
        "### 1. Writing Assistant for Nepali\n",
        "\n",
        "```python\n",
        "def writing_assistant(text):\n",
        "    # Check and highlight grammatical errors in Nepali text\n",
        "    sentences = text.split('।')  # Split by Nepali sentence delimiter\n",
        "    sentences = [s.strip() + '।' for s in sentences if s.strip()]\n",
        "    \n",
        "    results = check_grammar_batch(sentences)\n",
        "    \n",
        "    print(\"Grammar Check Results:\")\n",
        "    print(\"=\" * 60)\n",
        "    for i, result in enumerate(results, 1):\n",
        "        status = \"✓\" if result['label'] == 'correct' else \"✗\"\n",
        "        print(f\"{{status}} Sentence {{i}}: {{result['sentence']}}\")\n",
        "        if result['label'] == 'incorrect':\n",
        "            print(f\"  └─ Potential grammar error (confidence: {{result['confidence']:.2%}})\")\n",
        "    \n",
        "    error_count = sum(1 for r in results if r['label'] == 'incorrect')\n",
        "    print(f\"\\\\nSummary: {{error_count}}/{{len(results)}} sentences may contain errors\")\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Example\n",
        "text = \"म विद्यालय जान्छु। तिमी कस्तो छौ? उनीहरू काम गर्दछन्।\"\n",
        "writing_assistant(text)\n",
        "```\n",
        "\n",
        "### 2. Educational Application\n",
        "\n",
        "```python\n",
        "def nepali_grammar_quiz(student_answer, correct_answer):\n",
        "    result = check_grammar(student_answer)\n",
        "    \n",
        "    if result['label'] == 'correct':\n",
        "        print(f\"✓ Excellent! Your sentence is grammatically correct.\")\n",
        "        print(f\"  Confidence: {{result['confidence']:.2%}}\")\n",
        "    else:\n",
        "        print(f\"✗ There might be a grammatical error.\")\n",
        "        print(f\"  Confidence: {{result['confidence']:.2%}}\")\n",
        "        print(f\"  Hint: Compare with correct form: {{correct_answer}}\")\n",
        "    \n",
        "    return result\n",
        "\n",
        "# Example quiz question\n",
        "nepali_grammar_quiz(\n",
        "    student_answer=\"म स्कूल जान्छ।\",\n",
        "    correct_answer=\"म स्कूल जान्छु।\"\n",
        ")\n",
        "```\n",
        "\n",
        "### 3. Content Quality Control\n",
        "\n",
        "```python\n",
        "def validate_nepali_content(content, threshold=0.85):\n",
        "    \\\"\\\"\\\"Validate grammar quality of Nepali content\\\"\\\"\\\"\n",
        "    sentences = content.split('।')\n",
        "    sentences = [s.strip() + '।' for s in sentences if s.strip()]\n",
        "    \n",
        "    results = check_grammar_batch(sentences)\n",
        "    \n",
        "    # Calculate quality score\n",
        "    correct_count = sum(1 for r in results if r['label'] == 'correct')\n",
        "    quality_score = correct_count / len(results)\n",
        "    \n",
        "    return {{\n",
        "        \"passed\": quality_score >= threshold,\n",
        "        \"quality_score\": quality_score,\n",
        "        \"total_sentences\": len(results),\n",
        "        \"correct_sentences\": correct_count,\n",
        "        \"error_sentences\": len(results) - correct_count,\n",
        "        \"details\": results\n",
        "    }}\n",
        "\n",
        "# Example\n",
        "content = \"नेपाल सुन्दर देश हो। यहाँ धेरै हिमाल छन्।\"\n",
        "validation = validate_nepali_content(content)\n",
        "print(f\"Quality Score: {{validation['quality_score']:.2%}}\")\n",
        "print(f\"Status: {{'PASSED' if validation['passed'] else 'NEEDS REVIEW'}}\")\n",
        "```\n",
        "\n",
        "### 4. Real-time Text Editor Integration\n",
        "\n",
        "```python\n",
        "class NepaliGrammarChecker:\n",
        "    def __init__(self, model_name=\"DipeshChaudhary/roberta-nepali-sequence-ged\"):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "        self.model.eval()\n",
        "    \n",
        "    def check_realtime(self, text, return_positions=True):\n",
        "        \\\"\\\"\\\"Check grammar with error positions for highlighting\\\"\\\"\\\"\n",
        "        sentences = text.split('।')\n",
        "        sentences = [s.strip() for s in sentences if s.strip()]\n",
        "        \n",
        "        errors = []\n",
        "        position = 0\n",
        "        \n",
        "        for sentence in sentences:\n",
        "            result = check_grammar(sentence + '।')\n",
        "            \n",
        "            if result['label'] == 'incorrect':\n",
        "                errors.append({{\n",
        "                    \"sentence\": sentence,\n",
        "                    \"start\": position,\n",
        "                    \"end\": position + len(sentence),\n",
        "                    \"confidence\": result['confidence']\n",
        "                }})\n",
        "            \n",
        "            position += len(sentence) + 1  # +1 for '।'\n",
        "        \n",
        "        return errors\n",
        "\n",
        "# Example: Integrate with text editor\n",
        "checker = NepaliGrammarChecker()\n",
        "text = \"म स्कूल जान्छ। तिमी कस्तो छौ?\"\n",
        "errors = checker.check_realtime(text)\n",
        "print(f\"Found {{len(errors)}} potential errors\")\n",
        "```\n",
        "\n",
        "## Model Architecture\n",
        "\n",
        "```\n",
        "RoBERTa Base Architecture\n",
        "├── Embedding Layer (50,256 vocab size)\n",
        "├── 12 Transformer Layers\n",
        "│   ├── Multi-Head Self-Attention (12 heads)\n",
        "│   ├── Feed-Forward Network (3072 hidden)\n",
        "│   └── Layer Normalization\n",
        "└── Classification Head\n",
        "    ├── Dense Layer (768 → 768)\n",
        "    ├── Dropout (0.1)\n",
        "    └── Output Layer (768 → 2)\n",
        "\n",
        "Total Parameters: ~125M\n",
        "```\n",
        "\n",
        "## Intended Use\n",
        "\n",
        "### Primary Applications\n",
        "- **Writing Assistance:** Help writers identify grammatical errors in Nepali text\n",
        "- **Educational Tools:** Assist students learning Nepali grammar\n",
        "- **Content Quality Control:** Validate grammar in published content\n",
        "- **Language Learning Apps:** Provide instant feedback on grammar usage\n",
        "- **Translation Post-Editing:** Verify grammar correctness in translated text\n",
        "\n",
        "### Target Users\n",
        "- Nepali language learners\n",
        "- Content creators and writers\n",
        "- Educators and students\n",
        "- Publishing platforms\n",
        "- NLP researchers working on Nepali language\n",
        "\n",
        "## Limitations and Considerations\n",
        "\n",
        "### Known Limitations\n",
        "\n",
        "1. **Dialectal Variations:** The model is trained primarily on standard Nepali and may not perform optimally on regional dialects\n",
        "2. **Informal Language:** Performance may vary with colloquial or informal Nepali\n",
        "3. **Context Dependency:** Some grammatical errors require broader context beyond single sentences\n",
        "4. **Punctuation Sensitivity:** The model considers punctuation as part of grammar checking\n",
        "5. **Domain Specificity:** May not capture domain-specific grammar rules (legal, medical, etc.)\n",
        "\n",
        "### Important Considerations\n",
        "\n",
        "- **False Positives:** The model may occasionally flag correct sentences as incorrect\n",
        "- **False Negatives:** Some grammatical errors might not be detected\n",
        "- **Not a Grammar Corrector:** This model only detects errors; it does not suggest corrections\n",
        "- **Sentence-Level Only:** Designed for sentence-level classification, not word-level error detection\n",
        "- **Static Training Data:** Based on data available up to the training cutoff date\n",
        "\n",
        "### Best Practices\n",
        "\n",
        "- Use as an assistive tool, not as the sole authority on grammar\n",
        "- Combine with human review for critical content\n",
        "- Consider the confidence scores when making decisions\n",
        "- Test on your specific domain/use case before deployment\n",
        "- Provide user feedback mechanisms to improve over time\n",
        "\n",
        "## Technical Specifications\n",
        "\n",
        "### Input/Output Format\n",
        "\n",
        "- **Input:** Single Nepali sentence (max 256 tokens)\n",
        "- **Output:** Binary classification (correct/incorrect) with confidence scores\n",
        "- **Processing:** Tokenization using RoBERTa tokenizer with BPE\n",
        "\n",
        "### Performance Benchmarks\n",
        "\n",
        "On NVIDIA H100:\n",
        "- **Inference Speed:** ~500 sentences/second (batch size 32)\n",
        "- **Latency:** <5ms per sentence (single inference)\n",
        "- **Memory:** ~2GB GPU memory (FP16 inference)\n",
        "\n",
        "### Deployment Recommendations\n",
        "\n",
        "- **CPU:** 4+ cores recommended for production\n",
        "- **GPU:** Any CUDA-capable GPU (T4, V100, A100, H100)\n",
        "- **Memory:** 4GB+ RAM, 2GB+ VRAM\n",
        "- **Precision:** FP16 or BF16 for optimal speed/memory tradeoff\n",
        "\n",
        "## Training Infrastructure\n",
        "\n",
        "- **Cloud Provider:** [Your provider]\n",
        "- **GPU:** NVIDIA H100 (80GB HBM3)\n",
        "- **CPU:** 26 cores\n",
        "- **RAM:** 200GB+\n",
        "- **Training Duration:** {train_hours:.2f} hours\n",
        "- **Cost:** ~${train_cost:.2f}\n",
        "\n",
        "## Ethical Considerations\n",
        "\n",
        "### Bias and Fairness\n",
        "- The model reflects patterns in the training data, which may contain biases\n",
        "- Performance may vary across different writing styles, registers, and demographics\n",
        "- Users should be aware that \"grammatically incorrect\" is context-dependent\n",
        "\n",
        "### Privacy\n",
        "- The model processes text locally and doesn't store user inputs\n",
        "- For production deployments, implement appropriate data handling policies\n",
        "\n",
        "### Accessibility\n",
        "- This tool should support, not replace, language learning and education\n",
        "- Should not be used to discriminate against non-native speakers or learners\n",
        "\n",
        "## Citation\n",
        "\n",
        "If you use this model in your research or application, please cite:\n",
        "\n",
        "```bibtex\n",
        "@misc{{roberta-nepali-ged-2024,\n",
        "  author = {{Dipesh Chaudhary}},\n",
        "  title = {{RoBERTa Nepali Grammatical Error Detection}},\n",
        "  year = {{2024}},\n",
        "  publisher = {{Hugging Face}},\n",
        "  howpublished = {{\\\\url{{https://huggingface.co/DipeshChaudhary/roberta-nepali-sequence-ged}}}}\n",
        "}}\n",
        "```\n",
        "\n",
        "Also cite the base model:\n",
        "\n",
        "```bibtex\n",
        "@misc{{roberta-nepali-125m,\n",
        "  author = {{IRIIS Research}},\n",
        "  title = {{RoBERTa Nepali 125M}},\n",
        "  year = {{2024}},\n",
        "  publisher = {{Hugging Face}},\n",
        "  howpublished = {{\\\\url{{https://huggingface.co/IRIIS-RESEARCH/RoBERTa_Nepali_125M}}}}\n",
        "}}\n",
        "```\n",
        "\n",
        "## References\n",
        "\n",
        "1. **Base Model:** [IRIIS-RESEARCH/RoBERTa_Nepali_125M](https://huggingface.co/IRIIS-RESEARCH/RoBERTa_Nepali_125M)\n",
        "2. **Dataset:** [sumitaryal/nepali_grammatical_error_detection](https://huggingface.co/datasets/sumitaryal/nepali_grammatical_error_detection)\n",
        "3. **RoBERTa Paper:** [Liu et al., 2019 - RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/abs/1907.11692)\n",
        "4. **Transformers Library:** [Hugging Face Transformers](https://github.com/huggingface/transformers)\n",
        "\n",
        "## Contact and Support\n",
        "\n",
        "- **Model Repository:** [https://huggingface.co/DipeshChaudhary/roberta-nepali-sequence-ged](https://huggingface.co/DipeshChaudhary/roberta-nepali-sequence-ged)\n",
        "- **Issues:** Please report issues on the model repository\n",
        "- **Updates:** Follow the repository for model updates and improvements\n",
        "\n",
        "## License\n",
        "\n",
        "This model is released under the Apache 2.0 License. See LICENSE for details.\n",
        "\n",
        "## Acknowledgments\n",
        "\n",
        "- IRIIS Research for the pre-trained RoBERTa Nepali model\n",
        "- Sumit Aryal for the grammatical error detection dataset\n",
        "- Hugging Face for the Transformers library and model hosting\n",
        "- The Nepali NLP community for continued support and feedback\n",
        "\n",
        "---\n",
        "\n",
        "*Last Updated: {datetime.now().strftime('%B %d, %Y')}*\n",
        "\"\"\"\n",
        "    \n",
        "    return model_card\n",
        "\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Mock data for demonstration\n",
        "    class MockResult:\n",
        "        def __init__(self):\n",
        "            self.metrics = {\n",
        "                'train_runtime': 10800  # 3 hours in seconds\n",
        "            }\n",
        "    \n",
        "    train_result = MockResult()\n",
        "    \n",
        "    final_metrics = {\n",
        "        'eval_accuracy': 0.9234,\n",
        "        'eval_f1': 0.9156,\n",
        "        'eval_precision': 0.9087,\n",
        "        'eval_recall': 0.9226,\n",
        "        'eval_precision_correct': 0.9321,\n",
        "        'eval_recall_correct': 0.9145,\n",
        "        'eval_f1_correct': 0.9232,\n",
        "        'eval_precision_incorrect': 0.8853,\n",
        "        'eval_recall_incorrect': 0.9307,\n",
        "        'eval_f1_incorrect': 0.9074\n",
        "    }\n",
        "    \n",
        "    # Generate the model card\n",
        "    model_card = generate_model_card(train_result, final_metrics)\n",
        "    \n",
        "    # Save to file\n",
        "    with open(\"MODEL_CARD.md\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(model_card)\n",
        "    \n",
        "    print(\"Model card generated successfully!\")\n",
        "    print(f\"Length: {len(model_card)} characters\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Model card uploaded successfully!\n"
          ]
        }
      ],
      "source": [
        "with open(\"./roberta-nepali-sequence-ged/README.md\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(model_card)\n",
        "\n",
        "# Push model card to Hub\n",
        "api.upload_file(\n",
        "    repo_id=hub_model_id,\n",
        "    path_in_repo=\"README.md\",\n",
        "    path_or_fileobj=\"./roberta-nepali-sequence-ged/README.md\",\n",
        "    token=hf_token\n",
        ")\n",
        "\n",
        "print(\"\\n✅ Model card uploaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6570d7bc",
      "metadata": {},
      "source": [
        "## refinetuning with lesser lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "4b2e8731",
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification,PreTrainedTokenizerFast\n",
        "\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"IRIIS-RESEARCH/RoBERTa_Nepali_125M\")\n",
        "model = RobertaForSequenceClassification.from_pretrained(\n",
        "    \"./nepali_grammar_detector/checkpoint-19694\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "12a127ee",
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./nepali_grammar_detector\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=512,  \n",
        "    per_device_eval_batch_size=1024,\n",
        "    learning_rate=1e-7,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=500,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=500,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=500,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True,\n",
        "    dataloader_num_workers=26,\n",
        "    # Hugging Face Hub integration\n",
        "    push_to_hub=True,\n",
        "    hub_model_id=hub_model_id,\n",
        "    hub_token=hf_token,\n",
        "    hub_strategy=\"every_save\",  # Push at every save\n",
        "    \n",
        "    # Optimization\n",
        "    dataloader_pin_memory=True,\n",
        "    fp16=True,  \n",
        "    tf32=True,\n",
        "    gradient_accumulation_steps=2,  # Effective batch size =  512* 2 = 1024\n",
        "    report_to=\"none\",\n",
        "    save_total_limit=3,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    compute_metrics=compute_metrics,\n",
        "    # callbacks=[\n",
        "    #     EarlyStoppingCallback(early_stopping_patience=6),\n",
        "    # ],\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "bb3e1685",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: The following arguments do not match the ones in the `trainer_state.json` within the checkpoint directory: \n",
            "\teval_steps: 500 (from args) != 1000 (from trainer_state.json)\n",
            "\tsave_steps: 500 (from args) != 1000 (from trainer_state.json)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='29541' max='29541' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [29541/29541 2:01:03, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision Correct</th>\n",
              "      <th>Recall Correct</th>\n",
              "      <th>F1 Correct</th>\n",
              "      <th>Precision Incorrect</th>\n",
              "      <th>Recall Incorrect</th>\n",
              "      <th>F1 Incorrect</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20000</td>\n",
              "      <td>0.168800</td>\n",
              "      <td>0.202986</td>\n",
              "      <td>0.920929</td>\n",
              "      <td>0.916995</td>\n",
              "      <td>0.934278</td>\n",
              "      <td>0.925556</td>\n",
              "      <td>0.925474</td>\n",
              "      <td>0.906109</td>\n",
              "      <td>0.915689</td>\n",
              "      <td>0.916995</td>\n",
              "      <td>0.934278</td>\n",
              "      <td>0.925556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21000</td>\n",
              "      <td>0.169800</td>\n",
              "      <td>0.198183</td>\n",
              "      <td>0.922680</td>\n",
              "      <td>0.920959</td>\n",
              "      <td>0.933122</td>\n",
              "      <td>0.927001</td>\n",
              "      <td>0.924646</td>\n",
              "      <td>0.911087</td>\n",
              "      <td>0.917816</td>\n",
              "      <td>0.920959</td>\n",
              "      <td>0.933122</td>\n",
              "      <td>0.927001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22000</td>\n",
              "      <td>0.170800</td>\n",
              "      <td>0.196330</td>\n",
              "      <td>0.923589</td>\n",
              "      <td>0.923005</td>\n",
              "      <td>0.932556</td>\n",
              "      <td>0.927756</td>\n",
              "      <td>0.924251</td>\n",
              "      <td>0.913634</td>\n",
              "      <td>0.918912</td>\n",
              "      <td>0.923005</td>\n",
              "      <td>0.932556</td>\n",
              "      <td>0.927756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23000</td>\n",
              "      <td>0.169700</td>\n",
              "      <td>0.195382</td>\n",
              "      <td>0.923866</td>\n",
              "      <td>0.924122</td>\n",
              "      <td>0.931799</td>\n",
              "      <td>0.927945</td>\n",
              "      <td>0.923577</td>\n",
              "      <td>0.915059</td>\n",
              "      <td>0.919298</td>\n",
              "      <td>0.924122</td>\n",
              "      <td>0.931799</td>\n",
              "      <td>0.927945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24000</td>\n",
              "      <td>0.168800</td>\n",
              "      <td>0.195393</td>\n",
              "      <td>0.923918</td>\n",
              "      <td>0.923024</td>\n",
              "      <td>0.933216</td>\n",
              "      <td>0.928092</td>\n",
              "      <td>0.924934</td>\n",
              "      <td>0.913596</td>\n",
              "      <td>0.919230</td>\n",
              "      <td>0.923024</td>\n",
              "      <td>0.933216</td>\n",
              "      <td>0.928092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25000</td>\n",
              "      <td>0.169400</td>\n",
              "      <td>0.200262</td>\n",
              "      <td>0.921221</td>\n",
              "      <td>0.914811</td>\n",
              "      <td>0.937572</td>\n",
              "      <td>0.926051</td>\n",
              "      <td>0.928722</td>\n",
              "      <td>0.903068</td>\n",
              "      <td>0.915715</td>\n",
              "      <td>0.914811</td>\n",
              "      <td>0.937572</td>\n",
              "      <td>0.926051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26000</td>\n",
              "      <td>0.168100</td>\n",
              "      <td>0.195631</td>\n",
              "      <td>0.923540</td>\n",
              "      <td>0.921362</td>\n",
              "      <td>0.934423</td>\n",
              "      <td>0.927847</td>\n",
              "      <td>0.926031</td>\n",
              "      <td>0.911457</td>\n",
              "      <td>0.918686</td>\n",
              "      <td>0.921362</td>\n",
              "      <td>0.934423</td>\n",
              "      <td>0.927847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27000</td>\n",
              "      <td>0.169200</td>\n",
              "      <td>0.190759</td>\n",
              "      <td>0.925992</td>\n",
              "      <td>0.928023</td>\n",
              "      <td>0.931585</td>\n",
              "      <td>0.929801</td>\n",
              "      <td>0.923719</td>\n",
              "      <td>0.919782</td>\n",
              "      <td>0.921746</td>\n",
              "      <td>0.928023</td>\n",
              "      <td>0.931585</td>\n",
              "      <td>0.929801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28000</td>\n",
              "      <td>0.170100</td>\n",
              "      <td>0.191072</td>\n",
              "      <td>0.925755</td>\n",
              "      <td>0.927235</td>\n",
              "      <td>0.932021</td>\n",
              "      <td>0.929622</td>\n",
              "      <td>0.924093</td>\n",
              "      <td>0.918798</td>\n",
              "      <td>0.921438</td>\n",
              "      <td>0.927235</td>\n",
              "      <td>0.932021</td>\n",
              "      <td>0.929622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29000</td>\n",
              "      <td>0.169700</td>\n",
              "      <td>0.190827</td>\n",
              "      <td>0.925934</td>\n",
              "      <td>0.927633</td>\n",
              "      <td>0.931922</td>\n",
              "      <td>0.929773</td>\n",
              "      <td>0.924029</td>\n",
              "      <td>0.919285</td>\n",
              "      <td>0.921651</td>\n",
              "      <td>0.927633</td>\n",
              "      <td>0.931922</td>\n",
              "      <td>0.929773</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=29541, training_loss=0.056452828461490884, metrics={'train_runtime': 7265.0241, 'train_samples_per_second': 4163.567, 'train_steps_per_second': 4.066, 'total_flos': 3.979345802142044e+18, 'train_loss': 0.056452828461490884, 'epoch': 3.0})"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train(resume_from_checkpoint=\"./nepali_grammar_detector/checkpoint-19694\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "ced3d2c1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "MODEL PREDICTIONS ON TEST SENTENCES (FROM TRAINING CORPUS)\n",
            "================================================================================\n",
            "\n",
            "1. Sentence: बाबाले सर्प बारे अरू केही बोल्छ।\n",
            "   Prediction: INCORRECT (confidence: 0.5757)\n",
            "   Probabilities → Correct: 0.4243 | Incorrect: 0.5757\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "2. Sentence: बाबाले सर्प बारे अरू केही बोल्नुभएन।\n",
            "   Prediction: CORRECT (confidence: 0.8555)\n",
            "   Probabilities → Correct: 0.8555 | Incorrect: 0.1445\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "3. Sentence: दुर्गमक्षेत्रका अरू जनताले पनि उनीहरूबाट पात सिक्नुपर्छ।\n",
            "   Prediction: INCORRECT (confidence: 0.9983)\n",
            "   Probabilities → Correct: 0.0017 | Incorrect: 0.9983\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "4. Sentence: दुर्गमक्षेत्रका अरू जनताले पनि उनीहरूबाट पाठ सिक्नुपर्छ।\n",
            "   Prediction: CORRECT (confidence: 0.9307)\n",
            "   Probabilities → Correct: 0.9307 | Incorrect: 0.0693\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "5. Sentence: तर यसका लागि निजी स्कूलहरू मात्रमा दोषी छैनन् ?\n",
            "   Prediction: INCORRECT (confidence: 0.9844)\n",
            "   Probabilities → Correct: 0.0156 | Incorrect: 0.9844\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "6. Sentence: तर यसका लागि निजी स्कूलहरू मात्रमा दोषी छैनन्।\n",
            "   Prediction: INCORRECT (confidence: 0.9787)\n",
            "   Probabilities → Correct: 0.0213 | Incorrect: 0.9787\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "7. Sentence: एकै कोठामा सुत्ने दाजुभाइ पनि बीच कुराकानी हुन छाडेको छ।\n",
            "   Prediction: INCORRECT (confidence: 0.9993)\n",
            "   Probabilities → Correct: 0.0007 | Incorrect: 0.9993\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "8. Sentence: एकै कोठामा सुत्ने दाजुभाइ बीच पनि कुराकानी हुन छाडेको छ।\n",
            "   Prediction: CORRECT (confidence: 0.9468)\n",
            "   Probabilities → Correct: 0.9468 | Incorrect: 0.0532\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "9. Sentence: सूचना क्रान्तिको दुनियाँमा मख्ख परेर ठूलो भ्रान्ति पालिरहेका छौं।\n",
            "   Prediction: INCORRECT (confidence: 0.8378)\n",
            "   Probabilities → Correct: 0.1622 | Incorrect: 0.8378\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "10. Sentence: हामी सूचना क्रान्तिको दुनियाँमा मख्ख परेर ठूलो भ्रान्ति पालिरहेका छौं।\n",
            "   Prediction: CORRECT (confidence: 0.9204)\n",
            "   Probabilities → Correct: 0.9204 | Incorrect: 0.0796\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "11. Sentence: यो टेक्निक पनि भाववादसँग सम्बद्ध।\n",
            "   Prediction: INCORRECT (confidence: 0.8267)\n",
            "   Probabilities → Correct: 0.1733 | Incorrect: 0.8267\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "12. Sentence: यो टेक्निक पनि भाववादसँग सम्बद्ध छ।\n",
            "   Prediction: CORRECT (confidence: 0.8164)\n",
            "   Probabilities → Correct: 0.8164 | Incorrect: 0.1836\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "13. Sentence: खाद्यान्नकै हकमा पनि सकेसम्म खेर गरी खाना नै नबनाए हुने।\n",
            "   Prediction: INCORRECT (confidence: 0.9993)\n",
            "   Probabilities → Correct: 0.0007 | Incorrect: 0.9993\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "14. Sentence: खाद्यान्नकै हकमा पनि सकेसम्म खेर जाने गरी खाना नै नबनाए हुने।\n",
            "   Prediction: CORRECT (confidence: 0.9298)\n",
            "   Probabilities → Correct: 0.9298 | Incorrect: 0.0702\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def predict_grammar(sentences):\n",
        "    \"\"\"\n",
        "    Enhanced prediction function with proper preprocessing\n",
        "    \"\"\"\n",
        "    if isinstance(sentences, str):\n",
        "        sentences = [sentences]\n",
        "    \n",
        "    # Get the device the model is on\n",
        "    device = next(model.parameters()).device\n",
        "    \n",
        "    inputs = tokenizer(\n",
        "        sentences,  # Use as-is since training data is already in garbled format\n",
        "        padding=True, \n",
        "        truncation=True, \n",
        "        max_length=256, \n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    \n",
        "    # Move inputs to the same device as model\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "    \n",
        "    results = []\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        predicted_class = predictions[i].argmax().item()\n",
        "        confidence = predictions[i][predicted_class].item()\n",
        "        label = \"incorrect\" if predicted_class == 1 else \"correct\"\n",
        "        \n",
        "        results.append({\n",
        "            'sentence': sentence,\n",
        "            'prediction': label,\n",
        "            'confidence': confidence,\n",
        "            'correct_prob': predictions[i][0].item(),\n",
        "            'incorrect_prob': predictions[i][1].item()\n",
        "        })\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Test sentences matching the 7 error types from your training corpus\n",
        "test_sentences = [\n",
        "    # 1. Verb Form Error\n",
        "    \"बाबाले सर्प बारे अरू केही बोल्छ।\",  # Incorrect\n",
        "    \"बाबाले सर्प बारे अरू केही बोल्नुभएन।\",  # Correct\n",
        "\n",
        "    # 2. Homophone Error\n",
        "    \"दुर्गमक्षेत्रका अरू जनताले पनि उनीहरूबाट पात सिक्नुपर्छ।\",  # Incorrect\n",
        "    \"दुर्गमक्षेत्रका अरू जनताले पनि उनीहरूबाट पाठ सिक्नुपर्छ।\",  # Correct\n",
        "\n",
        "    # 3. Punctuation Error\n",
        "    \"तर यसका लागि निजी स्कूलहरू मात्रमा दोषी छैनन् ?\",  # Incorrect\n",
        "    \"तर यसका लागि निजी स्कूलहरू मात्रमा दोषी छैनन्।\",  # Correct\n",
        "\n",
        "    # 4. Sentence Structure Error\n",
        "    \"एकै कोठामा सुत्ने दाजुभाइ पनि बीच कुराकानी हुन छाडेको छ।\",  # Incorrect\n",
        "    \"एकै कोठामा सुत्ने दाजुभाइ बीच पनि कुराकानी हुन छाडेको छ।\",  # Correct\n",
        "\n",
        "    # 5. Pronoun Missing Error\n",
        "    \"सूचना क्रान्तिको दुनियाँमा मख्ख परेर ठूलो भ्रान्ति पालिरहेका छौं।\",  # Incorrect\n",
        "    \"हामी सूचना क्रान्तिको दुनियाँमा मख्ख परेर ठूलो भ्रान्ति पालिरहेका छौं।\",  # Correct\n",
        "\n",
        "    # 6. Main Verb Missing\n",
        "    \"यो टेक्निक पनि भाववादसँग सम्बद्ध।\",  # Incorrect\n",
        "    \"यो टेक्निक पनि भाववादसँग सम्बद्ध छ।\",  # Correct\n",
        "\n",
        "    # 7. Auxiliary Verb Missing\n",
        "    \"खाद्यान्नकै हकमा पनि सकेसम्म खेर गरी खाना नै नबनाए हुने।\",  # Incorrect\n",
        "    \"खाद्यान्नकै हकमा पनि सकेसम्म खेर जाने गरी खाना नै नबनाए हुने।\",  # Correct\n",
        "\n",
        "]\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MODEL PREDICTIONS ON TEST SENTENCES (FROM TRAINING CORPUS)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "predictions = predict_grammar(test_sentences)\n",
        "for i, pred in enumerate(predictions, 1):\n",
        "    print(f\"\\n{i}. Sentence: {pred['sentence']}\")\n",
        "    print(f\"   Prediction: {pred['prediction'].upper()} (confidence: {pred['confidence']:.4f})\")\n",
        "    print(f\"   Probabilities → Correct: {pred['correct_prob']:.4f} | Incorrect: {pred['incorrect_prob']:.4f}\")\n",
        "    print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cbe869e",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
