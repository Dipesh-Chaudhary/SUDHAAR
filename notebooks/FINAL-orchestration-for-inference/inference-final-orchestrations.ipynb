{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets huggingface_hub torch accelerate -q\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T10:43:48.636137Z","iopub.execute_input":"2025-11-15T10:43:48.636755Z","iopub.status.idle":"2025-11-15T10:45:12.973228Z","shell.execute_reply.started":"2025-11-15T10:43:48.636726Z","shell.execute_reply":"2025-11-15T10:45:12.972304Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"**wait!!!**","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    AutoModelForTokenClassification,\n    AutoModelForMaskedLM,\n)\nfrom typing import List, Tuple, Dict, Any, Optional\nimport re\nimport warnings\nfrom copy import deepcopy\n\nwarnings.filterwarnings(\"ignore\")\n\n# ============================================================================\n# CONFIGURATION\n# ============================================================================\n\nBASE_MODEL = \"IRIIS-RESEARCH/RoBERTa_Nepali_125M\"\n\n# Model Hub IDs\nGED_MODEL_HUB_ID = \"DipeshChaudhary/roberta-nepali-sequence-ged\"\nBINARY_MODEL_HUB_ID = \"DipeshChaudhary/nepali-gec-binary-detector\"\nERROR_TYPE_MODEL_HUB_ID = \"DipeshChaudhary/nepali-gec-error-type-classifier\"\nMLM_MODEL_HUB_ID = \"DipeshChaudhary/nepali-mlm-guesser-finetuned-model-1\"\n\n# CORRECT Label Mapping for Error Type Model\nERROR_ID2LABEL = {\n    0: '$DELETE',\n    1: '$REPLACE',\n    2: '$APPEND',\n    3: '$SWAP_NEXT',\n    4: '$SWAP_PREV',\n    5: '$MERGE_NEXT',\n    6: '$MERGE_PREV'\n}\n\nERROR_LABEL2ID = {v: k for k, v in ERROR_ID2LABEL.items()}\n\n# Optimal Thresholds\nBINARY_THRESHOLD = 0.42\n\nERROR_TYPE_THRESHOLDS = {\n    '$DELETE': 0.05,\n    '$REPLACE': 0.51,\n    '$APPEND': 0.45,\n    '$SWAP_NEXT': 0.50,\n    '$SWAP_PREV': 0.51,\n    '$MERGE_NEXT': 0.05,\n    '$MERGE_PREV': 0.05,\n}\n\n# Tags categorized by reliability\nRELIABLE_TAGS = {'$REPLACE', '$APPEND', '$SWAP_NEXT', '$SWAP_PREV'}\nUNRELIABLE_TAGS = {'$DELETE', '$MERGE_NEXT', '$MERGE_PREV'}\n\n# Pipeline parameters\nMAX_CORRECTION_ITERATIONS = 10\nMLM_TOP_K_SUGGESTIONS = 5  # Increased from 3 for aggressive fallback\n\n# ============================================================================\n# MODEL LOADING\n# ============================================================================\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"ğŸ”§ Using device: {device}\")\n\n# Tokenizers\nged_tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\ngector_tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, add_prefix_space=True)\n\n# Models\nprint(\"ğŸ“¦ Loading models...\")\nged_model = AutoModelForSequenceClassification.from_pretrained(GED_MODEL_HUB_ID).to(device)\nbinary_model = AutoModelForTokenClassification.from_pretrained(BINARY_MODEL_HUB_ID).to(device)\nerror_model = AutoModelForTokenClassification.from_pretrained(ERROR_TYPE_MODEL_HUB_ID).to(device)\nmlm_model = AutoModelForMaskedLM.from_pretrained(MLM_MODEL_HUB_ID).to(device)\n\nged_model.eval()\nbinary_model.eval()\nerror_model.eval()\nmlm_model.eval()\nprint(\"âœ… All models loaded successfully!\")\n\n# ============================================================================\n# PREPROCESSING & POSTPROCESSING\n# ============================================================================\n\ndef preprocess_sentence(sentence: str) -> str:\n    \"\"\"Separates punctuation for better GEC token alignment.\"\"\"\n    sentence = re.sub(r'([à¥¤?,!])', r' \\1', sentence)\n    sentence = re.sub(r'\\s+', ' ', sentence).strip()\n    return sentence\n\ndef postprocess_sentence(tokens: List[str]) -> str:\n    \"\"\"Re-merges separated punctuation.\"\"\"\n    sentence = \" \".join(tokens)\n    sentence = re.sub(r'\\s+([à¥¤?,!])', r'\\1', sentence).strip()\n    return sentence\n\n# ============================================================================\n# GED & BINARY VALIDATION\n# ============================================================================\n\ndef check_sentence_correctness(sentence: str) -> Tuple[bool, float]:\n    \"\"\"Check if sentence is correct using GED model.\"\"\"\n    inputs = ged_tokenizer(sentence, return_tensors=\"pt\", truncation=True).to(device)\n    with torch.no_grad():\n        logits = ged_model(**inputs).logits\n    probs = torch.softmax(logits, dim=-1)[0]\n    is_correct = torch.argmax(probs).item() == 0\n    confidence = probs[0 if is_correct else 1].item()\n    return is_correct, confidence\n\ndef validate_with_binary_model(sentence: str) -> Tuple[bool, List[int]]:\n    \"\"\"Validate sentence using token-level binary classifier.\"\"\"\n    inputs = gector_tokenizer(sentence, return_tensors=\"pt\", truncation=True).to(device)\n    \n    with torch.no_grad():\n        binary_logits = binary_model(**inputs).logits\n    \n    binary_probs = torch.softmax(binary_logits, dim=-1)[0]\n    \n    # Map tokens to words\n    word_ids = inputs.word_ids(batch_index=0)\n    word_start_token_map = {}\n    for token_idx, word_idx in enumerate(word_ids):\n        if word_idx is not None and word_idx not in word_start_token_map:\n            word_start_token_map[word_idx] = token_idx\n    \n    error_positions = []\n    for word_idx in sorted(word_start_token_map.keys()):\n        token_idx = word_start_token_map[word_idx]\n        binary_error_prob = binary_probs[token_idx, 1].item()\n        \n        if binary_error_prob > BINARY_THRESHOLD:\n            error_positions.append(word_idx)\n    \n    all_correct = len(error_positions) == 0\n    return all_correct, error_positions\n\ndef is_sentence_fully_correct(sentence: str) -> Tuple[bool, str]:\n    \"\"\"Validate sentence using BOTH GED and Binary models.\"\"\"\n    ged_correct, ged_conf = check_sentence_correctness(sentence)\n    binary_correct, error_positions = validate_with_binary_model(sentence)\n    \n    if ged_correct and binary_correct:\n        return True, f\"âœ“ Both models agree (GED: {ged_conf:.3f})\"\n    elif not ged_correct and not binary_correct:\n        return False, f\"âœ— Both models detect errors (GED: {ged_conf:.3f}, Binary: {len(error_positions)} errors)\"\n    elif not ged_correct:\n        return False, f\"âœ— GED detects error (conf: {ged_conf:.3f})\"\n    else:\n        return False, f\"âœ— Binary detects {len(error_positions)} error(s) at positions: {error_positions}\"\n\n# ============================================================================\n# MLM GUESSING (Multi-token strategy)\n# ============================================================================\n\ndef get_mlm_suggestions(sentence: str, mask_positions: List[int], k: int = MLM_TOP_K_SUGGESTIONS, verbose: bool = False) -> List[List[str]]:\n    \"\"\"Get MLM suggestions with multi-mask strategy for compound words.\"\"\"\n    if not mask_positions:\n        return []\n    \n    token_list = sentence.split()\n    valid_positions = [pos for pos in mask_positions if 0 <= pos <= len(token_list)]\n    if not valid_positions:\n        return []\n    \n    all_suggestions_per_position = []\n    \n    for pos in valid_positions:\n        position_suggestions = []\n        \n        if verbose:\n            print(f\"      ğŸ” MLM for position {pos} (word: '{token_list[pos] if pos < len(token_list) else 'APPEND'}')\")\n        \n        # Strategy 1: Single mask\n        single_mask_suggestions = _get_single_mask_suggestions(token_list, pos, k)\n        if verbose and single_mask_suggestions:\n            print(f\"        Single mask: {single_mask_suggestions[:3]}\")\n        position_suggestions.extend(single_mask_suggestions)\n        \n        # Strategy 2: Double mask\n        double_mask_suggestions = _get_multi_mask_suggestions(token_list, pos, num_masks=2, k=k)\n        if verbose and double_mask_suggestions:\n            print(f\"        Double mask: {double_mask_suggestions[:3]}\")\n        position_suggestions.extend(double_mask_suggestions)\n        \n        # Strategy 3: Triple mask\n        triple_mask_suggestions = _get_multi_mask_suggestions(token_list, pos, num_masks=3, k=k)\n        if verbose and triple_mask_suggestions:\n            print(f\"        Triple mask: {triple_mask_suggestions[:3]}\")\n        position_suggestions.extend(triple_mask_suggestions)\n        \n        # Remove duplicates and keep top-k\n        seen = set()\n        unique_suggestions = []\n        for sugg in position_suggestions:\n            if sugg and sugg not in seen:\n                seen.add(sugg)\n                unique_suggestions.append(sugg)\n                if len(unique_suggestions) >= k:\n                    break\n        \n        if verbose:\n            print(f\"        âœ“ Final suggestions: {unique_suggestions}\")\n        \n        all_suggestions_per_position.append(unique_suggestions[:k])\n    \n    return all_suggestions_per_position\n\ndef _get_single_mask_suggestions(token_list: List[str], position: int, k: int) -> List[str]:\n    \"\"\"Get suggestions with a single [MASK] token.\"\"\"\n    temp_list = list(token_list)\n    \n    if position < len(temp_list):\n        temp_list[position] = gector_tokenizer.mask_token\n    elif position == len(temp_list):\n        temp_list.append(gector_tokenizer.mask_token)\n    else:\n        return []\n    \n    masked_sentence = \" \".join(temp_list)\n    return _predict_masked_tokens(masked_sentence, k)\n\ndef _get_multi_mask_suggestions(token_list: List[str], position: int, num_masks: int, k: int) -> List[str]:\n    \"\"\"Get suggestions by placing multiple consecutive [MASK] tokens.\"\"\"\n    temp_list = list(token_list)\n    \n    if position < len(temp_list):\n        temp_list[position:position+1] = [gector_tokenizer.mask_token] * num_masks\n    elif position == len(temp_list):\n        temp_list.extend([gector_tokenizer.mask_token] * num_masks)\n    else:\n        return []\n    \n    masked_sentence = \" \".join(temp_list)\n    return _predict_masked_tokens(masked_sentence, k, expect_multi_token=True)\n\ndef _predict_masked_tokens(masked_sentence: str, k: int, expect_multi_token: bool = False) -> List[str]:\n    \"\"\"Core MLM prediction function.\"\"\"\n    inputs = gector_tokenizer(masked_sentence, return_tensors='pt', truncation=True).to(device)\n    mask_token_indices = torch.where(inputs[\"input_ids\"] == gector_tokenizer.mask_token_id)[1]\n    \n    if mask_token_indices.numel() == 0:\n        return []\n    \n    with torch.no_grad():\n        logits = mlm_model(**inputs).logits\n    \n    suggestions = []\n    \n    if expect_multi_token and mask_token_indices.numel() > 1:\n        num_masks = mask_token_indices.numel()\n        first_mask_logits = logits[0, mask_token_indices[0], :]\n        top_first = torch.topk(first_mask_logits, min(k * 2, 50)).indices.tolist()\n        \n        for first_token_id in top_first:\n            first_decoded = gector_tokenizer.decode(first_token_id).strip()\n            \n            if not _is_valid_token(first_decoded):\n                continue\n            \n            remaining_parts = []\n            for mask_idx in mask_token_indices[1:]:\n                mask_logits = logits[0, mask_idx, :]\n                top_token_id = torch.argmax(mask_logits).item()\n                decoded = gector_tokenizer.decode(top_token_id).strip()\n                \n                if decoded.startswith('##'):\n                    decoded = decoded[2:]\n                \n                if decoded and len(decoded) > 0:\n                    remaining_parts.append(decoded)\n            \n            if remaining_parts:\n                full_word = first_decoded + \"\".join(remaining_parts)\n            else:\n                full_word = first_decoded\n            \n            if full_word and len(full_word) > 0:\n                suggestions.append(full_word)\n            \n            if len(suggestions) >= k:\n                break\n    else:\n        for mask_idx in mask_token_indices:\n            mask_logits = logits[0, mask_idx, :]\n            top_k_tokens = torch.topk(mask_logits, k * 3).indices.tolist()\n            \n            for token_id in top_k_tokens:\n                decoded = gector_tokenizer.decode(token_id).strip()\n                \n                if _is_valid_token(decoded):\n                    suggestions.append(decoded)\n                \n                if len(suggestions) >= k:\n                    break\n            \n            if suggestions:\n                break\n    \n    return suggestions[:k]\n\ndef _is_valid_token(token: str) -> bool:\n    \"\"\"Check if a token is valid for use as a correction.\"\"\"\n    if not token or len(token) < 1:\n        return False\n    \n    invalid_tokens = {'(', ')', '[', ']', '{', '}', '<', '>', '\"', \"'\", '`', ',', '.'}\n    if token in invalid_tokens:\n        return False\n    \n    if token.startswith('##'):\n        return False\n    \n    return True\n\ndef apply_mlm_to_positions(tokens: List[str], positions: List[int], suggestions: List[List[str]]) -> str:\n    \"\"\"Apply MLM suggestions to specific positions.\"\"\"\n    result = list(tokens)\n    \n    for pos, sugg_list in zip(positions, suggestions):\n        if sugg_list and 0 <= pos < len(result):\n            suggestion = sugg_list[0]\n            if _is_valid_token(suggestion):\n                result[pos] = suggestion\n    \n    return \" \".join(result)\n\n# ============================================================================\n# TOKEN CLASSIFICATION & ERROR DETECTION\n# ============================================================================\n\ndef get_token_predictions(sentence: str, verbose: bool = False) -> List[Dict[str, Any]]:\n    \"\"\"Get comprehensive token-level predictions.\"\"\"\n    inputs = gector_tokenizer(sentence, return_tensors=\"pt\", truncation=True).to(device)\n    \n    with torch.no_grad():\n        binary_logits = binary_model(**inputs).logits\n        error_logits = error_model(**inputs).logits\n    \n    binary_probs = torch.softmax(binary_logits, dim=-1)[0]\n    error_probs = torch.softmax(error_logits, dim=-1)[0]\n    \n    word_ids = inputs.word_ids(batch_index=0)\n    word_start_token_map = {}\n    for token_idx, word_idx in enumerate(word_ids):\n        if word_idx is not None and word_idx not in word_start_token_map:\n            word_start_token_map[word_idx] = token_idx\n    \n    tokens = sentence.split()\n    predictions = []\n    \n    for word_idx in sorted(word_start_token_map.keys()):\n        if word_idx >= len(tokens):\n            continue\n        \n        token_idx = word_start_token_map[word_idx]\n        token = tokens[word_idx]\n        \n        binary_error_prob = binary_probs[token_idx, 1].item()\n        \n        error_type_probs = {}\n        for error_id, error_tag in ERROR_ID2LABEL.items():\n            error_type_probs[error_tag] = error_probs[token_idx, error_id].item()\n        \n        candidate_tags = []\n        for tag, prob in error_type_probs.items():\n            threshold = ERROR_TYPE_THRESHOLDS[tag]\n            if prob > threshold:\n                candidate_tags.append((tag, prob))\n        \n        candidate_tags.sort(key=lambda x: x[1], reverse=True)\n        \n        is_error = binary_error_prob > BINARY_THRESHOLD\n        primary_tag = candidate_tags[0][0] if candidate_tags else None\n        \n        pred = {\n            'word_idx': word_idx,\n            'token': token,\n            'binary_error_prob': binary_error_prob,\n            'error_type_probs': error_type_probs,\n            'candidate_tags': candidate_tags,\n            'primary_tag': primary_tag,\n            'is_error': is_error,\n            'is_reliable': primary_tag in RELIABLE_TAGS if primary_tag else False\n        }\n        \n        predictions.append(pred)\n        \n        if verbose and is_error:\n            print(f\"  âš ï¸  Token '{token}' @ pos {word_idx}\")\n            print(f\"      Binary: {binary_error_prob:.3f} > {BINARY_THRESHOLD}\")\n            if primary_tag:\n                print(f\"      Primary: {primary_tag} ({error_type_probs[primary_tag]:.3f})\")\n    \n    return predictions\n\n# ============================================================================\n# CORRECTION STRATEGIES\n# ============================================================================\n\ndef apply_tag_based_correction(tokens: List[str], corrections: List[Dict[str, Any]], \n                                use_mlm_for_unreliable: bool = False) -> str:\n    \"\"\"Apply corrections based on predicted tags with proper phase handling.\"\"\"\n    result_tokens = list(tokens)\n    valid_corrections = [c for c in corrections if c['primary_tag'] is not None]\n    \n    if not valid_corrections:\n        return \" \".join(result_tokens)\n    \n    swaps = []\n    deletes_merges = []\n    replaces_appends = []\n    \n    for corr in valid_corrections:\n        tag = corr['primary_tag']\n        if tag in ['$SWAP_NEXT', '$SWAP_PREV']:\n            swaps.append(corr)\n        elif tag in ['$DELETE', '$MERGE_NEXT', '$MERGE_PREV']:\n            deletes_merges.append(corr)\n        else:\n            replaces_appends.append(corr)\n    \n    # PHASE 1: Swaps\n    for corr in swaps:\n        idx = corr['word_idx']\n        tag = corr['primary_tag']\n        \n        if tag == '$SWAP_NEXT' and idx + 1 < len(result_tokens):\n            result_tokens[idx], result_tokens[idx + 1] = result_tokens[idx + 1], result_tokens[idx]\n        elif tag == '$SWAP_PREV' and idx > 0:\n            result_tokens[idx], result_tokens[idx - 1] = result_tokens[idx - 1], result_tokens[idx]\n    \n    # PHASE 2: Deletions and Merges\n    for corr in sorted(deletes_merges, key=lambda x: x['word_idx'], reverse=True):\n        idx = corr['word_idx']\n        tag = corr['primary_tag']\n        \n        if idx >= len(result_tokens):\n            continue\n        \n        if use_mlm_for_unreliable:\n            continue\n        \n        if tag == '$DELETE':\n            result_tokens.pop(idx)\n        elif tag == '$MERGE_NEXT' and idx + 1 < len(result_tokens):\n            result_tokens[idx] = result_tokens[idx] + result_tokens.pop(idx + 1)\n        elif tag == '$MERGE_PREV' and idx > 0:\n            result_tokens[idx - 1] = result_tokens[idx - 1] + result_tokens.pop(idx)\n    \n    # PHASE 3: Replacements and Appends\n    offset = 0\n    for corr in sorted(replaces_appends, key=lambda x: x['word_idx']):\n        original_idx = corr['word_idx']\n        tag = corr['primary_tag']\n        current_idx = original_idx + offset\n        \n        if current_idx >= len(result_tokens):\n            continue\n        \n        if tag == '$REPLACE':\n            suggestions = get_mlm_suggestions(\" \".join(result_tokens), [current_idx], k=5, verbose=False)\n            if suggestions and suggestions[0]:\n                for sugg in suggestions[0]:\n                    if _is_valid_token(sugg):\n                        result_tokens[current_idx] = sugg\n                        break\n        \n        elif tag == '$APPEND':\n            suggestions = get_mlm_suggestions(\" \".join(result_tokens), [current_idx + 1], k=5)\n            if suggestions and suggestions[0]:\n                for sugg in suggestions[0]:\n                    if _is_valid_token(sugg):\n                        result_tokens.insert(current_idx + 1, sugg)\n                        offset += 1\n                        break\n    \n    return \" \".join(result_tokens)\n\ndef generate_correction_candidates(tokens: List[str], predictions: List[Dict[str, Any]]) -> List[Tuple[str, str]]:\n    \"\"\"Generate multiple correction candidates with strategies.\"\"\"\n    candidates = []\n    \n    error_predictions = [p for p in predictions if p['is_error']]\n    if not error_predictions:\n        return [((\" \".join(tokens), \"no_errors\"))]\n    \n    valid_predictions = [p for p in error_predictions if p['primary_tag'] is not None]\n    \n    # Strategy 1: Primary tags\n    if valid_predictions:\n        corrected = apply_tag_based_correction(tokens, valid_predictions, use_mlm_for_unreliable=False)\n        candidates.append((corrected, \"primary_tags\"))\n    \n    # Strategy 2: Forced swap\n    swap_corrections = [p for p in valid_predictions if 'SWAP' in (p['primary_tag'] or '')]\n    non_swap_errors = [p for p in valid_predictions if 'SWAP' not in (p['primary_tag'] or '')]\n    \n    if len(swap_corrections) == 1 and non_swap_errors:\n        swap_idx = swap_corrections[0]['word_idx']\n        for other in non_swap_errors:\n            other_idx = other['word_idx']\n            if abs(swap_idx - other_idx) == 1:\n                temp_tokens = list(tokens)\n                if swap_idx < other_idx:\n                    temp_tokens[swap_idx], temp_tokens[other_idx] = temp_tokens[other_idx], temp_tokens[swap_idx]\n                else:\n                    temp_tokens[other_idx], temp_tokens[swap_idx] = temp_tokens[swap_idx], temp_tokens[other_idx]\n                \n                remaining = [p for p in valid_predictions if p['word_idx'] not in [swap_idx, other_idx]]\n                corrected = apply_tag_based_correction(temp_tokens, remaining, use_mlm_for_unreliable=False)\n                candidates.append((corrected, \"forced_swap\"))\n                break\n    \n    # Strategy 3: MLM for unreliable\n    unreliable_predictions = [p for p in valid_predictions if not p['is_reliable']]\n    if unreliable_predictions:\n        unreliable_positions = [p['word_idx'] for p in unreliable_predictions]\n        suggestions = get_mlm_suggestions(\" \".join(tokens), unreliable_positions)\n        \n        if suggestions and len(suggestions) == len(unreliable_positions):\n            corrected = apply_mlm_to_positions(tokens, unreliable_positions, suggestions)\n            reliable_corrections = [p for p in valid_predictions if p['is_reliable']]\n            if reliable_corrections:\n                corrected = apply_tag_based_correction(corrected.split(), reliable_corrections, use_mlm_for_unreliable=False)\n            candidates.append((corrected, \"mlm_unreliable\"))\n    \n    # Strategy 4: Full MLM\n    all_error_positions = [p['word_idx'] for p in error_predictions]\n    if len(all_error_positions) > 1:\n        suggestions = get_mlm_suggestions(\" \".join(tokens), all_error_positions)\n        if suggestions and len(suggestions) == len(all_error_positions):\n            corrected = apply_mlm_to_positions(tokens, all_error_positions, suggestions)\n            candidates.append((corrected, \"full_mlm\"))\n    \n    # Remove duplicates\n    seen = set()\n    unique_candidates = []\n    for sent, strategy in candidates:\n        if sent not in seen:\n            seen.add(sent)\n            unique_candidates.append((sent, strategy))\n    \n    return unique_candidates\n\n# ============================================================================\n# MAIN PIPELINE (WITH AGGRESSIVE MLM FALLBACK)\n# ============================================================================\n\ndef correct_sentence(sentence: str, verbose: bool = True) -> str:\n    \"\"\"Complete GEC pipeline with aggressive MLM fallback for GED-only errors.\"\"\"\n    preprocessed = preprocess_sentence(sentence)\n    \n    if verbose:\n        print(\"\\n\" + \"=\"*80)\n        print(f\"ğŸ” INPUT: {sentence}\")\n        print(f\"ğŸ”§ PREPROCESSED: {preprocessed}\")\n        print(\"=\"*80)\n    \n    current_sentence = preprocessed\n    iteration = 0\n    correction_history = []\n    seen_sentences = {current_sentence}\n    previous_error_count = float('inf')\n    \n    while iteration < MAX_CORRECTION_ITERATIONS:\n        iteration += 1\n        \n        if verbose:\n            print(f\"\\n{'â”€'*80}\")\n            print(f\"ğŸ”„ ITERATION {iteration}/{MAX_CORRECTION_ITERATIONS}\")\n            print(f\"{'â”€'*80}\")\n        \n        is_correct, validation_msg = is_sentence_fully_correct(current_sentence)\n        \n        if verbose:\n            print(f\"ğŸ” Validation: {validation_msg}\")\n        \n        if is_correct:\n            if verbose:\n                print(f\"âœ… CORRECTION COMPLETE after {iteration} iteration(s)!\")\n            break\n        \n        predictions = get_token_predictions(current_sentence, verbose=verbose)\n        error_predictions = [p for p in predictions if p['is_error']]\n        \n        # CRITICAL FIX: GED-only error scenario - EXHAUSTIVE SEARCH\n        if not error_predictions:\n            if verbose:\n                print(\"âš ï¸  Binary found no errors, but GED detected issues.\")\n                print(\"ğŸ”„ Attempting AGGRESSIVE MLM on ALL token positions...\")\n            \n            tokens = current_sentence.split()\n            all_valid_candidates = []  # Store (sentence, confidence, strategy, position)\n            \n            # PHASE 1: Single-position MLM (1 mask, 2 masks, 3 masks)\n            if verbose:\n                print(f\"\\n   ğŸ“ PHASE 1: Testing ALL {len(tokens)} positions with single/double/triple masks\")\n            \n            for pos in range(len(tokens)):\n                if verbose:\n                    print(f\"      Position {pos}/{len(tokens)-1} ('{tokens[pos]}')\")\n                \n                # Try single mask\n                suggestions_single = get_mlm_suggestions(current_sentence, [pos], k=5, verbose=False)\n                \n                if suggestions_single and suggestions_single[0]:\n                    for sugg in suggestions_single[0]:\n                        test_tokens = list(tokens)\n                        test_tokens[pos] = sugg\n                        test_sentence = \" \".join(test_tokens)\n                        \n                        if test_sentence in seen_sentences:\n                            continue\n                        \n                        is_valid, reason = is_sentence_fully_correct(test_sentence)\n                        \n                        if is_valid:\n                            # Get GED confidence\n                            ged_correct, ged_conf = check_sentence_correctness(test_sentence)\n                            all_valid_candidates.append({\n                                'sentence': test_sentence,\n                                'confidence': ged_conf,\n                                'strategy': f\"1mask_pos{pos}\",\n                                'position': pos,\n                                'original': tokens[pos],\n                                'replacement': sugg\n                            })\n                            if verbose:\n                                print(f\"         âœ… 1-mask: '{tokens[pos]}' â†’ '{sugg}' (conf: {ged_conf:.3f})\")\n            \n            # PHASE 2: Two-position MLM (adjacent pairs)\n            if verbose:\n                print(f\"\\n   ğŸ“ PHASE 2: Testing adjacent position pairs ({len(tokens)-1} pairs)\")\n            \n            for pos in range(len(tokens) - 1):\n                if verbose:\n                    print(f\"      Pair [{pos},{pos+1}] ('{tokens[pos]}', '{tokens[pos+1]}')\")\n                \n                suggestions_pair = get_mlm_suggestions(current_sentence, [pos, pos + 1], k=3, verbose=False)\n                \n                if suggestions_pair and len(suggestions_pair) == 2:\n                    # Try all combinations of suggestions\n                    for sugg1 in suggestions_pair[0]:\n                        for sugg2 in suggestions_pair[1]:\n                            test_tokens = list(tokens)\n                            test_tokens[pos] = sugg1\n                            test_tokens[pos + 1] = sugg2\n                            test_sentence = \" \".join(test_tokens)\n                            \n                            if test_sentence in seen_sentences:\n                                continue\n                            \n                            is_valid, reason = is_sentence_fully_correct(test_sentence)\n                            \n                            if is_valid:\n                                ged_correct, ged_conf = check_sentence_correctness(test_sentence)\n                                all_valid_candidates.append({\n                                    'sentence': test_sentence,\n                                    'confidence': ged_conf,\n                                    'strategy': f\"2mask_pos{pos}-{pos+1}\",\n                                    'position': pos,\n                                    'original': f\"{tokens[pos]} {tokens[pos+1]}\",\n                                    'replacement': f\"{sugg1} {sugg2}\"\n                                })\n                                if verbose:\n                                    print(f\"         âœ… 2-mask: '{tokens[pos]} {tokens[pos+1]}' â†’ '{sugg1} {sugg2}' (conf: {ged_conf:.3f})\")\n            \n            # PHASE 3: Three-position MLM (adjacent triplets)\n            if len(tokens) > 2:\n                if verbose:\n                    print(f\"\\n   ğŸ“ PHASE 3: Testing adjacent position triplets ({len(tokens)-2} triplets)\")\n                \n                for pos in range(len(tokens) - 2):\n                    if verbose:\n                        print(f\"      Triplet [{pos},{pos+1},{pos+2}] ('{tokens[pos]}', '{tokens[pos+1]}', '{tokens[pos+2]}')\")\n                    \n                    suggestions_triple = get_mlm_suggestions(current_sentence, [pos, pos + 1, pos + 2], k=2, verbose=False)\n                    \n                    if suggestions_triple and len(suggestions_triple) == 3:\n                        # Try top combinations\n                        for sugg1 in suggestions_triple[0][:2]:\n                            for sugg2 in suggestions_triple[1][:2]:\n                                for sugg3 in suggestions_triple[2][:2]:\n                                    test_tokens = list(tokens)\n                                    test_tokens[pos] = sugg1\n                                    test_tokens[pos + 1] = sugg2\n                                    test_tokens[pos + 2] = sugg3\n                                    test_sentence = \" \".join(test_tokens)\n                                    \n                                    if test_sentence in seen_sentences:\n                                        continue\n                                    \n                                    is_valid, reason = is_sentence_fully_correct(test_sentence)\n                                    \n                                    if is_valid:\n                                        ged_correct, ged_conf = check_sentence_correctness(test_sentence)\n                                        all_valid_candidates.append({\n                                            'sentence': test_sentence,\n                                            'confidence': ged_conf,\n                                            'strategy': f\"3mask_pos{pos}-{pos+1}-{pos+2}\",\n                                            'position': pos,\n                                            'original': f\"{tokens[pos]} {tokens[pos+1]} {tokens[pos+2]}\",\n                                            'replacement': f\"{sugg1} {sugg2} {sugg3}\"\n                                        })\n                                        if verbose:\n                                            print(f\"         âœ… 3-mask: (conf: {ged_conf:.3f})\")\n            \n            # SELECT BEST CANDIDATE BY HIGHEST CONFIDENCE\n            if all_valid_candidates:\n                # Sort by confidence (descending)\n                all_valid_candidates.sort(key=lambda x: x['confidence'], reverse=True)\n                \n                best = all_valid_candidates[0]\n                \n                if verbose:\n                    print(f\"\\n   ğŸ† BEST CANDIDATE SELECTED:\")\n                    print(f\"      Strategy: {best['strategy']}\")\n                    print(f\"      Change: '{best['original']}' â†’ '{best['replacement']}'\")\n                    print(f\"      Confidence: {best['confidence']:.4f}\")\n                    print(f\"      Total valid candidates: {len(all_valid_candidates)}\")\n                    \n                    if len(all_valid_candidates) > 1:\n                        print(f\"\\n   ğŸ“Š Other candidates:\")\n                        for i, cand in enumerate(all_valid_candidates[1:6], 1):  # Show top 5\n                            print(f\"      {i}. [{cand['strategy']}] conf={cand['confidence']:.4f}\")\n                \n                current_sentence = best['sentence']\n                seen_sentences.add(current_sentence)\n                correction_history.append((iteration, best['strategy'], current_sentence))\n                \n                if verbose:\n                    print(f\"\\n   âœ… Applied best correction with confidence {best['confidence']:.4f}\")\n            else:\n                if verbose:\n                    print(f\"\\n   âŒ No valid corrections found after exhaustive search\")\n                    print(f\"      Tested {len(tokens)} single positions\")\n                    print(f\"      Tested {len(tokens)-1} position pairs\")\n                    print(f\"      Tested {max(0, len(tokens)-2)} position triplets\")\n                    print(\"âš ï¸  Stopping.\")\n                break\n            \n            continue  # Skip to next iteration\n        \n        if verbose:\n            print(f\"\\nğŸ“Š Found {len(error_predictions)} error token(s)\")\n        \n        if len(error_predictions) > previous_error_count * 1.5:\n            if verbose:\n                print(f\"âš ï¸  Error count increased significantly. Stopping.\")\n            break\n        \n        previous_error_count = len(error_predictions)\n        \n        tokens = current_sentence.split()\n        candidates = generate_correction_candidates(tokens, predictions)\n        \n        if verbose:\n            print(f\"\\nğŸ’¡ Generated {len(candidates)} correction candidate(s)\")\n        \n        best_candidate = None\n        best_strategy = None\n        \n        for candidate, strategy in candidates:\n            if candidate in seen_sentences:\n                if verbose:\n                    print(f\"   ğŸ”„ [{strategy}]: Already seen (skipping)\")\n                continue\n            \n            is_valid, reason = is_sentence_fully_correct(candidate)\n            \n            if verbose:\n                status = \"âœ…\" if is_valid else \"âŒ\"\n                print(f\"   {status} [{strategy}]: {candidate[:80]}{'...' if len(candidate) > 80 else ''}\")\n            \n            if is_valid:\n                best_candidate = candidate\n                best_strategy = strategy\n                break\n        \n        if best_candidate:\n            current_sentence = best_candidate\n            seen_sentences.add(current_sentence)\n            correction_history.append((iteration, best_strategy, current_sentence))\n            if verbose:\n                print(f\"\\nâœ“ Applied [{best_strategy}] correction\")\n        else:\n            if iteration >= MAX_CORRECTION_ITERATIONS - 1:\n                if verbose:\n                    print(f\"\\nğŸ†˜ LAST RESORT: Attempting full MLM masking...\")\n                \n                error_positions = [p['word_idx'] for p in error_predictions]\n                suggestions = get_mlm_suggestions(current_sentence, error_positions)\n                \n                if suggestions and len(suggestions) == len(error_positions):\n                    last_attempt = apply_mlm_to_positions(tokens, error_positions, suggestions)\n                    is_valid, reason = is_sentence_fully_correct(last_attempt)\n                    \n                    if verbose:\n                        status = \"âœ…\" if is_valid else \"âŒ\"\n                        print(f\"   {status} Full MLM result: {last_attempt}\")\n                    \n                    if is_valid:\n                        current_sentence = last_attempt\n                        break\n                \n                if verbose:\n                    print(f\"\\nâŒ UNABLE TO CORRECT\")\n                    print(f\"   This error pattern is too complex for the current models.\")\n                \n                if len(error_predictions) > 5:\n                    if verbose:\n                        print(f\"   Reverting to original sentence.\")\n                    current_sentence = preprocessed\n            else:\n                if candidates:\n                    candidate_errors = len([p for p in get_token_predictions(candidates[0][0]) if p['is_error']])\n                    if candidate_errors <= len(error_predictions):\n                        current_sentence = candidates[0][0]\n                        seen_sentences.add(current_sentence)\n                        if verbose:\n                            print(f\"\\nâš ï¸  Using best candidate despite validation failure\")\n                    else:\n                        if verbose:\n                            print(f\"\\nâš ï¸  Candidate would make things worse. Stopping.\")\n                        break\n    \n    final_output = postprocess_sentence(current_sentence.split())\n    \n    if verbose:\n        print(\"\\n\" + \"=\"*80)\n        print(f\"ğŸ¯ FINAL OUTPUT: {final_output}\")\n        if correction_history:\n            print(f\"ğŸ“ˆ Correction path: {' â†’ '.join([f'{s}(iter {i})' for i, s, _ in correction_history])}\")\n        print(\"=\"*80 + \"\\n\")\n    \n    return final_output\n\n# ============================================================================\n# BATCH PROCESSING\n# ============================================================================\n\ndef correct_sentences_batch(sentences: List[str], verbose: bool = False) -> List[Tuple[str, str]]:\n    \"\"\"Correct multiple sentences.\"\"\"\n    results = []\n    \n    for i, sent in enumerate(sentences, 1):\n        if verbose:\n            print(f\"\\n{'='*80}\")\n            print(f\"Processing sentence {i}/{len(sentences)}\")\n        \n        corrected = correct_sentence(sent, verbose=verbose)\n        results.append((sent, corrected))\n    \n    return results\n\n# ============================================================================\n# EXAMPLE USAGE\n# ============================================================================\n\nif __name__ == \"__main__\":\n    test_sentences = [\n        \"à¤¨à¤¾à¤® à¤®à¥‡à¤°à¥‹ à¤¦à¤¿à¤ªà¥‡à¤¶ à¤¹à¥‹ à¥¤\",\n        \"à¤® à¤¸à¥à¤•à¥à¤² à¤œà¤¾à¤¨à¥à¤›à¥ à¥¤\",\n        \"à¤¯à¥‹ à¤•à¤¿à¤¤à¤¾à¤¬ à¤®à¥‡à¤°à¥‹ à¤¹à¥‹ à¥¤\",\n        \"à¤¡à¥‹à¤œà¤° à¤ªà¤¨à¤¿ à¤®à¤¾à¤Ÿà¥‹à¤²à¥‡ à¤›à¥‹à¤ªà¤‚ à¤—à¤à¤•à¥‹ à¤› à¥¤\",\n        \"à¤•à¤¾à¤°à¥à¤¯à¤¾à¤²à¤¯à¤®à¤¾ à¤œà¤¡à¤¾à¤¨ à¤—à¤°à¤¿à¤à¤•à¤¾ à¤†à¤§à¤¾ à¤¦à¤°à¥à¤œà¤¨à¤­à¤¨à¥à¤¦à¤¾ à¤¬à¤¢à¥€ à¤•à¥à¤¯à¤¾à¤®à¥‡à¤°à¤¾à¤²à¥‡ à¤šà¥Œà¤¬à¤¿à¤¸à¥ˆ à¤˜à¤¨à¥à¤Ÿà¤¾ à¤•à¤¾à¤® à¤—à¤°à¥à¤¨ à¤¸à¤•à¥à¥€ à¤¸à¥Œà¤°à¥à¤¯ à¤Šà¤°à¥à¤œà¤¾à¤®à¤¾ à¤œà¤¡à¤¾à¤¨ à¤—à¤°à¤¿à¤à¤•à¥‹ à¤¹à¥‹à¥¤\",\n        \"à¤¤à¤¾à¤²à¤¿à¤®à¤•à¥‹ à¤²à¤¾à¤—à¤¿ à¤¬à¥‹à¤²à¤¾à¤‰à¤à¤¦à¤¾ à¤ªà¤¨à¤¿ à¤¨à¤œà¤¾à¤¨à¥‡ à¤®à¥à¤¡à¤®à¤¾ à¤¢à¥à¤•à¥à¤• à¤­à¤à¤° à¤¬à¤¸à¤¿à¤°à¤¹à¥‡à¤•à¥‹ à¤¥à¤¿à¤à¤ à¥¤\",\n        \"à¤¦à¥à¤°à¥à¤˜à¤Ÿà¤¨à¤¾à¤¬à¤¾à¤œà¤¾ à¤¬à¤œà¤¾à¤à¤° à¤†à¤‰à¤à¤¦à¥ˆà¤¨ à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ à¤¸à¤¸à¤¾à¤¨à¥‹à¤—à¤²à¥à¤¤à¥€à¤²à¥‡ à¤¹à¥à¤¨à¥‡ à¤¹à¥‹ à¥¤\",\n        \"à¤­à¥€à¤®à¤¦à¤¤à¥à¤¤ à¤¨à¤—à¤°à¤ªà¤¾à¤²à¤¿à¤•à¤¾à¤ªà¤›à¤¿ à¤ªà¥à¤°à¤¦à¥‡à¤¶ à¤¸à¤°à¤•à¤¾à¤°à¤•à¥‹ à¤¸à¤¬à¥ˆà¤­à¤¨à¥à¤¦à¤¾ à¤§à¥‡à¤°à¥ˆ à¤¬à¤œà¥‡à¤Ÿ à¤•à¥ƒà¤·à¥à¤£à¤ªà¥à¤° à¤¨à¤—à¤°à¤ªà¤¾à¤²à¤¿à¤•à¤¾à¤®à¤¾ à¤ªà¤°à¥‡à¤•à¥‹ à¥¤\",\n        \"à¤¸à¤®à¥ƒà¤¦à¥à¤§à¤¿à¤•à¤¾ à¤²à¤¾à¤—à¤¿ à¤†à¤°à¥à¤¥à¤¿à¤• à¤ªà¤¾à¤¤à¥‹ à¤¨à¥ˆ à¤®à¥à¤–à¥à¤¯ à¤¹à¥‹ à¥¤\",\n        \"à¤®à¥‡à¤°à¥‹ à¤¨à¤¾à¤® à¤¦à¤¿à¤ªà¥‡à¤¶ à¤¹à¥‹à¥¤\"\n    ]\n    \n    print(\"\\n\" + \"ğŸš€\"*40)\n    print(\"NEPALI GEC PIPELINE - WITH AGGRESSIVE MLM FALLBACK\")\n    print(\"ğŸš€\"*40)\n    \n    for sent in test_sentences:\n        corrected = correct_sentence(sent, verbose=True)\n    \n    print(\"\\n\" + \"âœ…\"*40)\n    print(\"PROCESSING COMPLETE\")\n    print(\"âœ…\"*40)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T13:06:11.987821Z","iopub.execute_input":"2025-11-15T13:06:11.988369Z","iopub.status.idle":"2025-11-15T13:06:24.926006Z","shell.execute_reply.started":"2025-11-15T13:06:11.988344Z","shell.execute_reply":"2025-11-15T13:06:24.925230Z"},"jupyter":{"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stdout","text":"ğŸ”§ Using device: cuda\nğŸ“¦ Loading models...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at DipeshChaudhary/nepali-gec-error-type-classifier were not used when initializing RobertaForTokenClassification: ['loss_fct.ce_loss.weight']\n- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"name":"stdout","text":"âœ… All models loaded successfully!\n\nğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€\nNEPALI GEC PIPELINE - WITH AGGRESSIVE MLM FALLBACK\nğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€\n\n================================================================================\nğŸ” INPUT: à¤¨à¤¾à¤® à¤®à¥‡à¤°à¥‹ à¤¦à¤¿à¤ªà¥‡à¤¶ à¤¹à¥‹ à¥¤\nğŸ”§ PREPROCESSED: à¤¨à¤¾à¤® à¤®à¥‡à¤°à¥‹ à¤¦à¤¿à¤ªà¥‡à¤¶ à¤¹à¥‹ à¥¤\n================================================================================\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 1/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ— Both models detect errors (GED: 0.893, Binary: 2 errors)\n  âš ï¸  Token 'à¤¨à¤¾à¤®' @ pos 0\n      Binary: 0.491 > 0.42\n      Primary: $APPEND (0.947)\n  âš ï¸  Token 'à¤®à¥‡à¤°à¥‹' @ pos 1\n      Binary: 0.739 > 0.42\n      Primary: $SWAP_NEXT (0.632)\n\nğŸ“Š Found 2 error token(s)\n\nğŸ’¡ Generated 3 correction candidate(s)\n   âŒ [primary_tags]: à¤¨à¤¾à¤® à¤¹à¥‹, à¤¦à¤¿à¤ªà¥‡à¤¶ à¤®à¥‡à¤°à¥‹ à¤¹à¥‹ à¥¤\n   âœ… [forced_swap]: à¤®à¥‡à¤°à¥‹ à¤¨à¤¾à¤® à¤¦à¤¿à¤ªà¥‡à¤¶ à¤¹à¥‹ à¥¤\n\nâœ“ Applied [forced_swap] correction\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 2/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ“ Both models agree (GED: 0.968)\nâœ… CORRECTION COMPLETE after 2 iteration(s)!\n\n================================================================================\nğŸ¯ FINAL OUTPUT: à¤®à¥‡à¤°à¥‹ à¤¨à¤¾à¤® à¤¦à¤¿à¤ªà¥‡à¤¶ à¤¹à¥‹à¥¤\nğŸ“ˆ Correction path: forced_swap(iter 1)\n================================================================================\n\n\n================================================================================\nğŸ” INPUT: à¤® à¤¸à¥à¤•à¥à¤² à¤œà¤¾à¤¨à¥à¤›à¥ à¥¤\nğŸ”§ PREPROCESSED: à¤® à¤¸à¥à¤•à¥à¤² à¤œà¤¾à¤¨à¥à¤›à¥ à¥¤\n================================================================================\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 1/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ“ Both models agree (GED: 0.961)\nâœ… CORRECTION COMPLETE after 1 iteration(s)!\n\n================================================================================\nğŸ¯ FINAL OUTPUT: à¤® à¤¸à¥à¤•à¥à¤² à¤œà¤¾à¤¨à¥à¤›à¥à¥¤\n================================================================================\n\n\n================================================================================\nğŸ” INPUT: à¤¯à¥‹ à¤•à¤¿à¤¤à¤¾à¤¬ à¤®à¥‡à¤°à¥‹ à¤¹à¥‹ à¥¤\nğŸ”§ PREPROCESSED: à¤¯à¥‹ à¤•à¤¿à¤¤à¤¾à¤¬ à¤®à¥‡à¤°à¥‹ à¤¹à¥‹ à¥¤\n================================================================================\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 1/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ“ Both models agree (GED: 0.663)\nâœ… CORRECTION COMPLETE after 1 iteration(s)!\n\n================================================================================\nğŸ¯ FINAL OUTPUT: à¤¯à¥‹ à¤•à¤¿à¤¤à¤¾à¤¬ à¤®à¥‡à¤°à¥‹ à¤¹à¥‹à¥¤\n================================================================================\n\n\n================================================================================\nğŸ” INPUT: à¤¡à¥‹à¤œà¤° à¤ªà¤¨à¤¿ à¤®à¤¾à¤Ÿà¥‹à¤²à¥‡ à¤›à¥‹à¤ªà¤‚ à¤—à¤à¤•à¥‹ à¤› à¥¤\nğŸ”§ PREPROCESSED: à¤¡à¥‹à¤œà¤° à¤ªà¤¨à¤¿ à¤®à¤¾à¤Ÿà¥‹à¤²à¥‡ à¤›à¥‹à¤ªà¤‚ à¤—à¤à¤•à¥‹ à¤› à¥¤\n================================================================================\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 1/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ— Both models detect errors (GED: 1.000, Binary: 1 errors)\n  âš ï¸  Token 'à¤›à¥‹à¤ªà¤‚' @ pos 3\n      Binary: 1.000 > 0.42\n      Primary: $REPLACE (1.000)\n\nğŸ“Š Found 1 error token(s)\n\nğŸ’¡ Generated 1 correction candidate(s)\n   âŒ [primary_tags]: à¤¡à¥‹à¤œà¤° à¤ªà¤¨à¤¿ à¤®à¤¾à¤Ÿà¥‹à¤²à¥‡ à¤›à¥‹à¤ªà¤¿ à¤—à¤à¤•à¥‹ à¤› à¥¤\n\nâš ï¸  Using best candidate despite validation failure\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 2/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ— Both models detect errors (GED: 0.999, Binary: 1 errors)\n  âš ï¸  Token 'à¤›à¥‹à¤ªà¤¿' @ pos 3\n      Binary: 0.998 > 0.42\n      Primary: $REPLACE (1.000)\n\nğŸ“Š Found 1 error token(s)\n\nğŸ’¡ Generated 1 correction candidate(s)\n   ğŸ”„ [primary_tags]: Already seen (skipping)\n\nâš ï¸  Using best candidate despite validation failure\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 3/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ— Both models detect errors (GED: 0.999, Binary: 1 errors)\n  âš ï¸  Token 'à¤›à¥‹à¤ªà¤¿' @ pos 3\n      Binary: 0.998 > 0.42\n      Primary: $REPLACE (1.000)\n\nğŸ“Š Found 1 error token(s)\n\nğŸ’¡ Generated 1 correction candidate(s)\n   ğŸ”„ [primary_tags]: Already seen (skipping)\n\nâš ï¸  Using best candidate despite validation failure\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 4/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ— Both models detect errors (GED: 0.999, Binary: 1 errors)\n  âš ï¸  Token 'à¤›à¥‹à¤ªà¤¿' @ pos 3\n      Binary: 0.998 > 0.42\n      Primary: $REPLACE (1.000)\n\nğŸ“Š Found 1 error token(s)\n\nğŸ’¡ Generated 1 correction candidate(s)\n   ğŸ”„ [primary_tags]: Already seen (skipping)\n\nâš ï¸  Using best candidate despite validation failure\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 5/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ— Both models detect errors (GED: 0.999, Binary: 1 errors)\n  âš ï¸  Token 'à¤›à¥‹à¤ªà¤¿' @ pos 3\n      Binary: 0.998 > 0.42\n      Primary: $REPLACE (1.000)\n\nğŸ“Š Found 1 error token(s)\n\nğŸ’¡ Generated 1 correction candidate(s)\n   ğŸ”„ [primary_tags]: Already seen (skipping)\n\nâš ï¸  Using best candidate despite validation failure\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 6/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ— Both models detect errors (GED: 0.999, Binary: 1 errors)\n  âš ï¸  Token 'à¤›à¥‹à¤ªà¤¿' @ pos 3\n      Binary: 0.998 > 0.42\n      Primary: $REPLACE (1.000)\n\nğŸ“Š Found 1 error token(s)\n\nğŸ’¡ Generated 1 correction candidate(s)\n   ğŸ”„ [primary_tags]: Already seen (skipping)\n\nâš ï¸  Using best candidate despite validation failure\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 7/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ— Both models detect errors (GED: 0.999, Binary: 1 errors)\n  âš ï¸  Token 'à¤›à¥‹à¤ªà¤¿' @ pos 3\n      Binary: 0.998 > 0.42\n      Primary: $REPLACE (1.000)\n\nğŸ“Š Found 1 error token(s)\n\nğŸ’¡ Generated 1 correction candidate(s)\n   ğŸ”„ [primary_tags]: Already seen (skipping)\n\nâš ï¸  Using best candidate despite validation failure\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 8/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ— Both models detect errors (GED: 0.999, Binary: 1 errors)\n  âš ï¸  Token 'à¤›à¥‹à¤ªà¤¿' @ pos 3\n      Binary: 0.998 > 0.42\n      Primary: $REPLACE (1.000)\n\nğŸ“Š Found 1 error token(s)\n\nğŸ’¡ Generated 1 correction candidate(s)\n   ğŸ”„ [primary_tags]: Already seen (skipping)\n\nâš ï¸  Using best candidate despite validation failure\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 9/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ— Both models detect errors (GED: 0.999, Binary: 1 errors)\n  âš ï¸  Token 'à¤›à¥‹à¤ªà¤¿' @ pos 3\n      Binary: 0.998 > 0.42\n      Primary: $REPLACE (1.000)\n\nğŸ“Š Found 1 error token(s)\n\nğŸ’¡ Generated 1 correction candidate(s)\n   ğŸ”„ [primary_tags]: Already seen (skipping)\n\nğŸ†˜ LAST RESORT: Attempting full MLM masking...\n   âŒ Full MLM result: à¤¡à¥‹à¤œà¤° à¤ªà¤¨à¤¿ à¤®à¤¾à¤Ÿà¥‹à¤²à¥‡ à¤›à¥‹à¤ªà¤¿ à¤—à¤à¤•à¥‹ à¤› à¥¤\n\nâŒ UNABLE TO CORRECT\n   This error pattern is too complex for the current models.\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 10/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ— Both models detect errors (GED: 0.999, Binary: 1 errors)\n  âš ï¸  Token 'à¤›à¥‹à¤ªà¤¿' @ pos 3\n      Binary: 0.998 > 0.42\n      Primary: $REPLACE (1.000)\n\nğŸ“Š Found 1 error token(s)\n\nğŸ’¡ Generated 1 correction candidate(s)\n   ğŸ”„ [primary_tags]: Already seen (skipping)\n\nğŸ†˜ LAST RESORT: Attempting full MLM masking...\n   âŒ Full MLM result: à¤¡à¥‹à¤œà¤° à¤ªà¤¨à¤¿ à¤®à¤¾à¤Ÿà¥‹à¤²à¥‡ à¤›à¥‹à¤ªà¤¿ à¤—à¤à¤•à¥‹ à¤› à¥¤\n\nâŒ UNABLE TO CORRECT\n   This error pattern is too complex for the current models.\n\n================================================================================\nğŸ¯ FINAL OUTPUT: à¤¡à¥‹à¤œà¤° à¤ªà¤¨à¤¿ à¤®à¤¾à¤Ÿà¥‹à¤²à¥‡ à¤›à¥‹à¤ªà¤¿ à¤—à¤à¤•à¥‹ à¤›à¥¤\n================================================================================\n\n\n================================================================================\nğŸ” INPUT: à¤•à¤¾à¤°à¥à¤¯à¤¾à¤²à¤¯à¤®à¤¾ à¤œà¤¡à¤¾à¤¨ à¤—à¤°à¤¿à¤à¤•à¤¾ à¤†à¤§à¤¾ à¤¦à¤°à¥à¤œà¤¨à¤­à¤¨à¥à¤¦à¤¾ à¤¬à¤¢à¥€ à¤•à¥à¤¯à¤¾à¤®à¥‡à¤°à¤¾à¤²à¥‡ à¤šà¥Œà¤¬à¤¿à¤¸à¥ˆ à¤˜à¤¨à¥à¤Ÿà¤¾ à¤•à¤¾à¤® à¤—à¤°à¥à¤¨ à¤¸à¤•à¥à¥€ à¤¸à¥Œà¤°à¥à¤¯ à¤Šà¤°à¥à¤œà¤¾à¤®à¤¾ à¤œà¤¡à¤¾à¤¨ à¤—à¤°à¤¿à¤à¤•à¥‹ à¤¹à¥‹à¥¤\nğŸ”§ PREPROCESSED: à¤•à¤¾à¤°à¥à¤¯à¤¾à¤²à¤¯à¤®à¤¾ à¤œà¤¡à¤¾à¤¨ à¤—à¤°à¤¿à¤à¤•à¤¾ à¤†à¤§à¤¾ à¤¦à¤°à¥à¤œà¤¨à¤­à¤¨à¥à¤¦à¤¾ à¤¬à¤¢à¥€ à¤•à¥à¤¯à¤¾à¤®à¥‡à¤°à¤¾à¤²à¥‡ à¤šà¥Œà¤¬à¤¿à¤¸à¥ˆ à¤˜à¤¨à¥à¤Ÿà¤¾ à¤•à¤¾à¤® à¤—à¤°à¥à¤¨ à¤¸à¤•à¥à¥€ à¤¸à¥Œà¤°à¥à¤¯ à¤Šà¤°à¥à¤œà¤¾à¤®à¤¾ à¤œà¤¡à¤¾à¤¨ à¤—à¤°à¤¿à¤à¤•à¥‹ à¤¹à¥‹ à¥¤\n================================================================================\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 1/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ— Both models detect errors (GED: 1.000, Binary: 3 errors)\n  âš ï¸  Token 'à¤—à¤°à¤¿à¤à¤•à¤¾' @ pos 2\n      Binary: 1.000 > 0.42\n      Primary: $SWAP_NEXT (0.999)\n  âš ï¸  Token 'à¤¸à¤•à¥à¥€' @ pos 11\n      Binary: 1.000 > 0.42\n      Primary: $REPLACE (1.000)\n  âš ï¸  Token 'à¤œà¤¡à¤¾à¤¨' @ pos 14\n      Binary: 0.999 > 0.42\n      Primary: $SWAP_PREV (0.999)\n\nğŸ“Š Found 3 error token(s)\n\nğŸ’¡ Generated 2 correction candidate(s)\n   âŒ [primary_tags]: à¤•à¤¾à¤°à¥à¤¯à¤¾à¤²à¤¯à¤®à¤¾ à¤œà¤¡à¤¾à¤¨ à¤†à¤§à¤¾ à¤—à¤°à¤¿à¤à¤•à¤¾ à¤¦à¤°à¥à¤œà¤¨à¤­à¤¨à¥à¤¦à¤¾ à¤¬à¤¢à¥€ à¤•à¥à¤¯à¤¾à¤®à¥‡à¤°à¤¾à¤²à¥‡ à¤šà¥Œà¤¬à¤¿à¤¸à¥ˆ à¤˜à¤¨à¥à¤Ÿà¤¾ à¤•à¤¾à¤® à¤—à¤°à¥à¤¨ à¤¸à¤•à¥à¤¨à¥‡...\n   âœ… [full_mlm]: à¤•à¤¾à¤°à¥à¤¯à¤¾à¤²à¤¯à¤®à¤¾ à¤œà¤¡à¤¾à¤¨ à¤—à¤°à¤¿à¤à¤•à¤¾ à¤†à¤§à¤¾ à¤¦à¤°à¥à¤œà¤¨à¤­à¤¨à¥à¤¦à¤¾ à¤¬à¤¢à¥€ à¤•à¥à¤¯à¤¾à¤®à¥‡à¤°à¤¾à¤²à¥‡ à¤šà¥Œà¤¬à¤¿à¤¸à¥ˆ à¤˜à¤¨à¥à¤Ÿà¤¾ à¤•à¤¾à¤® à¤—à¤°à¥à¤¨ à¤¸à¤•à¥à¤¨à¥‡...\n\nâœ“ Applied [full_mlm] correction\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 2/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ“ Both models agree (GED: 0.907)\nâœ… CORRECTION COMPLETE after 2 iteration(s)!\n\n================================================================================\nğŸ¯ FINAL OUTPUT: à¤•à¤¾à¤°à¥à¤¯à¤¾à¤²à¤¯à¤®à¤¾ à¤œà¤¡à¤¾à¤¨ à¤—à¤°à¤¿à¤à¤•à¤¾ à¤†à¤§à¤¾ à¤¦à¤°à¥à¤œà¤¨à¤­à¤¨à¥à¤¦à¤¾ à¤¬à¤¢à¥€ à¤•à¥à¤¯à¤¾à¤®à¥‡à¤°à¤¾à¤²à¥‡ à¤šà¥Œà¤¬à¤¿à¤¸à¥ˆ à¤˜à¤¨à¥à¤Ÿà¤¾ à¤•à¤¾à¤® à¤—à¤°à¥à¤¨ à¤¸à¤•à¥à¤¨à¥‡à¤—à¤°à¥€ à¤¸à¥Œà¤°à¥à¤¯ à¤Šà¤°à¥à¤œà¤¾à¤®à¤¾ à¤¨à¤¿à¤°à¥à¤®à¤¾à¤£ à¤—à¤°à¤¿à¤à¤•à¥‹ à¤¹à¥‹à¥¤\nğŸ“ˆ Correction path: full_mlm(iter 1)\n================================================================================\n\n\n================================================================================\nğŸ” INPUT: à¤¤à¤¾à¤²à¤¿à¤®à¤•à¥‹ à¤²à¤¾à¤—à¤¿ à¤¬à¥‹à¤²à¤¾à¤‰à¤à¤¦à¤¾ à¤ªà¤¨à¤¿ à¤¨à¤œà¤¾à¤¨à¥‡ à¤®à¥à¤¡à¤®à¤¾ à¤¢à¥à¤•à¥à¤• à¤­à¤à¤° à¤¬à¤¸à¤¿à¤°à¤¹à¥‡à¤•à¥‹ à¤¥à¤¿à¤à¤ à¥¤\nğŸ”§ PREPROCESSED: à¤¤à¤¾à¤²à¤¿à¤®à¤•à¥‹ à¤²à¤¾à¤—à¤¿ à¤¬à¥‹à¤²à¤¾à¤‰à¤à¤¦à¤¾ à¤ªà¤¨à¤¿ à¤¨à¤œà¤¾à¤¨à¥‡ à¤®à¥à¤¡à¤®à¤¾ à¤¢à¥à¤•à¥à¤• à¤­à¤à¤° à¤¬à¤¸à¤¿à¤°à¤¹à¥‡à¤•à¥‹ à¤¥à¤¿à¤à¤ à¥¤\n================================================================================\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 1/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ— GED detects error (conf: 0.557)\nâš ï¸  Binary found no errors, but GED detected issues.\nğŸ”„ Attempting AGGRESSIVE MLM on ALL token positions...\n\n   ğŸ“ PHASE 1: Testing ALL 11 positions with single/double/triple masks\n      Position 0/10 ('à¤¤à¤¾à¤²à¤¿à¤®à¤•à¥‹')\n      Position 1/10 ('à¤²à¤¾à¤—à¤¿')\n         âœ… 1-mask: 'à¤²à¤¾à¤—à¤¿' â†’ 'à¤¡à¤°,' (conf: 0.538)\n      Position 2/10 ('à¤¬à¥‹à¤²à¤¾à¤‰à¤à¤¦à¤¾')\n      Position 3/10 ('à¤ªà¤¨à¤¿')\n      Position 4/10 ('à¤¨à¤œà¤¾à¤¨à¥‡')\n      Position 5/10 ('à¤®à¥à¤¡à¤®à¤¾')\n         âœ… 1-mask: 'à¤®à¥à¤¡à¤®à¤¾' â†’ 'à¤®,' (conf: 0.809)\n         âœ… 1-mask: 'à¤®à¥à¤¡à¤®à¤¾' â†’ 'à¤­à¤¯à¥‹,' (conf: 0.590)\n         âœ… 1-mask: 'à¤®à¥à¤¡à¤®à¤¾' â†’ 'à¤­à¤¨à¥à¤¦à¤¾à¤­à¤¨à¥à¤¦à¥ˆ' (conf: 0.642)\n      Position 6/10 ('à¤¢à¥à¤•à¥à¤•')\n      Position 7/10 ('à¤­à¤à¤°')\n         âœ… 1-mask: 'à¤­à¤à¤°' â†’ 'à¤¬à¤¨à¤¾à¤à¤°' (conf: 0.562)\n      Position 8/10 ('à¤¬à¤¸à¤¿à¤°à¤¹à¥‡à¤•à¥‹')\n         âœ… 1-mask: 'à¤¬à¤¸à¤¿à¤°à¤¹à¥‡à¤•à¥‹' â†’ 'à¤¦à¤¿à¤à¤•à¥‹' (conf: 0.675)\n         âœ… 1-mask: 'à¤¬à¤¸à¤¿à¤°à¤¹à¥‡à¤•à¥‹' â†’ 'à¤®' (conf: 0.527)\n      Position 9/10 ('à¤¥à¤¿à¤à¤')\n         âœ… 1-mask: 'à¤¥à¤¿à¤à¤' â†’ 'à¤¬à¤¤à¤¾à¤‰à¤à¤›à¤¨à¥' (conf: 0.623)\n         âœ… 1-mask: 'à¤¥à¤¿à¤à¤' â†’ 'à¤¬à¤¤à¤¾à¤‰à¤à¤›à¤¿à¤¨à¥' (conf: 0.639)\n         âœ… 1-mask: 'à¤¥à¤¿à¤à¤' â†’ 'à¤¬à¤¤à¤¾à¤‰à¤›à¤¨à¥' (conf: 0.602)\n         âœ… 1-mask: 'à¤¥à¤¿à¤à¤' â†’ 'à¤­à¥‡à¤Ÿà¤¿à¤¨à¥à¤›à¤¨à¥' (conf: 0.874)\n      Position 10/10 ('à¥¤')\n         âœ… 1-mask: 'à¥¤' â†’ 'à¤®à¥¤' (conf: 0.950)\n\n   ğŸ“ PHASE 2: Testing adjacent position pairs (10 pairs)\n      Pair [0,1] ('à¤¤à¤¾à¤²à¤¿à¤®à¤•à¥‹', 'à¤²à¤¾à¤—à¤¿')\n      Pair [1,2] ('à¤²à¤¾à¤—à¤¿', 'à¤¬à¥‹à¤²à¤¾à¤‰à¤à¤¦à¤¾')\n      Pair [2,3] ('à¤¬à¥‹à¤²à¤¾à¤‰à¤à¤¦à¤¾', 'à¤ªà¤¨à¤¿')\n      Pair [3,4] ('à¤ªà¤¨à¤¿', 'à¤¨à¤œà¤¾à¤¨à¥‡')\n         âœ… 2-mask: 'à¤ªà¤¨à¤¿ à¤¨à¤œà¤¾à¤¨à¥‡' â†’ 'à¤†à¤¯à¥‹, à¤¨à¤—à¤°à¥à¤¨à¥‡' (conf: 0.508)\n      Pair [4,5] ('à¤¨à¤œà¤¾à¤¨à¥‡', 'à¤®à¥à¤¡à¤®à¤¾')\n         âœ… 2-mask: 'à¤¨à¤œà¤¾à¤¨à¥‡ à¤®à¥à¤¡à¤®à¤¾' â†’ 'à¤¨à¤—à¤°à¥à¤¨à¥‡ à¤®,' (conf: 0.688)\n         âœ… 2-mask: 'à¤¨à¤œà¤¾à¤¨à¥‡ à¤®à¥à¤¡à¤®à¤¾' â†’ 'à¤¨à¤—à¤°à¥à¤¨à¥‡ à¤­à¤¯à¥‹,' (conf: 0.633)\n      Pair [5,6] ('à¤®à¥à¤¡à¤®à¤¾', 'à¤¢à¥à¤•à¥à¤•')\n      Pair [6,7] ('à¤¢à¥à¤•à¥à¤•', 'à¤­à¤à¤°')\n         âœ… 2-mask: 'à¤¢à¥à¤•à¥à¤• à¤­à¤à¤°' â†’ 'à¤¨à¤¿ à¤®' (conf: 0.829)\n      Pair [7,8] ('à¤­à¤à¤°', 'à¤¬à¤¸à¤¿à¤°à¤¹à¥‡à¤•à¥‹')\n         âœ… 2-mask: 'à¤­à¤à¤° à¤¬à¤¸à¤¿à¤°à¤¹à¥‡à¤•à¥‹' â†’ 'à¤¬à¤¨à¤¾à¤à¤° à¤¦à¤¿à¤à¤•à¥‹' (conf: 0.803)\n         âœ… 2-mask: 'à¤­à¤à¤° à¤¬à¤¸à¤¿à¤°à¤¹à¥‡à¤•à¥‹' â†’ 'à¤¬à¤¨à¤¾à¤à¤° à¤«à¤°à¥à¤•à¤à¤¦à¥ˆ' (conf: 0.551)\n      Pair [8,9] ('à¤¬à¤¸à¤¿à¤°à¤¹à¥‡à¤•à¥‹', 'à¤¥à¤¿à¤à¤')\n         âœ… 2-mask: 'à¤¬à¤¸à¤¿à¤°à¤¹à¥‡à¤•à¥‹ à¤¥à¤¿à¤à¤' â†’ 'à¤¦à¤¿à¤à¤•à¥‹ à¤¬à¤¤à¤¾à¤‰à¤à¤›à¤¨à¥' (conf: 0.771)\n         âœ… 2-mask: 'à¤¬à¤¸à¤¿à¤°à¤¹à¥‡à¤•à¥‹ à¤¥à¤¿à¤à¤' â†’ 'à¤¦à¤¿à¤à¤•à¥‹ à¤¬à¤¤à¤¾à¤‰à¤à¤›à¤¿à¤¨à¥' (conf: 0.718)\n         âœ… 2-mask: 'à¤¬à¤¸à¤¿à¤°à¤¹à¥‡à¤•à¥‹ à¤¥à¤¿à¤à¤' â†’ 'à¤¦à¤¿à¤à¤•à¥‹ à¤¬à¤¤à¤¾à¤‰à¤›à¤¨à¥' (conf: 0.709)\n      Pair [9,10] ('à¤¥à¤¿à¤à¤', 'à¥¤')\n         âœ… 2-mask: 'à¤¥à¤¿à¤à¤ à¥¤' â†’ 'à¤¬à¤¤à¤¾à¤‰à¤à¤›à¤¨à¥ à¥¤' (conf: 0.623)\n         âœ… 2-mask: 'à¤¥à¤¿à¤à¤ à¥¤' â†’ 'à¤¬à¤¤à¤¾à¤‰à¤à¤›à¤¨à¥ à¤®à¥¤' (conf: 0.887)\n         âœ… 2-mask: 'à¤¥à¤¿à¤à¤ à¥¤' â†’ 'à¤¬à¤¤à¤¾à¤‰à¤à¤›à¤¿à¤¨à¥ à¥¤' (conf: 0.639)\n         âœ… 2-mask: 'à¤¥à¤¿à¤à¤ à¥¤' â†’ 'à¤¬à¤¤à¤¾à¤‰à¤à¤›à¤¿à¤¨à¥ à¤®à¥¤' (conf: 0.895)\n         âœ… 2-mask: 'à¤¥à¤¿à¤à¤ à¥¤' â†’ 'à¤¬à¤¤à¤¾à¤‰à¤›à¤¨à¥ à¥¤' (conf: 0.602)\n         âœ… 2-mask: 'à¤¥à¤¿à¤à¤ à¥¤' â†’ 'à¤¬à¤¤à¤¾à¤‰à¤›à¤¨à¥ à¤®à¥¤' (conf: 0.877)\n\n   ğŸ“ PHASE 3: Testing adjacent position triplets (9 triplets)\n      Triplet [0,1,2] ('à¤¤à¤¾à¤²à¤¿à¤®à¤•à¥‹', 'à¤²à¤¾à¤—à¤¿', 'à¤¬à¥‹à¤²à¤¾à¤‰à¤à¤¦à¤¾')\n      Triplet [1,2,3] ('à¤²à¤¾à¤—à¤¿', 'à¤¬à¥‹à¤²à¤¾à¤‰à¤à¤¦à¤¾', 'à¤ªà¤¨à¤¿')\n      Triplet [2,3,4] ('à¤¬à¥‹à¤²à¤¾à¤‰à¤à¤¦à¤¾', 'à¤ªà¤¨à¤¿', 'à¤¨à¤œà¤¾à¤¨à¥‡')\n      Triplet [3,4,5] ('à¤ªà¤¨à¤¿', 'à¤¨à¤œà¤¾à¤¨à¥‡', 'à¤®à¥à¤¡à¤®à¤¾')\n      Triplet [4,5,6] ('à¤¨à¤œà¤¾à¤¨à¥‡', 'à¤®à¥à¤¡à¤®à¤¾', 'à¤¢à¥à¤•à¥à¤•')\n      Triplet [5,6,7] ('à¤®à¥à¤¡à¤®à¤¾', 'à¤¢à¥à¤•à¥à¤•', 'à¤­à¤à¤°')\n      Triplet [6,7,8] ('à¤¢à¥à¤•à¥à¤•', 'à¤­à¤à¤°', 'à¤¬à¤¸à¤¿à¤°à¤¹à¥‡à¤•à¥‹')\n         âœ… 3-mask: (conf: 0.617)\n         âœ… 3-mask: (conf: 0.654)\n         âœ… 3-mask: (conf: 0.576)\n      Triplet [7,8,9] ('à¤­à¤à¤°', 'à¤¬à¤¸à¤¿à¤°à¤¹à¥‡à¤•à¥‹', 'à¤¥à¤¿à¤à¤')\n         âœ… 3-mask: (conf: 0.824)\n         âœ… 3-mask: (conf: 0.804)\n      Triplet [8,9,10] ('à¤¬à¤¸à¤¿à¤°à¤¹à¥‡à¤•à¥‹', 'à¤¥à¤¿à¤à¤', 'à¥¤')\n         âœ… 3-mask: (conf: 0.771)\n         âœ… 3-mask: (conf: 0.853)\n         âœ… 3-mask: (conf: 0.718)\n         âœ… 3-mask: (conf: 0.802)\n\n   ğŸ† BEST CANDIDATE SELECTED:\n      Strategy: 1mask_pos10\n      Change: 'à¥¤' â†’ 'à¤®à¥¤'\n      Confidence: 0.9497\n      Total valid candidates: 36\n\n   ğŸ“Š Other candidates:\n      1. [2mask_pos9-10] conf=0.8947\n      2. [2mask_pos9-10] conf=0.8871\n      3. [2mask_pos9-10] conf=0.8772\n      4. [1mask_pos9] conf=0.8738\n      5. [3mask_pos8-9-10] conf=0.8533\n\n   âœ… Applied best correction with confidence 0.9497\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 2/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ“ Both models agree (GED: 0.950)\nâœ… CORRECTION COMPLETE after 2 iteration(s)!\n\n================================================================================\nğŸ¯ FINAL OUTPUT: à¤¤à¤¾à¤²à¤¿à¤®à¤•à¥‹ à¤²à¤¾à¤—à¤¿ à¤¬à¥‹à¤²à¤¾à¤‰à¤à¤¦à¤¾ à¤ªà¤¨à¤¿ à¤¨à¤œà¤¾à¤¨à¥‡ à¤®à¥à¤¡à¤®à¤¾ à¤¢à¥à¤•à¥à¤• à¤­à¤à¤° à¤¬à¤¸à¤¿à¤°à¤¹à¥‡à¤•à¥‹ à¤¥à¤¿à¤à¤ à¤®à¥¤\nğŸ“ˆ Correction path: 1mask_pos10(iter 1)\n================================================================================\n\n\n================================================================================\nğŸ” INPUT: à¤¦à¥à¤°à¥à¤˜à¤Ÿà¤¨à¤¾à¤¬à¤¾à¤œà¤¾ à¤¬à¤œà¤¾à¤à¤° à¤†à¤‰à¤à¤¦à¥ˆà¤¨ à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ à¤¸à¤¸à¤¾à¤¨à¥‹à¤—à¤²à¥à¤¤à¥€à¤²à¥‡ à¤¹à¥à¤¨à¥‡ à¤¹à¥‹ à¥¤\nğŸ”§ PREPROCESSED: à¤¦à¥à¤°à¥à¤˜à¤Ÿà¤¨à¤¾à¤¬à¤¾à¤œà¤¾ à¤¬à¤œà¤¾à¤à¤° à¤†à¤‰à¤à¤¦à¥ˆà¤¨ à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ à¤¸à¤¸à¤¾à¤¨à¥‹à¤—à¤²à¥à¤¤à¥€à¤²à¥‡ à¤¹à¥à¤¨à¥‡ à¤¹à¥‹ à¥¤\n================================================================================\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 1/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ— GED detects error (conf: 0.831)\nâš ï¸  Binary found no errors, but GED detected issues.\nğŸ”„ Attempting AGGRESSIVE MLM on ALL token positions...\n\n   ğŸ“ PHASE 1: Testing ALL 8 positions with single/double/triple masks\n      Position 0/7 ('à¤¦à¥à¤°à¥à¤˜à¤Ÿà¤¨à¤¾à¤¬à¤¾à¤œà¤¾')\n      Position 1/7 ('à¤¬à¤œà¤¾à¤à¤°')\n      Position 2/7 ('à¤†à¤‰à¤à¤¦à¥ˆà¤¨')\n         âœ… 1-mask: 'à¤†à¤‰à¤à¤¦à¥ˆà¤¨' â†’ 'à¤¹à¥‹à¤‡à¤¨,' (conf: 0.906)\n         âœ… 1-mask: 'à¤†à¤‰à¤à¤¦à¥ˆà¤¨' â†’ 'à¤¹à¥ˆà¤¨,' (conf: 0.895)\n         âœ… 1-mask: 'à¤†à¤‰à¤à¤¦à¥ˆà¤¨' â†’ 'à¤¹à¥à¤à¤¦à¥ˆà¤¨,' (conf: 0.887)\n         âœ… 1-mask: 'à¤†à¤‰à¤à¤¦à¥ˆà¤¨' â†’ '-' (conf: 0.517)\n      Position 3/7 ('à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ')\n         âœ… 1-mask: 'à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ' â†’ 'à¤¤à¤°,' (conf: 0.781)\n         âœ… 1-mask: 'à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ' â†’ 'à¤°,' (conf: 0.851)\n         âœ… 1-mask: 'à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ' â†’ 'à¥¤' (conf: 0.821)\n         âœ… 1-mask: 'à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ' â†’ 'à¤¨à¤¿,' (conf: 0.673)\n      Position 4/7 ('à¤¸à¤¸à¤¾à¤¨à¥‹à¤—à¤²à¥à¤¤à¥€à¤²à¥‡')\n      Position 5/7 ('à¤¹à¥à¤¨à¥‡')\n      Position 6/7 ('à¤¹à¥‹')\n      Position 7/7 ('à¥¤')\n\n   ğŸ“ PHASE 2: Testing adjacent position pairs (7 pairs)\n      Pair [0,1] ('à¤¦à¥à¤°à¥à¤˜à¤Ÿà¤¨à¤¾à¤¬à¤¾à¤œà¤¾', 'à¤¬à¤œà¤¾à¤à¤°')\n         âœ… 2-mask: 'à¤¦à¥à¤°à¥à¤˜à¤Ÿà¤¨à¤¾à¤¬à¤¾à¤œà¤¾ à¤¬à¤œà¤¾à¤à¤°' â†’ 'à¤œà¥à¤¨ à¤†à¤‰à¤à¤¦à¥ˆà¤¨,' (conf: 0.588)\n      Pair [1,2] ('à¤¬à¤œà¤¾à¤à¤°', 'à¤†à¤‰à¤à¤¦à¥ˆà¤¨')\n      Pair [2,3] ('à¤†à¤‰à¤à¤¦à¥ˆà¤¨', 'à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ')\n         âœ… 2-mask: 'à¤†à¤‰à¤à¤¦à¥ˆà¤¨ à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ' â†’ 'à¤¹à¥‹à¤‡à¤¨, à¤¤à¤°,' (conf: 0.844)\n         âœ… 2-mask: 'à¤†à¤‰à¤à¤¦à¥ˆà¤¨ à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ' â†’ 'à¤¹à¥‹à¤‡à¤¨, à¤°,' (conf: 0.867)\n         âœ… 2-mask: 'à¤†à¤‰à¤à¤¦à¥ˆà¤¨ à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ' â†’ 'à¤¹à¥ˆà¤¨, à¤¤à¤°,' (conf: 0.818)\n         âœ… 2-mask: 'à¤†à¤‰à¤à¤¦à¥ˆà¤¨ à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ' â†’ 'à¤¹à¥ˆà¤¨, à¤°,' (conf: 0.837)\n         âœ… 2-mask: 'à¤†à¤‰à¤à¤¦à¥ˆà¤¨ à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ' â†’ 'à¤¹à¥à¤à¤¦à¥ˆà¤¨, à¤¤à¤°,' (conf: 0.811)\n         âœ… 2-mask: 'à¤†à¤‰à¤à¤¦à¥ˆà¤¨ à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ' â†’ 'à¤¹à¥à¤à¤¦à¥ˆà¤¨, à¤°,' (conf: 0.847)\n      Pair [3,4] ('à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ', 'à¤¸à¤¸à¤¾à¤¨à¥‹à¤—à¤²à¥à¤¤à¥€à¤²à¥‡')\n         âœ… 2-mask: 'à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ à¤¸à¤¸à¤¾à¤¨à¥‹à¤—à¤²à¥à¤¤à¥€à¤²à¥‡' â†’ 'à¤¤à¤°, à¤ªà¤°à¤¿à¤£à¤¾à¤®' (conf: 0.581)\n         âœ… 2-mask: 'à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ à¤¸à¤¸à¤¾à¤¨à¥‹à¤—à¤²à¥à¤¤à¥€à¤²à¥‡' â†’ 'à¤°, à¤ªà¤°à¤¿à¤£à¤¾à¤®' (conf: 0.712)\n      Pair [4,5] ('à¤¸à¤¸à¤¾à¤¨à¥‹à¤—à¤²à¥à¤¤à¥€à¤²à¥‡', 'à¤¹à¥à¤¨à¥‡')\n      Pair [5,6] ('à¤¹à¥à¤¨à¥‡', 'à¤¹à¥‹')\n      Pair [6,7] ('à¤¹à¥‹', 'à¥¤')\n\n   ğŸ“ PHASE 3: Testing adjacent position triplets (6 triplets)\n      Triplet [0,1,2] ('à¤¦à¥à¤°à¥à¤˜à¤Ÿà¤¨à¤¾à¤¬à¤¾à¤œà¤¾', 'à¤¬à¤œà¤¾à¤à¤°', 'à¤†à¤‰à¤à¤¦à¥ˆà¤¨')\n         âœ… 3-mask: (conf: 0.563)\n         âœ… 3-mask: (conf: 0.579)\n         âœ… 3-mask: (conf: 0.625)\n      Triplet [1,2,3] ('à¤¬à¤œà¤¾à¤à¤°', 'à¤†à¤‰à¤à¤¦à¥ˆà¤¨', 'à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ')\n      Triplet [2,3,4] ('à¤†à¤‰à¤à¤¦à¥ˆà¤¨', 'à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ', 'à¤¸à¤¸à¤¾à¤¨à¥‹à¤—à¤²à¥à¤¤à¥€à¤²à¥‡')\n      Triplet [3,4,5] ('à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ', 'à¤¸à¤¸à¤¾à¤¨à¥‹à¤—à¤²à¥à¤¤à¥€à¤²à¥‡', 'à¤¹à¥à¤¨à¥‡')\n      Triplet [4,5,6] ('à¤¸à¤¸à¤¾à¤¨à¥‹à¤—à¤²à¥à¤¤à¥€à¤²à¥‡', 'à¤¹à¥à¤¨à¥‡', 'à¤¹à¥‹')\n      Triplet [5,6,7] ('à¤¹à¥à¤¨à¥‡', 'à¤¹à¥‹', 'à¥¤')\n\n   ğŸ† BEST CANDIDATE SELECTED:\n      Strategy: 1mask_pos2\n      Change: 'à¤†à¤‰à¤à¤¦à¥ˆà¤¨' â†’ 'à¤¹à¥‹à¤‡à¤¨,'\n      Confidence: 0.9056\n      Total valid candidates: 20\n\n   ğŸ“Š Other candidates:\n      1. [1mask_pos2] conf=0.8949\n      2. [1mask_pos2] conf=0.8866\n      3. [2mask_pos2-3] conf=0.8672\n      4. [1mask_pos3] conf=0.8513\n      5. [2mask_pos2-3] conf=0.8474\n\n   âœ… Applied best correction with confidence 0.9056\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 2/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ“ Both models agree (GED: 0.906)\nâœ… CORRECTION COMPLETE after 2 iteration(s)!\n\n================================================================================\nğŸ¯ FINAL OUTPUT: à¤¦à¥à¤°à¥à¤˜à¤Ÿà¤¨à¤¾à¤¬à¤¾à¤œà¤¾ à¤¬à¤œà¤¾à¤à¤° à¤¹à¥‹à¤‡à¤¨, à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ à¤¸à¤¸à¤¾à¤¨à¥‹à¤—à¤²à¥à¤¤à¥€à¤²à¥‡ à¤¹à¥à¤¨à¥‡ à¤¹à¥‹à¥¤\nğŸ“ˆ Correction path: 1mask_pos2(iter 1)\n================================================================================\n\n\n================================================================================\nğŸ” INPUT: à¤­à¥€à¤®à¤¦à¤¤à¥à¤¤ à¤¨à¤—à¤°à¤ªà¤¾à¤²à¤¿à¤•à¤¾à¤ªà¤›à¤¿ à¤ªà¥à¤°à¤¦à¥‡à¤¶ à¤¸à¤°à¤•à¤¾à¤°à¤•à¥‹ à¤¸à¤¬à¥ˆà¤­à¤¨à¥à¤¦à¤¾ à¤§à¥‡à¤°à¥ˆ à¤¬à¤œà¥‡à¤Ÿ à¤•à¥ƒà¤·à¥à¤£à¤ªà¥à¤° à¤¨à¤—à¤°à¤ªà¤¾à¤²à¤¿à¤•à¤¾à¤®à¤¾ à¤ªà¤°à¥‡à¤•à¥‹ à¥¤\nğŸ”§ PREPROCESSED: à¤­à¥€à¤®à¤¦à¤¤à¥à¤¤ à¤¨à¤—à¤°à¤ªà¤¾à¤²à¤¿à¤•à¤¾à¤ªà¤›à¤¿ à¤ªà¥à¤°à¤¦à¥‡à¤¶ à¤¸à¤°à¤•à¤¾à¤°à¤•à¥‹ à¤¸à¤¬à¥ˆà¤­à¤¨à¥à¤¦à¤¾ à¤§à¥‡à¤°à¥ˆ à¤¬à¤œà¥‡à¤Ÿ à¤•à¥ƒà¤·à¥à¤£à¤ªà¥à¤° à¤¨à¤—à¤°à¤ªà¤¾à¤²à¤¿à¤•à¤¾à¤®à¤¾ à¤ªà¤°à¥‡à¤•à¥‹ à¥¤\n================================================================================\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 1/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ— Both models detect errors (GED: 1.000, Binary: 1 errors)\n  âš ï¸  Token 'à¤ªà¤°à¥‡à¤•à¥‹' @ pos 9\n      Binary: 0.999 > 0.42\n      Primary: $APPEND (1.000)\n\nğŸ“Š Found 1 error token(s)\n\nğŸ’¡ Generated 1 correction candidate(s)\n   âœ… [primary_tags]: à¤­à¥€à¤®à¤¦à¤¤à¥à¤¤ à¤¨à¤—à¤°à¤ªà¤¾à¤²à¤¿à¤•à¤¾à¤ªà¤›à¤¿ à¤ªà¥à¤°à¤¦à¥‡à¤¶ à¤¸à¤°à¤•à¤¾à¤°à¤•à¥‹ à¤¸à¤¬à¥ˆà¤­à¤¨à¥à¤¦à¤¾ à¤§à¥‡à¤°à¥ˆ à¤¬à¤œà¥‡à¤Ÿ à¤•à¥ƒà¤·à¥à¤£à¤ªà¥à¤° à¤¨à¤—à¤°à¤ªà¤¾à¤²à¤¿à¤•à¤¾à¤®à¤¾ à¤ªà¤°à¥‡à¤•...\n\nâœ“ Applied [primary_tags] correction\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 2/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ“ Both models agree (GED: 0.985)\nâœ… CORRECTION COMPLETE after 2 iteration(s)!\n\n================================================================================\nğŸ¯ FINAL OUTPUT: à¤­à¥€à¤®à¤¦à¤¤à¥à¤¤ à¤¨à¤—à¤°à¤ªà¤¾à¤²à¤¿à¤•à¤¾à¤ªà¤›à¤¿ à¤ªà¥à¤°à¤¦à¥‡à¤¶ à¤¸à¤°à¤•à¤¾à¤°à¤•à¥‹ à¤¸à¤¬à¥ˆà¤­à¤¨à¥à¤¦à¤¾ à¤§à¥‡à¤°à¥ˆ à¤¬à¤œà¥‡à¤Ÿ à¤•à¥ƒà¤·à¥à¤£à¤ªà¥à¤° à¤¨à¤—à¤°à¤ªà¤¾à¤²à¤¿à¤•à¤¾à¤®à¤¾ à¤ªà¤°à¥‡à¤•à¥‹ à¤›à¥¤à¥¤\nğŸ“ˆ Correction path: primary_tags(iter 1)\n================================================================================\n\n\n================================================================================\nğŸ” INPUT: à¤¸à¤®à¥ƒà¤¦à¥à¤§à¤¿à¤•à¤¾ à¤²à¤¾à¤—à¤¿ à¤†à¤°à¥à¤¥à¤¿à¤• à¤ªà¤¾à¤¤à¥‹ à¤¨à¥ˆ à¤®à¥à¤–à¥à¤¯ à¤¹à¥‹ à¥¤\nğŸ”§ PREPROCESSED: à¤¸à¤®à¥ƒà¤¦à¥à¤§à¤¿à¤•à¤¾ à¤²à¤¾à¤—à¤¿ à¤†à¤°à¥à¤¥à¤¿à¤• à¤ªà¤¾à¤¤à¥‹ à¤¨à¥ˆ à¤®à¥à¤–à¥à¤¯ à¤¹à¥‹ à¥¤\n================================================================================\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 1/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ— Both models detect errors (GED: 1.000, Binary: 1 errors)\n  âš ï¸  Token 'à¤ªà¤¾à¤¤à¥‹' @ pos 3\n      Binary: 0.993 > 0.42\n      Primary: $REPLACE (0.997)\n\nğŸ“Š Found 1 error token(s)\n\nğŸ’¡ Generated 1 correction candidate(s)\n   âœ… [primary_tags]: à¤¸à¤®à¥ƒà¤¦à¥à¤§à¤¿à¤•à¤¾ à¤²à¤¾à¤—à¤¿ à¤†à¤°à¥à¤¥à¤¿à¤• à¤¨à¤¿à¤°à¥à¤®à¤¾à¤£ à¤¨à¥ˆ à¤®à¥à¤–à¥à¤¯ à¤¹à¥‹ à¥¤\n\nâœ“ Applied [primary_tags] correction\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 2/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ“ Both models agree (GED: 0.857)\nâœ… CORRECTION COMPLETE after 2 iteration(s)!\n\n================================================================================\nğŸ¯ FINAL OUTPUT: à¤¸à¤®à¥ƒà¤¦à¥à¤§à¤¿à¤•à¤¾ à¤²à¤¾à¤—à¤¿ à¤†à¤°à¥à¤¥à¤¿à¤• à¤¨à¤¿à¤°à¥à¤®à¤¾à¤£ à¤¨à¥ˆ à¤®à¥à¤–à¥à¤¯ à¤¹à¥‹à¥¤\nğŸ“ˆ Correction path: primary_tags(iter 1)\n================================================================================\n\n\n================================================================================\nğŸ” INPUT: à¤®à¥‡à¤°à¥‹ à¤¨à¤¾à¤® à¤¦à¤¿à¤ªà¥‡à¤¶ à¤¹à¥‹à¥¤\nğŸ”§ PREPROCESSED: à¤®à¥‡à¤°à¥‹ à¤¨à¤¾à¤® à¤¦à¤¿à¤ªà¥‡à¤¶ à¤¹à¥‹ à¥¤\n================================================================================\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 1/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ“ Both models agree (GED: 0.968)\nâœ… CORRECTION COMPLETE after 1 iteration(s)!\n\n================================================================================\nğŸ¯ FINAL OUTPUT: à¤®à¥‡à¤°à¥‹ à¤¨à¤¾à¤® à¤¦à¤¿à¤ªà¥‡à¤¶ à¤¹à¥‹à¥¤\n================================================================================\n\n\nâœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…\nPROCESSING COMPLETE\nâœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…\n","output_type":"stream"}],"execution_count":69},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    test_sentences = [\n        \"à¤¨à¤¾à¤® à¤®à¥‡à¤°à¥‹ à¤¦à¤¿à¤ªà¥‡à¤¶ à¤¹à¥‹ à¥¤\",\n        \"à¤® à¤¸à¥à¤•à¥à¤² à¤œà¤¾à¤¨à¥à¤›à¥ à¥¤\",\n        \"à¤¯à¥‹ à¤•à¤¿à¤¤à¤¾à¤¬ à¤®à¥‡à¤°à¥‹ à¤¹à¥‹ à¥¤\",\n        \"à¤¡à¥‹à¤œà¤° à¤ªà¤¨à¤¿ à¤®à¤¾à¤Ÿà¥‹à¤²à¥‡ à¤›à¥‹à¤ªà¤‚ à¤—à¤à¤•à¥‹ à¤› à¥¤\",\n        \"à¤•à¤¾à¤°à¥à¤¯à¤¾à¤²à¤¯à¤®à¤¾ à¤œà¤¡à¤¾à¤¨ à¤—à¤°à¤¿à¤à¤•à¤¾ à¤†à¤§à¤¾ à¤¦à¤°à¥à¤œà¤¨à¤­à¤¨à¥à¤¦à¤¾ à¤¬à¤¢à¥€ à¤•à¥à¤¯à¤¾à¤®à¥‡à¤°à¤¾à¤²à¥‡ à¤šà¥Œà¤¬à¤¿à¤¸à¥ˆ à¤˜à¤¨à¥à¤Ÿà¤¾ à¤•à¤¾à¤® à¤—à¤°à¥à¤¨ à¤¸à¤•à¥à¥€ à¤¸à¥Œà¤°à¥à¤¯ à¤Šà¤°à¥à¤œà¤¾à¤®à¤¾ à¤œà¤¡à¤¾à¤¨ à¤—à¤°à¤¿à¤à¤•à¥‹ à¤¹à¥‹à¥¤\",\n        \"à¤¤à¤¾à¤²à¤¿à¤®à¤•à¥‹ à¤²à¤¾à¤—à¤¿ à¤¬à¥‹à¤²à¤¾à¤‰à¤à¤¦à¤¾ à¤ªà¤¨à¤¿ à¤¨à¤œà¤¾à¤¨à¥‡ à¤®à¥à¤¡à¤®à¤¾ à¤¢à¥à¤•à¥à¤• à¤­à¤à¤° à¤¬à¤¸à¤¿à¤°à¤¹à¥‡à¤•à¥‹ à¤¥à¤¿à¤à¤ à¥¤\",\n        \"à¤¦à¥à¤°à¥à¤˜à¤Ÿà¤¨à¤¾à¤¬à¤¾à¤œà¤¾ à¤¬à¤œà¤¾à¤à¤° à¤†à¤‰à¤à¤¦à¥ˆà¤¨ à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ à¤¸à¤¸à¤¾à¤¨à¥‹à¤—à¤²à¥à¤¤à¥€à¤²à¥‡ à¤¹à¥à¤¨à¥‡ à¤¹à¥‹ à¥¤\",\n        \"à¤­à¥€à¤®à¤¦à¤¤à¥à¤¤ à¤¨à¤—à¤°à¤ªà¤¾à¤²à¤¿à¤•à¤¾à¤ªà¤›à¤¿ à¤ªà¥à¤°à¤¦à¥‡à¤¶ à¤¸à¤°à¤•à¤¾à¤°à¤•à¥‹ à¤¸à¤¬à¥ˆà¤­à¤¨à¥à¤¦à¤¾ à¤§à¥‡à¤°à¥ˆ à¤¬à¤œà¥‡à¤Ÿ à¤•à¥ƒà¤·à¥à¤£à¤ªà¥à¤° à¤¨à¤—à¤°à¤ªà¤¾à¤²à¤¿à¤•à¤¾à¤®à¤¾ à¤ªà¤°à¥‡à¤•à¥‹ à¥¤\",\n        \"à¤¸à¤®à¥ƒà¤¦à¥à¤§à¤¿à¤•à¤¾ à¤²à¤¾à¤—à¤¿ à¤†à¤°à¥à¤¥à¤¿à¤• à¤ªà¤¾à¤¤à¥‹ à¤¨à¥ˆ à¤®à¥à¤–à¥à¤¯ à¤¹à¥‹ à¥¤\",\n        \"à¤®à¥‡à¤°à¥‹ à¤¨à¤¾à¤® à¤¦à¤¿à¤ªà¥‡à¤¶ à¤¹à¥‹\"\n    ]\n    \n    print(\"\\n\" + \"ğŸš€\"*40)\n    print(\"NEPALI GEC PIPELINE - WITH AGGRESSIVE MLM FALLBACK\")\n    print(\"ğŸš€\"*40)\n    pairs = []\n    \n    for sent in test_sentences:\n        corrected = correct_sentence(sent, verbose=True)\n        pairs.append((sent, corrected))   # store pair\n    \n    print(\"\\n\" + \"âœ…\"*40)\n    print(\"PROCESSING COMPLETE\")\n    print(\"âœ…\"*40)\n    print(\"\\n\" + \"âœ…\"*40)\n    print(\"PROCESSING COMPLETE\")\n    print(\"âœ…\"*40)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T13:40:22.553107Z","iopub.execute_input":"2025-11-15T13:40:22.553826Z","iopub.status.idle":"2025-11-15T13:40:33.407008Z","shell.execute_reply.started":"2025-11-15T13:40:22.553801Z","shell.execute_reply":"2025-11-15T13:40:33.406378Z"}},"outputs":[{"name":"stdout","text":"\nğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€\nNEPALI GEC PIPELINE - WITH AGGRESSIVE MLM FALLBACK\nğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€\n\n================================================================================\nğŸ” INPUT: à¤¨à¤¾à¤® à¤®à¥‡à¤°à¥‹ à¤¦à¤¿à¤ªà¥‡à¤¶ à¤¹à¥‹ à¥¤\nğŸ”§ PREPROCESSED: à¤¨à¤¾à¤® à¤®à¥‡à¤°à¥‹ à¤¦à¤¿à¤ªà¥‡à¤¶ à¤¹à¥‹ à¥¤\n================================================================================\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 1/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ— Both models detect errors (GED: 0.893, Binary: 2 errors)\n  âš ï¸  Token 'à¤¨à¤¾à¤®' @ pos 0\n      Binary: 0.491 > 0.42\n      Primary: $APPEND (0.947)\n  âš ï¸  Token 'à¤®à¥‡à¤°à¥‹' @ pos 1\n      Binary: 0.739 > 0.42\n      Primary: $SWAP_NEXT (0.632)\n\nğŸ“Š Found 2 error token(s)\n\nğŸ’¡ Generated 3 correction candidate(s)\n   âŒ [primary_tags]: à¤¨à¤¾à¤® à¤¹à¥‹, à¤¦à¤¿à¤ªà¥‡à¤¶ à¤®à¥‡à¤°à¥‹ à¤¹à¥‹ à¥¤\n   âœ… [forced_swap]: à¤®à¥‡à¤°à¥‹ à¤¨à¤¾à¤® à¤¦à¤¿à¤ªà¥‡à¤¶ à¤¹à¥‹ à¥¤\n\nâœ“ Applied [forced_swap] correction\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 2/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ“ Both models agree (GED: 0.968)\nâœ… CORRECTION COMPLETE after 2 iteration(s)!\n\n================================================================================\nğŸ¯ FINAL OUTPUT: à¤®à¥‡à¤°à¥‹ à¤¨à¤¾à¤® à¤¦à¤¿à¤ªà¥‡à¤¶ à¤¹à¥‹à¥¤\nğŸ“ˆ Correction path: forced_swap(iter 1)\n================================================================================\n\n\n================================================================================\nğŸ” INPUT: à¤® à¤¸à¥à¤•à¥à¤² à¤œà¤¾à¤¨à¥à¤›à¥ à¥¤\nğŸ”§ PREPROCESSED: à¤® à¤¸à¥à¤•à¥à¤² à¤œà¤¾à¤¨à¥à¤›à¥ à¥¤\n================================================================================\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 1/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ“ Both models agree (GED: 0.961)\nâœ… CORRECTION COMPLETE after 1 iteration(s)!\n\n================================================================================\nğŸ¯ FINAL OUTPUT: à¤® à¤¸à¥à¤•à¥à¤² à¤œà¤¾à¤¨à¥à¤›à¥à¥¤\n================================================================================\n\n\n================================================================================\nğŸ” INPUT: à¤¯à¥‹ à¤•à¤¿à¤¤à¤¾à¤¬ à¤®à¥‡à¤°à¥‹ à¤¹à¥‹ à¥¤\nğŸ”§ PREPROCESSED: à¤¯à¥‹ à¤•à¤¿à¤¤à¤¾à¤¬ à¤®à¥‡à¤°à¥‹ à¤¹à¥‹ à¥¤\n================================================================================\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 1/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ“ Both models agree (GED: 0.663)\nâœ… CORRECTION COMPLETE after 1 iteration(s)!\n\n================================================================================\nğŸ¯ FINAL OUTPUT: à¤¯à¥‹ à¤•à¤¿à¤¤à¤¾à¤¬ à¤®à¥‡à¤°à¥‹ à¤¹à¥‹à¥¤\n================================================================================\n\n\n================================================================================\nğŸ” INPUT: à¤¡à¥‹à¤œà¤° à¤ªà¤¨à¤¿ à¤®à¤¾à¤Ÿà¥‹à¤²à¥‡ à¤›à¥‹à¤ªà¤‚ à¤—à¤à¤•à¥‹ à¤› à¥¤\nğŸ”§ PREPROCESSED: à¤¡à¥‹à¤œà¤° à¤ªà¤¨à¤¿ à¤®à¤¾à¤Ÿà¥‹à¤²à¥‡ à¤›à¥‹à¤ªà¤‚ à¤—à¤à¤•à¥‹ à¤› à¥¤\n================================================================================\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 1/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ— Both models detect errors (GED: 1.000, Binary: 1 errors)\n  âš ï¸  Token 'à¤›à¥‹à¤ªà¤‚' @ pos 3\n      Binary: 1.000 > 0.42\n      Primary: $REPLACE (1.000)\n\nğŸ“Š Found 1 error token(s)\n\nğŸ’¡ Generated 1 correction candidate(s)\n   âŒ [primary_tags]: à¤¡à¥‹à¤œà¤° à¤ªà¤¨à¤¿ à¤®à¤¾à¤Ÿà¥‹à¤²à¥‡ à¤›à¥‹à¤ªà¤¿ à¤—à¤à¤•à¥‹ à¤› à¥¤\n\nâš ï¸  Using best candidate despite validation failure\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 2/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ— Both models detect errors (GED: 0.999, Binary: 1 errors)\n  âš ï¸  Token 'à¤›à¥‹à¤ªà¤¿' @ pos 3\n      Binary: 0.998 > 0.42\n      Primary: $REPLACE (1.000)\n\nğŸ“Š Found 1 error token(s)\n\nğŸ’¡ Generated 1 correction candidate(s)\n   ğŸ”„ [primary_tags]: Already seen (skipping)\n\nâš ï¸  Using best candidate despite validation failure\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 3/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ— Both models detect errors (GED: 0.999, Binary: 1 errors)\n  âš ï¸  Token 'à¤›à¥‹à¤ªà¤¿' @ pos 3\n      Binary: 0.998 > 0.42\n      Primary: $REPLACE (1.000)\n\nğŸ“Š Found 1 error token(s)\n\nğŸ’¡ Generated 1 correction candidate(s)\n   ğŸ”„ [primary_tags]: Already seen (skipping)\n\nâš ï¸  Using best candidate despite validation failure\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 4/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ— Both models detect errors (GED: 0.999, Binary: 1 errors)\n  âš ï¸  Token 'à¤›à¥‹à¤ªà¤¿' @ pos 3\n      Binary: 0.998 > 0.42\n      Primary: $REPLACE (1.000)\n\nğŸ“Š Found 1 error token(s)\n\nğŸ’¡ Generated 1 correction candidate(s)\n   ğŸ”„ [primary_tags]: Already seen (skipping)\n\nâš ï¸  Using best candidate despite validation failure\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 5/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ— Both models detect errors (GED: 0.999, Binary: 1 errors)\n  âš ï¸  Token 'à¤›à¥‹à¤ªà¤¿' @ pos 3\n      Binary: 0.998 > 0.42\n      Primary: $REPLACE (1.000)\n\nğŸ“Š Found 1 error token(s)\n\nğŸ’¡ Generated 1 correction candidate(s)\n   ğŸ”„ [primary_tags]: Already seen (skipping)\n\nâš ï¸  Using best candidate despite validation failure\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 6/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ— Both models detect errors (GED: 0.999, Binary: 1 errors)\n  âš ï¸  Token 'à¤›à¥‹à¤ªà¤¿' @ pos 3\n      Binary: 0.998 > 0.42\n      Primary: $REPLACE (1.000)\n\nğŸ“Š Found 1 error token(s)\n\nğŸ’¡ Generated 1 correction candidate(s)\n   ğŸ”„ [primary_tags]: Already seen (skipping)\n\nâš ï¸  Using best candidate despite validation failure\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 7/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ— Both models detect errors (GED: 0.999, Binary: 1 errors)\n  âš ï¸  Token 'à¤›à¥‹à¤ªà¤¿' @ pos 3\n      Binary: 0.998 > 0.42\n      Primary: $REPLACE (1.000)\n\nğŸ“Š Found 1 error token(s)\n\nğŸ’¡ Generated 1 correction candidate(s)\n   ğŸ”„ [primary_tags]: Already seen (skipping)\n\nâš ï¸  Using best candidate despite validation failure\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 8/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ— Both models detect errors (GED: 0.999, Binary: 1 errors)\n  âš ï¸  Token 'à¤›à¥‹à¤ªà¤¿' @ pos 3\n      Binary: 0.998 > 0.42\n      Primary: $REPLACE (1.000)\n\nğŸ“Š Found 1 error token(s)\n\nğŸ’¡ Generated 1 correction candidate(s)\n   ğŸ”„ [primary_tags]: Already seen (skipping)\n\nâš ï¸  Using best candidate despite validation failure\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 9/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ— Both models detect errors (GED: 0.999, Binary: 1 errors)\n  âš ï¸  Token 'à¤›à¥‹à¤ªà¤¿' @ pos 3\n      Binary: 0.998 > 0.42\n      Primary: $REPLACE (1.000)\n\nğŸ“Š Found 1 error token(s)\n\nğŸ’¡ Generated 1 correction candidate(s)\n   ğŸ”„ [primary_tags]: Already seen (skipping)\n\nğŸ†˜ LAST RESORT: Attempting full MLM masking...\n   âŒ Full MLM result: à¤¡à¥‹à¤œà¤° à¤ªà¤¨à¤¿ à¤®à¤¾à¤Ÿà¥‹à¤²à¥‡ à¤›à¥‹à¤ªà¤¿ à¤—à¤à¤•à¥‹ à¤› à¥¤\n\nâŒ UNABLE TO CORRECT\n   This error pattern is too complex for the current models.\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 10/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ— Both models detect errors (GED: 0.999, Binary: 1 errors)\n  âš ï¸  Token 'à¤›à¥‹à¤ªà¤¿' @ pos 3\n      Binary: 0.998 > 0.42\n      Primary: $REPLACE (1.000)\n\nğŸ“Š Found 1 error token(s)\n\nğŸ’¡ Generated 1 correction candidate(s)\n   ğŸ”„ [primary_tags]: Already seen (skipping)\n\nğŸ†˜ LAST RESORT: Attempting full MLM masking...\n   âŒ Full MLM result: à¤¡à¥‹à¤œà¤° à¤ªà¤¨à¤¿ à¤®à¤¾à¤Ÿà¥‹à¤²à¥‡ à¤›à¥‹à¤ªà¤¿ à¤—à¤à¤•à¥‹ à¤› à¥¤\n\nâŒ UNABLE TO CORRECT\n   This error pattern is too complex for the current models.\n\n================================================================================\nğŸ¯ FINAL OUTPUT: à¤¡à¥‹à¤œà¤° à¤ªà¤¨à¤¿ à¤®à¤¾à¤Ÿà¥‹à¤²à¥‡ à¤›à¥‹à¤ªà¤¿ à¤—à¤à¤•à¥‹ à¤›à¥¤\n================================================================================\n\n\n================================================================================\nğŸ” INPUT: à¤•à¤¾à¤°à¥à¤¯à¤¾à¤²à¤¯à¤®à¤¾ à¤œà¤¡à¤¾à¤¨ à¤—à¤°à¤¿à¤à¤•à¤¾ à¤†à¤§à¤¾ à¤¦à¤°à¥à¤œà¤¨à¤­à¤¨à¥à¤¦à¤¾ à¤¬à¤¢à¥€ à¤•à¥à¤¯à¤¾à¤®à¥‡à¤°à¤¾à¤²à¥‡ à¤šà¥Œà¤¬à¤¿à¤¸à¥ˆ à¤˜à¤¨à¥à¤Ÿà¤¾ à¤•à¤¾à¤® à¤—à¤°à¥à¤¨ à¤¸à¤•à¥à¥€ à¤¸à¥Œà¤°à¥à¤¯ à¤Šà¤°à¥à¤œà¤¾à¤®à¤¾ à¤œà¤¡à¤¾à¤¨ à¤—à¤°à¤¿à¤à¤•à¥‹ à¤¹à¥‹à¥¤\nğŸ”§ PREPROCESSED: à¤•à¤¾à¤°à¥à¤¯à¤¾à¤²à¤¯à¤®à¤¾ à¤œà¤¡à¤¾à¤¨ à¤—à¤°à¤¿à¤à¤•à¤¾ à¤†à¤§à¤¾ à¤¦à¤°à¥à¤œà¤¨à¤­à¤¨à¥à¤¦à¤¾ à¤¬à¤¢à¥€ à¤•à¥à¤¯à¤¾à¤®à¥‡à¤°à¤¾à¤²à¥‡ à¤šà¥Œà¤¬à¤¿à¤¸à¥ˆ à¤˜à¤¨à¥à¤Ÿà¤¾ à¤•à¤¾à¤® à¤—à¤°à¥à¤¨ à¤¸à¤•à¥à¥€ à¤¸à¥Œà¤°à¥à¤¯ à¤Šà¤°à¥à¤œà¤¾à¤®à¤¾ à¤œà¤¡à¤¾à¤¨ à¤—à¤°à¤¿à¤à¤•à¥‹ à¤¹à¥‹ à¥¤\n================================================================================\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 1/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ— Both models detect errors (GED: 1.000, Binary: 3 errors)\n  âš ï¸  Token 'à¤—à¤°à¤¿à¤à¤•à¤¾' @ pos 2\n      Binary: 1.000 > 0.42\n      Primary: $SWAP_NEXT (0.999)\n  âš ï¸  Token 'à¤¸à¤•à¥à¥€' @ pos 11\n      Binary: 1.000 > 0.42\n      Primary: $REPLACE (1.000)\n  âš ï¸  Token 'à¤œà¤¡à¤¾à¤¨' @ pos 14\n      Binary: 0.999 > 0.42\n      Primary: $SWAP_PREV (0.999)\n\nğŸ“Š Found 3 error token(s)\n\nğŸ’¡ Generated 2 correction candidate(s)\n   âŒ [primary_tags]: à¤•à¤¾à¤°à¥à¤¯à¤¾à¤²à¤¯à¤®à¤¾ à¤œà¤¡à¤¾à¤¨ à¤†à¤§à¤¾ à¤—à¤°à¤¿à¤à¤•à¤¾ à¤¦à¤°à¥à¤œà¤¨à¤­à¤¨à¥à¤¦à¤¾ à¤¬à¤¢à¥€ à¤•à¥à¤¯à¤¾à¤®à¥‡à¤°à¤¾à¤²à¥‡ à¤šà¥Œà¤¬à¤¿à¤¸à¥ˆ à¤˜à¤¨à¥à¤Ÿà¤¾ à¤•à¤¾à¤® à¤—à¤°à¥à¤¨ à¤¸à¤•à¥à¤¨à¥‡...\n   âœ… [full_mlm]: à¤•à¤¾à¤°à¥à¤¯à¤¾à¤²à¤¯à¤®à¤¾ à¤œà¤¡à¤¾à¤¨ à¤—à¤°à¤¿à¤à¤•à¤¾ à¤†à¤§à¤¾ à¤¦à¤°à¥à¤œà¤¨à¤­à¤¨à¥à¤¦à¤¾ à¤¬à¤¢à¥€ à¤•à¥à¤¯à¤¾à¤®à¥‡à¤°à¤¾à¤²à¥‡ à¤šà¥Œà¤¬à¤¿à¤¸à¥ˆ à¤˜à¤¨à¥à¤Ÿà¤¾ à¤•à¤¾à¤® à¤—à¤°à¥à¤¨ à¤¸à¤•à¥à¤¨à¥‡...\n\nâœ“ Applied [full_mlm] correction\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 2/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ“ Both models agree (GED: 0.907)\nâœ… CORRECTION COMPLETE after 2 iteration(s)!\n\n================================================================================\nğŸ¯ FINAL OUTPUT: à¤•à¤¾à¤°à¥à¤¯à¤¾à¤²à¤¯à¤®à¤¾ à¤œà¤¡à¤¾à¤¨ à¤—à¤°à¤¿à¤à¤•à¤¾ à¤†à¤§à¤¾ à¤¦à¤°à¥à¤œà¤¨à¤­à¤¨à¥à¤¦à¤¾ à¤¬à¤¢à¥€ à¤•à¥à¤¯à¤¾à¤®à¥‡à¤°à¤¾à¤²à¥‡ à¤šà¥Œà¤¬à¤¿à¤¸à¥ˆ à¤˜à¤¨à¥à¤Ÿà¤¾ à¤•à¤¾à¤® à¤—à¤°à¥à¤¨ à¤¸à¤•à¥à¤¨à¥‡à¤—à¤°à¥€ à¤¸à¥Œà¤°à¥à¤¯ à¤Šà¤°à¥à¤œà¤¾à¤®à¤¾ à¤¨à¤¿à¤°à¥à¤®à¤¾à¤£ à¤—à¤°à¤¿à¤à¤•à¥‹ à¤¹à¥‹à¥¤\nğŸ“ˆ Correction path: full_mlm(iter 1)\n================================================================================\n\n\n================================================================================\nğŸ” INPUT: à¤¤à¤¾à¤²à¤¿à¤®à¤•à¥‹ à¤²à¤¾à¤—à¤¿ à¤¬à¥‹à¤²à¤¾à¤‰à¤à¤¦à¤¾ à¤ªà¤¨à¤¿ à¤¨à¤œà¤¾à¤¨à¥‡ à¤®à¥à¤¡à¤®à¤¾ à¤¢à¥à¤•à¥à¤• à¤­à¤à¤° à¤¬à¤¸à¤¿à¤°à¤¹à¥‡à¤•à¥‹ à¤¥à¤¿à¤à¤ à¥¤\nğŸ”§ PREPROCESSED: à¤¤à¤¾à¤²à¤¿à¤®à¤•à¥‹ à¤²à¤¾à¤—à¤¿ à¤¬à¥‹à¤²à¤¾à¤‰à¤à¤¦à¤¾ à¤ªà¤¨à¤¿ à¤¨à¤œà¤¾à¤¨à¥‡ à¤®à¥à¤¡à¤®à¤¾ à¤¢à¥à¤•à¥à¤• à¤­à¤à¤° à¤¬à¤¸à¤¿à¤°à¤¹à¥‡à¤•à¥‹ à¤¥à¤¿à¤à¤ à¥¤\n================================================================================\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 1/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ— GED detects error (conf: 0.557)\nâš ï¸  Binary found no errors, but GED detected issues.\nğŸ”„ Attempting AGGRESSIVE MLM on ALL token positions...\n\n   ğŸ“ PHASE 1: Testing ALL 11 positions with single/double/triple masks\n      Position 0/10 ('à¤¤à¤¾à¤²à¤¿à¤®à¤•à¥‹')\n      Position 1/10 ('à¤²à¤¾à¤—à¤¿')\n         âœ… 1-mask: 'à¤²à¤¾à¤—à¤¿' â†’ 'à¤¡à¤°,' (conf: 0.538)\n      Position 2/10 ('à¤¬à¥‹à¤²à¤¾à¤‰à¤à¤¦à¤¾')\n      Position 3/10 ('à¤ªà¤¨à¤¿')\n      Position 4/10 ('à¤¨à¤œà¤¾à¤¨à¥‡')\n      Position 5/10 ('à¤®à¥à¤¡à¤®à¤¾')\n         âœ… 1-mask: 'à¤®à¥à¤¡à¤®à¤¾' â†’ 'à¤®,' (conf: 0.809)\n         âœ… 1-mask: 'à¤®à¥à¤¡à¤®à¤¾' â†’ 'à¤­à¤¯à¥‹,' (conf: 0.590)\n         âœ… 1-mask: 'à¤®à¥à¤¡à¤®à¤¾' â†’ 'à¤­à¤¨à¥à¤¦à¤¾à¤­à¤¨à¥à¤¦à¥ˆ' (conf: 0.642)\n      Position 6/10 ('à¤¢à¥à¤•à¥à¤•')\n      Position 7/10 ('à¤­à¤à¤°')\n         âœ… 1-mask: 'à¤­à¤à¤°' â†’ 'à¤¬à¤¨à¤¾à¤à¤°' (conf: 0.562)\n      Position 8/10 ('à¤¬à¤¸à¤¿à¤°à¤¹à¥‡à¤•à¥‹')\n         âœ… 1-mask: 'à¤¬à¤¸à¤¿à¤°à¤¹à¥‡à¤•à¥‹' â†’ 'à¤¦à¤¿à¤à¤•à¥‹' (conf: 0.675)\n         âœ… 1-mask: 'à¤¬à¤¸à¤¿à¤°à¤¹à¥‡à¤•à¥‹' â†’ 'à¤®' (conf: 0.527)\n      Position 9/10 ('à¤¥à¤¿à¤à¤')\n         âœ… 1-mask: 'à¤¥à¤¿à¤à¤' â†’ 'à¤¬à¤¤à¤¾à¤‰à¤à¤›à¤¨à¥' (conf: 0.623)\n         âœ… 1-mask: 'à¤¥à¤¿à¤à¤' â†’ 'à¤¬à¤¤à¤¾à¤‰à¤à¤›à¤¿à¤¨à¥' (conf: 0.639)\n         âœ… 1-mask: 'à¤¥à¤¿à¤à¤' â†’ 'à¤¬à¤¤à¤¾à¤‰à¤›à¤¨à¥' (conf: 0.602)\n         âœ… 1-mask: 'à¤¥à¤¿à¤à¤' â†’ 'à¤­à¥‡à¤Ÿà¤¿à¤¨à¥à¤›à¤¨à¥' (conf: 0.874)\n      Position 10/10 ('à¥¤')\n         âœ… 1-mask: 'à¥¤' â†’ 'à¤®à¥¤' (conf: 0.950)\n\n   ğŸ“ PHASE 2: Testing adjacent position pairs (10 pairs)\n      Pair [0,1] ('à¤¤à¤¾à¤²à¤¿à¤®à¤•à¥‹', 'à¤²à¤¾à¤—à¤¿')\n      Pair [1,2] ('à¤²à¤¾à¤—à¤¿', 'à¤¬à¥‹à¤²à¤¾à¤‰à¤à¤¦à¤¾')\n      Pair [2,3] ('à¤¬à¥‹à¤²à¤¾à¤‰à¤à¤¦à¤¾', 'à¤ªà¤¨à¤¿')\n      Pair [3,4] ('à¤ªà¤¨à¤¿', 'à¤¨à¤œà¤¾à¤¨à¥‡')\n         âœ… 2-mask: 'à¤ªà¤¨à¤¿ à¤¨à¤œà¤¾à¤¨à¥‡' â†’ 'à¤†à¤¯à¥‹, à¤¨à¤—à¤°à¥à¤¨à¥‡' (conf: 0.508)\n      Pair [4,5] ('à¤¨à¤œà¤¾à¤¨à¥‡', 'à¤®à¥à¤¡à¤®à¤¾')\n         âœ… 2-mask: 'à¤¨à¤œà¤¾à¤¨à¥‡ à¤®à¥à¤¡à¤®à¤¾' â†’ 'à¤¨à¤—à¤°à¥à¤¨à¥‡ à¤®,' (conf: 0.688)\n         âœ… 2-mask: 'à¤¨à¤œà¤¾à¤¨à¥‡ à¤®à¥à¤¡à¤®à¤¾' â†’ 'à¤¨à¤—à¤°à¥à¤¨à¥‡ à¤­à¤¯à¥‹,' (conf: 0.633)\n      Pair [5,6] ('à¤®à¥à¤¡à¤®à¤¾', 'à¤¢à¥à¤•à¥à¤•')\n      Pair [6,7] ('à¤¢à¥à¤•à¥à¤•', 'à¤­à¤à¤°')\n         âœ… 2-mask: 'à¤¢à¥à¤•à¥à¤• à¤­à¤à¤°' â†’ 'à¤¨à¤¿ à¤®' (conf: 0.829)\n      Pair [7,8] ('à¤­à¤à¤°', 'à¤¬à¤¸à¤¿à¤°à¤¹à¥‡à¤•à¥‹')\n         âœ… 2-mask: 'à¤­à¤à¤° à¤¬à¤¸à¤¿à¤°à¤¹à¥‡à¤•à¥‹' â†’ 'à¤¬à¤¨à¤¾à¤à¤° à¤¦à¤¿à¤à¤•à¥‹' (conf: 0.803)\n         âœ… 2-mask: 'à¤­à¤à¤° à¤¬à¤¸à¤¿à¤°à¤¹à¥‡à¤•à¥‹' â†’ 'à¤¬à¤¨à¤¾à¤à¤° à¤«à¤°à¥à¤•à¤à¤¦à¥ˆ' (conf: 0.551)\n      Pair [8,9] ('à¤¬à¤¸à¤¿à¤°à¤¹à¥‡à¤•à¥‹', 'à¤¥à¤¿à¤à¤')\n         âœ… 2-mask: 'à¤¬à¤¸à¤¿à¤°à¤¹à¥‡à¤•à¥‹ à¤¥à¤¿à¤à¤' â†’ 'à¤¦à¤¿à¤à¤•à¥‹ à¤¬à¤¤à¤¾à¤‰à¤à¤›à¤¨à¥' (conf: 0.771)\n         âœ… 2-mask: 'à¤¬à¤¸à¤¿à¤°à¤¹à¥‡à¤•à¥‹ à¤¥à¤¿à¤à¤' â†’ 'à¤¦à¤¿à¤à¤•à¥‹ à¤¬à¤¤à¤¾à¤‰à¤à¤›à¤¿à¤¨à¥' (conf: 0.718)\n         âœ… 2-mask: 'à¤¬à¤¸à¤¿à¤°à¤¹à¥‡à¤•à¥‹ à¤¥à¤¿à¤à¤' â†’ 'à¤¦à¤¿à¤à¤•à¥‹ à¤¬à¤¤à¤¾à¤‰à¤›à¤¨à¥' (conf: 0.709)\n      Pair [9,10] ('à¤¥à¤¿à¤à¤', 'à¥¤')\n         âœ… 2-mask: 'à¤¥à¤¿à¤à¤ à¥¤' â†’ 'à¤¬à¤¤à¤¾à¤‰à¤à¤›à¤¨à¥ à¥¤' (conf: 0.623)\n         âœ… 2-mask: 'à¤¥à¤¿à¤à¤ à¥¤' â†’ 'à¤¬à¤¤à¤¾à¤‰à¤à¤›à¤¨à¥ à¤®à¥¤' (conf: 0.887)\n         âœ… 2-mask: 'à¤¥à¤¿à¤à¤ à¥¤' â†’ 'à¤¬à¤¤à¤¾à¤‰à¤à¤›à¤¿à¤¨à¥ à¥¤' (conf: 0.639)\n         âœ… 2-mask: 'à¤¥à¤¿à¤à¤ à¥¤' â†’ 'à¤¬à¤¤à¤¾à¤‰à¤à¤›à¤¿à¤¨à¥ à¤®à¥¤' (conf: 0.895)\n         âœ… 2-mask: 'à¤¥à¤¿à¤à¤ à¥¤' â†’ 'à¤¬à¤¤à¤¾à¤‰à¤›à¤¨à¥ à¥¤' (conf: 0.602)\n         âœ… 2-mask: 'à¤¥à¤¿à¤à¤ à¥¤' â†’ 'à¤¬à¤¤à¤¾à¤‰à¤›à¤¨à¥ à¤®à¥¤' (conf: 0.877)\n\n   ğŸ“ PHASE 3: Testing adjacent position triplets (9 triplets)\n      Triplet [0,1,2] ('à¤¤à¤¾à¤²à¤¿à¤®à¤•à¥‹', 'à¤²à¤¾à¤—à¤¿', 'à¤¬à¥‹à¤²à¤¾à¤‰à¤à¤¦à¤¾')\n      Triplet [1,2,3] ('à¤²à¤¾à¤—à¤¿', 'à¤¬à¥‹à¤²à¤¾à¤‰à¤à¤¦à¤¾', 'à¤ªà¤¨à¤¿')\n      Triplet [2,3,4] ('à¤¬à¥‹à¤²à¤¾à¤‰à¤à¤¦à¤¾', 'à¤ªà¤¨à¤¿', 'à¤¨à¤œà¤¾à¤¨à¥‡')\n      Triplet [3,4,5] ('à¤ªà¤¨à¤¿', 'à¤¨à¤œà¤¾à¤¨à¥‡', 'à¤®à¥à¤¡à¤®à¤¾')\n      Triplet [4,5,6] ('à¤¨à¤œà¤¾à¤¨à¥‡', 'à¤®à¥à¤¡à¤®à¤¾', 'à¤¢à¥à¤•à¥à¤•')\n      Triplet [5,6,7] ('à¤®à¥à¤¡à¤®à¤¾', 'à¤¢à¥à¤•à¥à¤•', 'à¤­à¤à¤°')\n      Triplet [6,7,8] ('à¤¢à¥à¤•à¥à¤•', 'à¤­à¤à¤°', 'à¤¬à¤¸à¤¿à¤°à¤¹à¥‡à¤•à¥‹')\n         âœ… 3-mask: (conf: 0.617)\n         âœ… 3-mask: (conf: 0.654)\n         âœ… 3-mask: (conf: 0.576)\n      Triplet [7,8,9] ('à¤­à¤à¤°', 'à¤¬à¤¸à¤¿à¤°à¤¹à¥‡à¤•à¥‹', 'à¤¥à¤¿à¤à¤')\n         âœ… 3-mask: (conf: 0.824)\n         âœ… 3-mask: (conf: 0.804)\n      Triplet [8,9,10] ('à¤¬à¤¸à¤¿à¤°à¤¹à¥‡à¤•à¥‹', 'à¤¥à¤¿à¤à¤', 'à¥¤')\n         âœ… 3-mask: (conf: 0.771)\n         âœ… 3-mask: (conf: 0.853)\n         âœ… 3-mask: (conf: 0.718)\n         âœ… 3-mask: (conf: 0.802)\n\n   ğŸ† BEST CANDIDATE SELECTED:\n      Strategy: 1mask_pos10\n      Change: 'à¥¤' â†’ 'à¤®à¥¤'\n      Confidence: 0.9497\n      Total valid candidates: 36\n\n   ğŸ“Š Other candidates:\n      1. [2mask_pos9-10] conf=0.8947\n      2. [2mask_pos9-10] conf=0.8871\n      3. [2mask_pos9-10] conf=0.8772\n      4. [1mask_pos9] conf=0.8738\n      5. [3mask_pos8-9-10] conf=0.8533\n\n   âœ… Applied best correction with confidence 0.9497\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 2/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ“ Both models agree (GED: 0.950)\nâœ… CORRECTION COMPLETE after 2 iteration(s)!\n\n================================================================================\nğŸ¯ FINAL OUTPUT: à¤¤à¤¾à¤²à¤¿à¤®à¤•à¥‹ à¤²à¤¾à¤—à¤¿ à¤¬à¥‹à¤²à¤¾à¤‰à¤à¤¦à¤¾ à¤ªà¤¨à¤¿ à¤¨à¤œà¤¾à¤¨à¥‡ à¤®à¥à¤¡à¤®à¤¾ à¤¢à¥à¤•à¥à¤• à¤­à¤à¤° à¤¬à¤¸à¤¿à¤°à¤¹à¥‡à¤•à¥‹ à¤¥à¤¿à¤à¤ à¤®à¥¤\nğŸ“ˆ Correction path: 1mask_pos10(iter 1)\n================================================================================\n\n\n================================================================================\nğŸ” INPUT: à¤¦à¥à¤°à¥à¤˜à¤Ÿà¤¨à¤¾à¤¬à¤¾à¤œà¤¾ à¤¬à¤œà¤¾à¤à¤° à¤†à¤‰à¤à¤¦à¥ˆà¤¨ à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ à¤¸à¤¸à¤¾à¤¨à¥‹à¤—à¤²à¥à¤¤à¥€à¤²à¥‡ à¤¹à¥à¤¨à¥‡ à¤¹à¥‹ à¥¤\nğŸ”§ PREPROCESSED: à¤¦à¥à¤°à¥à¤˜à¤Ÿà¤¨à¤¾à¤¬à¤¾à¤œà¤¾ à¤¬à¤œà¤¾à¤à¤° à¤†à¤‰à¤à¤¦à¥ˆà¤¨ à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ à¤¸à¤¸à¤¾à¤¨à¥‹à¤—à¤²à¥à¤¤à¥€à¤²à¥‡ à¤¹à¥à¤¨à¥‡ à¤¹à¥‹ à¥¤\n================================================================================\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 1/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ— GED detects error (conf: 0.831)\nâš ï¸  Binary found no errors, but GED detected issues.\nğŸ”„ Attempting AGGRESSIVE MLM on ALL token positions...\n\n   ğŸ“ PHASE 1: Testing ALL 8 positions with single/double/triple masks\n      Position 0/7 ('à¤¦à¥à¤°à¥à¤˜à¤Ÿà¤¨à¤¾à¤¬à¤¾à¤œà¤¾')\n      Position 1/7 ('à¤¬à¤œà¤¾à¤à¤°')\n      Position 2/7 ('à¤†à¤‰à¤à¤¦à¥ˆà¤¨')\n         âœ… 1-mask: 'à¤†à¤‰à¤à¤¦à¥ˆà¤¨' â†’ 'à¤¹à¥‹à¤‡à¤¨,' (conf: 0.906)\n         âœ… 1-mask: 'à¤†à¤‰à¤à¤¦à¥ˆà¤¨' â†’ 'à¤¹à¥ˆà¤¨,' (conf: 0.895)\n         âœ… 1-mask: 'à¤†à¤‰à¤à¤¦à¥ˆà¤¨' â†’ 'à¤¹à¥à¤à¤¦à¥ˆà¤¨,' (conf: 0.887)\n         âœ… 1-mask: 'à¤†à¤‰à¤à¤¦à¥ˆà¤¨' â†’ '-' (conf: 0.517)\n      Position 3/7 ('à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ')\n         âœ… 1-mask: 'à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ' â†’ 'à¤¤à¤°,' (conf: 0.781)\n         âœ… 1-mask: 'à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ' â†’ 'à¤°,' (conf: 0.851)\n         âœ… 1-mask: 'à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ' â†’ 'à¥¤' (conf: 0.821)\n         âœ… 1-mask: 'à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ' â†’ 'à¤¨à¤¿,' (conf: 0.673)\n      Position 4/7 ('à¤¸à¤¸à¤¾à¤¨à¥‹à¤—à¤²à¥à¤¤à¥€à¤²à¥‡')\n      Position 5/7 ('à¤¹à¥à¤¨à¥‡')\n      Position 6/7 ('à¤¹à¥‹')\n      Position 7/7 ('à¥¤')\n\n   ğŸ“ PHASE 2: Testing adjacent position pairs (7 pairs)\n      Pair [0,1] ('à¤¦à¥à¤°à¥à¤˜à¤Ÿà¤¨à¤¾à¤¬à¤¾à¤œà¤¾', 'à¤¬à¤œà¤¾à¤à¤°')\n         âœ… 2-mask: 'à¤¦à¥à¤°à¥à¤˜à¤Ÿà¤¨à¤¾à¤¬à¤¾à¤œà¤¾ à¤¬à¤œà¤¾à¤à¤°' â†’ 'à¤œà¥à¤¨ à¤†à¤‰à¤à¤¦à¥ˆà¤¨,' (conf: 0.588)\n      Pair [1,2] ('à¤¬à¤œà¤¾à¤à¤°', 'à¤†à¤‰à¤à¤¦à¥ˆà¤¨')\n      Pair [2,3] ('à¤†à¤‰à¤à¤¦à¥ˆà¤¨', 'à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ')\n         âœ… 2-mask: 'à¤†à¤‰à¤à¤¦à¥ˆà¤¨ à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ' â†’ 'à¤¹à¥‹à¤‡à¤¨, à¤¤à¤°,' (conf: 0.844)\n         âœ… 2-mask: 'à¤†à¤‰à¤à¤¦à¥ˆà¤¨ à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ' â†’ 'à¤¹à¥‹à¤‡à¤¨, à¤°,' (conf: 0.867)\n         âœ… 2-mask: 'à¤†à¤‰à¤à¤¦à¥ˆà¤¨ à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ' â†’ 'à¤¹à¥ˆà¤¨, à¤¤à¤°,' (conf: 0.818)\n         âœ… 2-mask: 'à¤†à¤‰à¤à¤¦à¥ˆà¤¨ à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ' â†’ 'à¤¹à¥ˆà¤¨, à¤°,' (conf: 0.837)\n         âœ… 2-mask: 'à¤†à¤‰à¤à¤¦à¥ˆà¤¨ à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ' â†’ 'à¤¹à¥à¤à¤¦à¥ˆà¤¨, à¤¤à¤°,' (conf: 0.811)\n         âœ… 2-mask: 'à¤†à¤‰à¤à¤¦à¥ˆà¤¨ à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ' â†’ 'à¤¹à¥à¤à¤¦à¥ˆà¤¨, à¤°,' (conf: 0.847)\n      Pair [3,4] ('à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ', 'à¤¸à¤¸à¤¾à¤¨à¥‹à¤—à¤²à¥à¤¤à¥€à¤²à¥‡')\n         âœ… 2-mask: 'à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ à¤¸à¤¸à¤¾à¤¨à¥‹à¤—à¤²à¥à¤¤à¥€à¤²à¥‡' â†’ 'à¤¤à¤°, à¤ªà¤°à¤¿à¤£à¤¾à¤®' (conf: 0.581)\n         âœ… 2-mask: 'à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ à¤¸à¤¸à¤¾à¤¨à¥‹à¤—à¤²à¥à¤¤à¥€à¤²à¥‡' â†’ 'à¤°, à¤ªà¤°à¤¿à¤£à¤¾à¤®' (conf: 0.712)\n      Pair [4,5] ('à¤¸à¤¸à¤¾à¤¨à¥‹à¤—à¤²à¥à¤¤à¥€à¤²à¥‡', 'à¤¹à¥à¤¨à¥‡')\n      Pair [5,6] ('à¤¹à¥à¤¨à¥‡', 'à¤¹à¥‹')\n      Pair [6,7] ('à¤¹à¥‹', 'à¥¤')\n\n   ğŸ“ PHASE 3: Testing adjacent position triplets (6 triplets)\n      Triplet [0,1,2] ('à¤¦à¥à¤°à¥à¤˜à¤Ÿà¤¨à¤¾à¤¬à¤¾à¤œà¤¾', 'à¤¬à¤œà¤¾à¤à¤°', 'à¤†à¤‰à¤à¤¦à¥ˆà¤¨')\n         âœ… 3-mask: (conf: 0.563)\n         âœ… 3-mask: (conf: 0.579)\n         âœ… 3-mask: (conf: 0.625)\n      Triplet [1,2,3] ('à¤¬à¤œà¤¾à¤à¤°', 'à¤†à¤‰à¤à¤¦à¥ˆà¤¨', 'à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ')\n      Triplet [2,3,4] ('à¤†à¤‰à¤à¤¦à¥ˆà¤¨', 'à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ', 'à¤¸à¤¸à¤¾à¤¨à¥‹à¤—à¤²à¥à¤¤à¥€à¤²à¥‡')\n      Triplet [3,4,5] ('à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ', 'à¤¸à¤¸à¤¾à¤¨à¥‹à¤—à¤²à¥à¤¤à¥€à¤²à¥‡', 'à¤¹à¥à¤¨à¥‡')\n      Triplet [4,5,6] ('à¤¸à¤¸à¤¾à¤¨à¥‹à¤—à¤²à¥à¤¤à¥€à¤²à¥‡', 'à¤¹à¥à¤¨à¥‡', 'à¤¹à¥‹')\n      Triplet [5,6,7] ('à¤¹à¥à¤¨à¥‡', 'à¤¹à¥‹', 'à¥¤')\n\n   ğŸ† BEST CANDIDATE SELECTED:\n      Strategy: 1mask_pos2\n      Change: 'à¤†à¤‰à¤à¤¦à¥ˆà¤¨' â†’ 'à¤¹à¥‹à¤‡à¤¨,'\n      Confidence: 0.9056\n      Total valid candidates: 20\n\n   ğŸ“Š Other candidates:\n      1. [1mask_pos2] conf=0.8949\n      2. [1mask_pos2] conf=0.8866\n      3. [2mask_pos2-3] conf=0.8672\n      4. [1mask_pos3] conf=0.8513\n      5. [2mask_pos2-3] conf=0.8474\n\n   âœ… Applied best correction with confidence 0.9056\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 2/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ“ Both models agree (GED: 0.906)\nâœ… CORRECTION COMPLETE after 2 iteration(s)!\n\n================================================================================\nğŸ¯ FINAL OUTPUT: à¤¦à¥à¤°à¥à¤˜à¤Ÿà¤¨à¤¾à¤¬à¤¾à¤œà¤¾ à¤¬à¤œà¤¾à¤à¤° à¤¹à¥‹à¤‡à¤¨, à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ à¤¸à¤¸à¤¾à¤¨à¥‹à¤—à¤²à¥à¤¤à¥€à¤²à¥‡ à¤¹à¥à¤¨à¥‡ à¤¹à¥‹à¥¤\nğŸ“ˆ Correction path: 1mask_pos2(iter 1)\n================================================================================\n\n\n================================================================================\nğŸ” INPUT: à¤­à¥€à¤®à¤¦à¤¤à¥à¤¤ à¤¨à¤—à¤°à¤ªà¤¾à¤²à¤¿à¤•à¤¾à¤ªà¤›à¤¿ à¤ªà¥à¤°à¤¦à¥‡à¤¶ à¤¸à¤°à¤•à¤¾à¤°à¤•à¥‹ à¤¸à¤¬à¥ˆà¤­à¤¨à¥à¤¦à¤¾ à¤§à¥‡à¤°à¥ˆ à¤¬à¤œà¥‡à¤Ÿ à¤•à¥ƒà¤·à¥à¤£à¤ªà¥à¤° à¤¨à¤—à¤°à¤ªà¤¾à¤²à¤¿à¤•à¤¾à¤®à¤¾ à¤ªà¤°à¥‡à¤•à¥‹ à¥¤\nğŸ”§ PREPROCESSED: à¤­à¥€à¤®à¤¦à¤¤à¥à¤¤ à¤¨à¤—à¤°à¤ªà¤¾à¤²à¤¿à¤•à¤¾à¤ªà¤›à¤¿ à¤ªà¥à¤°à¤¦à¥‡à¤¶ à¤¸à¤°à¤•à¤¾à¤°à¤•à¥‹ à¤¸à¤¬à¥ˆà¤­à¤¨à¥à¤¦à¤¾ à¤§à¥‡à¤°à¥ˆ à¤¬à¤œà¥‡à¤Ÿ à¤•à¥ƒà¤·à¥à¤£à¤ªà¥à¤° à¤¨à¤—à¤°à¤ªà¤¾à¤²à¤¿à¤•à¤¾à¤®à¤¾ à¤ªà¤°à¥‡à¤•à¥‹ à¥¤\n================================================================================\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 1/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ— Both models detect errors (GED: 1.000, Binary: 1 errors)\n  âš ï¸  Token 'à¤ªà¤°à¥‡à¤•à¥‹' @ pos 9\n      Binary: 0.999 > 0.42\n      Primary: $APPEND (1.000)\n\nğŸ“Š Found 1 error token(s)\n\nğŸ’¡ Generated 1 correction candidate(s)\n   âœ… [primary_tags]: à¤­à¥€à¤®à¤¦à¤¤à¥à¤¤ à¤¨à¤—à¤°à¤ªà¤¾à¤²à¤¿à¤•à¤¾à¤ªà¤›à¤¿ à¤ªà¥à¤°à¤¦à¥‡à¤¶ à¤¸à¤°à¤•à¤¾à¤°à¤•à¥‹ à¤¸à¤¬à¥ˆà¤­à¤¨à¥à¤¦à¤¾ à¤§à¥‡à¤°à¥ˆ à¤¬à¤œà¥‡à¤Ÿ à¤•à¥ƒà¤·à¥à¤£à¤ªà¥à¤° à¤¨à¤—à¤°à¤ªà¤¾à¤²à¤¿à¤•à¤¾à¤®à¤¾ à¤ªà¤°à¥‡à¤•...\n\nâœ“ Applied [primary_tags] correction\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 2/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ“ Both models agree (GED: 0.985)\nâœ… CORRECTION COMPLETE after 2 iteration(s)!\n\n================================================================================\nğŸ¯ FINAL OUTPUT: à¤­à¥€à¤®à¤¦à¤¤à¥à¤¤ à¤¨à¤—à¤°à¤ªà¤¾à¤²à¤¿à¤•à¤¾à¤ªà¤›à¤¿ à¤ªà¥à¤°à¤¦à¥‡à¤¶ à¤¸à¤°à¤•à¤¾à¤°à¤•à¥‹ à¤¸à¤¬à¥ˆà¤­à¤¨à¥à¤¦à¤¾ à¤§à¥‡à¤°à¥ˆ à¤¬à¤œà¥‡à¤Ÿ à¤•à¥ƒà¤·à¥à¤£à¤ªà¥à¤° à¤¨à¤—à¤°à¤ªà¤¾à¤²à¤¿à¤•à¤¾à¤®à¤¾ à¤ªà¤°à¥‡à¤•à¥‹ à¤›à¥¤à¥¤\nğŸ“ˆ Correction path: primary_tags(iter 1)\n================================================================================\n\n\n================================================================================\nğŸ” INPUT: à¤¸à¤®à¥ƒà¤¦à¥à¤§à¤¿à¤•à¤¾ à¤²à¤¾à¤—à¤¿ à¤†à¤°à¥à¤¥à¤¿à¤• à¤ªà¤¾à¤¤à¥‹ à¤¨à¥ˆ à¤®à¥à¤–à¥à¤¯ à¤¹à¥‹ à¥¤\nğŸ”§ PREPROCESSED: à¤¸à¤®à¥ƒà¤¦à¥à¤§à¤¿à¤•à¤¾ à¤²à¤¾à¤—à¤¿ à¤†à¤°à¥à¤¥à¤¿à¤• à¤ªà¤¾à¤¤à¥‹ à¤¨à¥ˆ à¤®à¥à¤–à¥à¤¯ à¤¹à¥‹ à¥¤\n================================================================================\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 1/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ— Both models detect errors (GED: 1.000, Binary: 1 errors)\n  âš ï¸  Token 'à¤ªà¤¾à¤¤à¥‹' @ pos 3\n      Binary: 0.993 > 0.42\n      Primary: $REPLACE (0.997)\n\nğŸ“Š Found 1 error token(s)\n\nğŸ’¡ Generated 1 correction candidate(s)\n   âœ… [primary_tags]: à¤¸à¤®à¥ƒà¤¦à¥à¤§à¤¿à¤•à¤¾ à¤²à¤¾à¤—à¤¿ à¤†à¤°à¥à¤¥à¤¿à¤• à¤¨à¤¿à¤°à¥à¤®à¤¾à¤£ à¤¨à¥ˆ à¤®à¥à¤–à¥à¤¯ à¤¹à¥‹ à¥¤\n\nâœ“ Applied [primary_tags] correction\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 2/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ“ Both models agree (GED: 0.857)\nâœ… CORRECTION COMPLETE after 2 iteration(s)!\n\n================================================================================\nğŸ¯ FINAL OUTPUT: à¤¸à¤®à¥ƒà¤¦à¥à¤§à¤¿à¤•à¤¾ à¤²à¤¾à¤—à¤¿ à¤†à¤°à¥à¤¥à¤¿à¤• à¤¨à¤¿à¤°à¥à¤®à¤¾à¤£ à¤¨à¥ˆ à¤®à¥à¤–à¥à¤¯ à¤¹à¥‹à¥¤\nğŸ“ˆ Correction path: primary_tags(iter 1)\n================================================================================\n\n\n================================================================================\nğŸ” INPUT: à¤®à¥‡à¤°à¥‹ à¤¨à¤¾à¤® à¤¦à¤¿à¤ªà¥‡à¤¶ à¤¹à¥‹\nğŸ”§ PREPROCESSED: à¤®à¥‡à¤°à¥‹ à¤¨à¤¾à¤® à¤¦à¤¿à¤ªà¥‡à¤¶ à¤¹à¥‹\n================================================================================\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 1/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ— Both models detect errors (GED: 1.000, Binary: 1 errors)\n  âš ï¸  Token 'à¤¹à¥‹' @ pos 3\n      Binary: 0.999 > 0.42\n      Primary: $APPEND (0.698)\n\nğŸ“Š Found 1 error token(s)\n\nğŸ’¡ Generated 1 correction candidate(s)\n   âœ… [primary_tags]: à¤®à¥‡à¤°à¥‹ à¤¨à¤¾à¤® à¤¦à¤¿à¤ªà¥‡à¤¶ à¤¹à¥‹ à¥¤\n\nâœ“ Applied [primary_tags] correction\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”„ ITERATION 2/10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ” Validation: âœ“ Both models agree (GED: 0.968)\nâœ… CORRECTION COMPLETE after 2 iteration(s)!\n\n================================================================================\nğŸ¯ FINAL OUTPUT: à¤®à¥‡à¤°à¥‹ à¤¨à¤¾à¤® à¤¦à¤¿à¤ªà¥‡à¤¶ à¤¹à¥‹à¥¤\nğŸ“ˆ Correction path: primary_tags(iter 1)\n================================================================================\n\n\nâœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…\nPROCESSING COMPLETE\nâœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…\n\nâœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…\nPROCESSING COMPLETE\nâœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…\n","output_type":"stream"}],"execution_count":87},{"cell_type":"code","source":"print(\"\\n\" + \"ğŸ“‹\"*40)\nprint(\"Test sentences             ---------------->       CORRECTED SENTENCES\")\nprint(\"ğŸ“‹\"*40)\n\nprint(f\"| {'Test Sentences':<50} | {'Corrected Sentence'} |\")\nprint(\"-\"*200)\n\nfor inc, cor in pairs:\n    print(\"-\"*100)\n    print(f\"{inc:<50} | {cor}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T13:42:57.467679Z","iopub.execute_input":"2025-11-15T13:42:57.468186Z","iopub.status.idle":"2025-11-15T13:42:57.473456Z","shell.execute_reply.started":"2025-11-15T13:42:57.468157Z","shell.execute_reply":"2025-11-15T13:42:57.472867Z"}},"outputs":[{"name":"stdout","text":"\nğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹\nTest sentences             ---------------->       CORRECTED SENTENCES\nğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹ğŸ“‹\n| Test Sentences                                     | Corrected Sentence |\n--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n----------------------------------------------------------------------------------------------------\nà¤¨à¤¾à¤® à¤®à¥‡à¤°à¥‹ à¤¦à¤¿à¤ªà¥‡à¤¶ à¤¹à¥‹ à¥¤                                | à¤®à¥‡à¤°à¥‹ à¤¨à¤¾à¤® à¤¦à¤¿à¤ªà¥‡à¤¶ à¤¹à¥‹à¥¤\n----------------------------------------------------------------------------------------------------\nà¤® à¤¸à¥à¤•à¥à¤² à¤œà¤¾à¤¨à¥à¤›à¥ à¥¤                                   | à¤® à¤¸à¥à¤•à¥à¤² à¤œà¤¾à¤¨à¥à¤›à¥à¥¤\n----------------------------------------------------------------------------------------------------\nà¤¯à¥‹ à¤•à¤¿à¤¤à¤¾à¤¬ à¤®à¥‡à¤°à¥‹ à¤¹à¥‹ à¥¤                                 | à¤¯à¥‹ à¤•à¤¿à¤¤à¤¾à¤¬ à¤®à¥‡à¤°à¥‹ à¤¹à¥‹à¥¤\n----------------------------------------------------------------------------------------------------\nà¤¡à¥‹à¤œà¤° à¤ªà¤¨à¤¿ à¤®à¤¾à¤Ÿà¥‹à¤²à¥‡ à¤›à¥‹à¤ªà¤‚ à¤—à¤à¤•à¥‹ à¤› à¥¤                      | à¤¡à¥‹à¤œà¤° à¤ªà¤¨à¤¿ à¤®à¤¾à¤Ÿà¥‹à¤²à¥‡ à¤›à¥‹à¤ªà¤¿ à¤—à¤à¤•à¥‹ à¤›à¥¤\n----------------------------------------------------------------------------------------------------\nà¤•à¤¾à¤°à¥à¤¯à¤¾à¤²à¤¯à¤®à¤¾ à¤œà¤¡à¤¾à¤¨ à¤—à¤°à¤¿à¤à¤•à¤¾ à¤†à¤§à¤¾ à¤¦à¤°à¥à¤œà¤¨à¤­à¤¨à¥à¤¦à¤¾ à¤¬à¤¢à¥€ à¤•à¥à¤¯à¤¾à¤®à¥‡à¤°à¤¾à¤²à¥‡ à¤šà¥Œà¤¬à¤¿à¤¸à¥ˆ à¤˜à¤¨à¥à¤Ÿà¤¾ à¤•à¤¾à¤® à¤—à¤°à¥à¤¨ à¤¸à¤•à¥à¥€ à¤¸à¥Œà¤°à¥à¤¯ à¤Šà¤°à¥à¤œà¤¾à¤®à¤¾ à¤œà¤¡à¤¾à¤¨ à¤—à¤°à¤¿à¤à¤•à¥‹ à¤¹à¥‹à¥¤ | à¤•à¤¾à¤°à¥à¤¯à¤¾à¤²à¤¯à¤®à¤¾ à¤œà¤¡à¤¾à¤¨ à¤—à¤°à¤¿à¤à¤•à¤¾ à¤†à¤§à¤¾ à¤¦à¤°à¥à¤œà¤¨à¤­à¤¨à¥à¤¦à¤¾ à¤¬à¤¢à¥€ à¤•à¥à¤¯à¤¾à¤®à¥‡à¤°à¤¾à¤²à¥‡ à¤šà¥Œà¤¬à¤¿à¤¸à¥ˆ à¤˜à¤¨à¥à¤Ÿà¤¾ à¤•à¤¾à¤® à¤—à¤°à¥à¤¨ à¤¸à¤•à¥à¤¨à¥‡à¤—à¤°à¥€ à¤¸à¥Œà¤°à¥à¤¯ à¤Šà¤°à¥à¤œà¤¾à¤®à¤¾ à¤¨à¤¿à¤°à¥à¤®à¤¾à¤£ à¤—à¤°à¤¿à¤à¤•à¥‹ à¤¹à¥‹à¥¤\n----------------------------------------------------------------------------------------------------\nà¤¤à¤¾à¤²à¤¿à¤®à¤•à¥‹ à¤²à¤¾à¤—à¤¿ à¤¬à¥‹à¤²à¤¾à¤‰à¤à¤¦à¤¾ à¤ªà¤¨à¤¿ à¤¨à¤œà¤¾à¤¨à¥‡ à¤®à¥à¤¡à¤®à¤¾ à¤¢à¥à¤•à¥à¤• à¤­à¤à¤° à¤¬à¤¸à¤¿à¤°à¤¹à¥‡à¤•à¥‹ à¤¥à¤¿à¤à¤ à¥¤ | à¤¤à¤¾à¤²à¤¿à¤®à¤•à¥‹ à¤²à¤¾à¤—à¤¿ à¤¬à¥‹à¤²à¤¾à¤‰à¤à¤¦à¤¾ à¤ªà¤¨à¤¿ à¤¨à¤œà¤¾à¤¨à¥‡ à¤®à¥à¤¡à¤®à¤¾ à¤¢à¥à¤•à¥à¤• à¤­à¤à¤° à¤¬à¤¸à¤¿à¤°à¤¹à¥‡à¤•à¥‹ à¤¥à¤¿à¤à¤ à¤®à¥¤\n----------------------------------------------------------------------------------------------------\nà¤¦à¥à¤°à¥à¤˜à¤Ÿà¤¨à¤¾à¤¬à¤¾à¤œà¤¾ à¤¬à¤œà¤¾à¤à¤° à¤†à¤‰à¤à¤¦à¥ˆà¤¨ à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ à¤¸à¤¸à¤¾à¤¨à¥‹à¤—à¤²à¥à¤¤à¥€à¤²à¥‡ à¤¹à¥à¤¨à¥‡ à¤¹à¥‹ à¥¤ | à¤¦à¥à¤°à¥à¤˜à¤Ÿà¤¨à¤¾à¤¬à¤¾à¤œà¤¾ à¤¬à¤œà¤¾à¤à¤° à¤¹à¥‹à¤‡à¤¨, à¤®à¤¾à¤¨à¤¿à¤¸à¤•à¥ˆ à¤¸à¤¸à¤¾à¤¨à¥‹à¤—à¤²à¥à¤¤à¥€à¤²à¥‡ à¤¹à¥à¤¨à¥‡ à¤¹à¥‹à¥¤\n----------------------------------------------------------------------------------------------------\nà¤­à¥€à¤®à¤¦à¤¤à¥à¤¤ à¤¨à¤—à¤°à¤ªà¤¾à¤²à¤¿à¤•à¤¾à¤ªà¤›à¤¿ à¤ªà¥à¤°à¤¦à¥‡à¤¶ à¤¸à¤°à¤•à¤¾à¤°à¤•à¥‹ à¤¸à¤¬à¥ˆà¤­à¤¨à¥à¤¦à¤¾ à¤§à¥‡à¤°à¥ˆ à¤¬à¤œà¥‡à¤Ÿ à¤•à¥ƒà¤·à¥à¤£à¤ªà¥à¤° à¤¨à¤—à¤°à¤ªà¤¾à¤²à¤¿à¤•à¤¾à¤®à¤¾ à¤ªà¤°à¥‡à¤•à¥‹ à¥¤ | à¤­à¥€à¤®à¤¦à¤¤à¥à¤¤ à¤¨à¤—à¤°à¤ªà¤¾à¤²à¤¿à¤•à¤¾à¤ªà¤›à¤¿ à¤ªà¥à¤°à¤¦à¥‡à¤¶ à¤¸à¤°à¤•à¤¾à¤°à¤•à¥‹ à¤¸à¤¬à¥ˆà¤­à¤¨à¥à¤¦à¤¾ à¤§à¥‡à¤°à¥ˆ à¤¬à¤œà¥‡à¤Ÿ à¤•à¥ƒà¤·à¥à¤£à¤ªà¥à¤° à¤¨à¤—à¤°à¤ªà¤¾à¤²à¤¿à¤•à¤¾à¤®à¤¾ à¤ªà¤°à¥‡à¤•à¥‹ à¤›à¥¤à¥¤\n----------------------------------------------------------------------------------------------------\nà¤¸à¤®à¥ƒà¤¦à¥à¤§à¤¿à¤•à¤¾ à¤²à¤¾à¤—à¤¿ à¤†à¤°à¥à¤¥à¤¿à¤• à¤ªà¤¾à¤¤à¥‹ à¤¨à¥ˆ à¤®à¥à¤–à¥à¤¯ à¤¹à¥‹ à¥¤           | à¤¸à¤®à¥ƒà¤¦à¥à¤§à¤¿à¤•à¤¾ à¤²à¤¾à¤—à¤¿ à¤†à¤°à¥à¤¥à¤¿à¤• à¤¨à¤¿à¤°à¥à¤®à¤¾à¤£ à¤¨à¥ˆ à¤®à¥à¤–à¥à¤¯ à¤¹à¥‹à¥¤\n----------------------------------------------------------------------------------------------------\nà¤®à¥‡à¤°à¥‹ à¤¨à¤¾à¤® à¤¦à¤¿à¤ªà¥‡à¤¶ à¤¹à¥‹                                  | à¤®à¥‡à¤°à¥‹ à¤¨à¤¾à¤® à¤¦à¤¿à¤ªà¥‡à¤¶ à¤¹à¥‹à¥¤\n","output_type":"stream"}],"execution_count":88},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}