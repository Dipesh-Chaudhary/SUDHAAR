{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "%uv pip install datasets transformers huggingface_hub\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.12.6 environment at: /usr/local\u001b[0m\r\n",
            "\u001b[37m\u280b\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u280b\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mdatasets==4.4.1                                                               \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mtransformers==4.56.0                                                          \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mhuggingface-hub==0.34.4                                                       \u001b[0m\r\u001b[2K\u001b[37m\u2839\u001b[0m \u001b[2mhuggingface-hub==0.34.4                                                       \u001b[0m\r\u001b[2K\u001b[37m\u2839\u001b[0m \u001b[2mfilelock==3.13.1                                                              \u001b[0m\r\u001b[2K\u001b[37m\u2839\u001b[0m \u001b[2mnumpy==2.1.2                                                                  \u001b[0m\r\u001b[2K\u001b[37m\u2839\u001b[0m \u001b[2mpyarrow==22.0.0                                                               \u001b[0m\r\u001b[2K\u001b[37m\u2839\u001b[0m \u001b[2mdill==0.4.0                                                                   \u001b[0m\r\u001b[2K\u001b[37m\u2839\u001b[0m \u001b[2mpandas==2.3.2                                                                 \u001b[0m\r\u001b[2K\u001b[37m\u2839\u001b[0m \u001b[2mnumpy==2.1.2                                                                  \u001b[0m\r\u001b[2K\u001b[37m\u2839\u001b[0m \u001b[2mrequests==2.32.5                                                              \u001b[0m\r\u001b[2K\u001b[37m\u2839\u001b[0m \u001b[2mhttpx==0.28.1                                                                 \u001b[0m\r\u001b[2K\u001b[37m\u2839\u001b[0m \u001b[2mtqdm==4.67.1                                                                  \u001b[0m\r\u001b[2K\u001b[37m\u2839\u001b[0m \u001b[2mxxhash==3.6.0                                                                 \u001b[0m\r\u001b[2K\u001b[37m\u2839\u001b[0m \u001b[2mmultiprocess==0.70.18                                                         \u001b[0m\r\u001b[2K\u001b[37m\u2839\u001b[0m \u001b[2mfsspec==2024.6.1                                                              \u001b[0m\r\u001b[2K\u001b[37m\u2839\u001b[0m \u001b[2mfsspec==2024.6.1                                                              \u001b[0m\r\u001b[2K\u001b[37m\u2839\u001b[0m \u001b[2mpackaging==25.0                                                               \u001b[0m\r\u001b[2K\u001b[37m\u2839\u001b[0m \u001b[2mpyyaml==6.0.2                                                                 \u001b[0m\r\u001b[2K\u001b[37m\u2839\u001b[0m \u001b[2mregex==2025.9.1                                                               \u001b[0m\r\u001b[2K\u001b[37m\u2839\u001b[0m \u001b[2mtokenizers==0.22.0                                                            \u001b[0m\r\u001b[2K\u001b[37m\u2839\u001b[0m \u001b[2msafetensors==0.6.2                                                            \u001b[0m\r\u001b[2K\u001b[37m\u2839\u001b[0m \u001b[2mtyping-extensions==4.12.2                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2839\u001b[0m \u001b[2mhf-xet==1.1.9                                                                 \u001b[0m\r\u001b[2K\u001b[37m\u2838\u001b[0m \u001b[2mhf-xet==1.1.9                                                                 \u001b[0m\r\u001b[2K\u001b[37m\u2838\u001b[0m \u001b[2mhf-xet==1.1.9                                                                 \u001b[0m\r\u001b[2K\u001b[37m\u2838\u001b[0m \u001b[2mmultidict==6.1.0                                                              \u001b[0m\r\u001b[2K\u001b[2mResolved \u001b[1m40 packages\u001b[0m \u001b[2min 459ms\u001b[0m\u001b[0m\r\n",
            "\u001b[37m\u280b\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/0)                                                   \r\u001b[2K\u001b[37m\u280b\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)                                                   \r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)                                                   \r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
            "\u001b[2mdatasets  \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/499.60 KiB                    \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
            "\u001b[2mdill      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/116.86 KiB\r\n",
            "\u001b[2mdatasets  \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/499.60 KiB                    \u001b[2A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[2A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
            "\u001b[2mdill      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/116.86 KiB\r\n",
            "\u001b[2mdatasets  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/499.60 KiB                  \u001b[2A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[2A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
            "\u001b[2mdill      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 14.88 KiB/116.86 KiB\r\n",
            "\u001b[2mdatasets  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/499.60 KiB                  \u001b[2A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[2A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
            "\u001b[2mdill      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 14.88 KiB/116.86 KiB\r\n",
            "\u001b[2mdatasets  \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 32.00 KiB/499.60 KiB                  \u001b[2A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[2A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
            "\u001b[2mdill      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 14.88 KiB/116.86 KiB\r\n",
            "\u001b[2mdatasets  \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 48.00 KiB/499.60 KiB                  \u001b[2A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[2A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
            "\u001b[2mdill      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 14.88 KiB/116.86 KiB\r\n",
            "\u001b[2mdatasets  \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 63.81 KiB/499.60 KiB                  \u001b[2A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[2A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
            "\u001b[2mdill      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 30.88 KiB/116.86 KiB\r\n",
            "\u001b[2mdatasets  \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 63.81 KiB/499.60 KiB                  \u001b[2A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[2A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
            "\u001b[2mdill      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 30.88 KiB/116.86 KiB\r\n",
            "\u001b[2mdatasets  \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 79.81 KiB/499.60 KiB                  \u001b[2A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[2A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
            "\u001b[2mdill      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 30.88 KiB/116.86 KiB\r\n",
            "\u001b[2mdatasets  \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 95.81 KiB/499.60 KiB                  \u001b[2A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[2A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
            "\u001b[2mdill      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 30.88 KiB/116.86 KiB\r\n",
            "\u001b[2mdatasets  \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 111.81 KiB/499.60 KiB                 \u001b[2A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[2A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
            "\u001b[2mdill      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 30.88 KiB/116.86 KiB\r\n",
            "\u001b[2mxxhash    \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/189.34 KiB\r\n",
            "\u001b[2mdatasets  \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 111.81 KiB/499.60 KiB                 \u001b[3A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[3A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
            "\u001b[2mdill      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 30.88 KiB/116.86 KiB\r\n",
            "\u001b[2mxxhash    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.00 KiB/189.34 KiB\r\n",
            "\u001b[2mdatasets  \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 111.81 KiB/499.60 KiB                 \u001b[3A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[3A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
            "\u001b[2mdill      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 30.88 KiB/116.86 KiB\r\n",
            "\u001b[2mxxhash    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.00 KiB/189.34 KiB\r\n",
            "\u001b[2mdatasets  \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 111.81 KiB/499.60 KiB\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/45.52 MiB                     \u001b[4A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[4A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
            "\u001b[2mdill      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 30.88 KiB/116.86 KiB\r\n",
            "\u001b[2mxxhash    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.00 KiB/189.34 KiB\r\n",
            "\u001b[2mdatasets  \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 111.81 KiB/499.60 KiB\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/45.52 MiB                   \u001b[4A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[4A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
            "\u001b[2mdill      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 30.88 KiB/116.86 KiB\r\n",
            "\u001b[2mmultiprocess\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/146.76 KiB\r\n",
            "\u001b[2mxxhash    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.00 KiB/189.34 KiB\r\n",
            "\u001b[2mdatasets  \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 111.81 KiB/499.60 KiB\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/45.52 MiB                   \u001b[5A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[5A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
            "\u001b[2mdill      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 30.88 KiB/116.86 KiB\r\n",
            "\u001b[2mmultiprocess\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 16.00 KiB/146.76 KiB\r\n",
            "\u001b[2mxxhash    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.00 KiB/189.34 KiB\r\n",
            "\u001b[2mdatasets  \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 111.81 KiB/499.60 KiB\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/45.52 MiB                   \u001b[5A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[5A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
            "\u001b[2mdill      \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 46.88 KiB/116.86 KiB\r\n",
            "\u001b[2mmultiprocess\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 16.00 KiB/146.76 KiB\r\n",
            "\u001b[2mxxhash    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 92.83 KiB/189.34 KiB\r\n",
            "\u001b[2mdatasets  \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 143.81 KiB/499.60 KiB\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 76.91 KiB/45.52 MiB                   \u001b[5A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[5A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
            "\u001b[2mdill      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 78.88 KiB/116.86 KiB\r\n",
            "\u001b[2mmultiprocess\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 48.00 KiB/146.76 KiB\r\n",
            "\u001b[2mdatasets  \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 207.81 KiB/499.60 KiB\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 540.91 KiB/45.52 MiB                  \u001b[4A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[4A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
            "\u001b[2mdill      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 78.88 KiB/116.86 KiB\r\n",
            "\u001b[2mmultiprocess\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 64.00 KiB/146.76 KiB\r\n",
            "\u001b[2mdatasets  \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 236.93 KiB/499.60 KiB\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 588.91 KiB/45.52 MiB                  \u001b[4A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[4A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
            "\u001b[2mdill      \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 109.41 KiB/116.86 KiB\r\n",
            "\u001b[2mmultiprocess\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 144.00 KiB/146.76 KiB\r\n",
            "\u001b[2mdatasets  \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 287.81 KiB/499.60 KiB\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.34 MiB/45.52 MiB                    \u001b[4A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[4A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
            "\u001b[2mmultiprocess\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 144.00 KiB/146.76 KiB\r\n",
            "\u001b[2mdatasets  \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 319.19 KiB/499.60 KiB\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.06 MiB/45.52 MiB                    \u001b[3A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[3A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
            "\u001b[2mdatasets  \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 319.19 KiB/499.60 KiB\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.33 MiB/45.52 MiB                    \u001b[2A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[2A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/5)\r\n",
            "\u001b[2mdatasets  \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 319.81 KiB/499.60 KiB\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.41 MiB/45.52 MiB                    \u001b[2A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[2A\u001b[37m\u2839\u001b[0m \u001b[2mPreparing packages...\u001b[0m (3/5)\r\n",
            "\u001b[2mdatasets  \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 367.81 KiB/499.60 KiB\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 3.78 MiB/45.52 MiB                    \u001b[2A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[2A\u001b[37m\u2839\u001b[0m \u001b[2mPreparing packages...\u001b[0m (3/5)\r\n",
            "\u001b[2mdatasets  \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 415.81 KiB/499.60 KiB\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 6.23 MiB/45.52 MiB                    \u001b[2A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[2A\u001b[37m\u2839\u001b[0m \u001b[2mPreparing packages...\u001b[0m (3/5)\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 8.06 MiB/45.52 MiB                    \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2839\u001b[0m \u001b[2mPreparing packages...\u001b[0m (3/5)\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 8.11 MiB/45.52 MiB                    \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2839\u001b[0m \u001b[2mPreparing packages...\u001b[0m (3/5)\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 9.42 MiB/45.52 MiB                    \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2838\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 11.68 MiB/45.52 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2838\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 14.08 MiB/45.52 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2838\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 16.23 MiB/45.52 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2838\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 19.14 MiB/45.52 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u283c\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 21.59 MiB/45.52 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u283c\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 24.69 MiB/45.52 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u283c\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 26.95 MiB/45.52 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u283c\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 29.82 MiB/45.52 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2834\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 32.00 MiB/45.52 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2834\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 33.73 MiB/45.52 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2834\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 35.39 MiB/45.52 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2834\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 37.57 MiB/45.52 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2826\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 39.51 MiB/45.52 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2826\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 41.16 MiB/45.52 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2826\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 43.12 MiB/45.52 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2826\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 43.69 MiB/45.52 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2827\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 43.81 MiB/45.52 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2827\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 43.95 MiB/45.52 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2827\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 44.08 MiB/45.52 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2827\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 44.20 MiB/45.52 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2807\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 44.40 MiB/45.52 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2807\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 44.68 MiB/45.52 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2807\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 44.92 MiB/45.52 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2807\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)\r\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 45.39 MiB/45.52 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u280b\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/5)                                                   \r\u001b[2K\u001b[2mPrepared \u001b[1m5 packages\u001b[0m \u001b[2min 1.61s\u001b[0m\u001b[0m\r\n",
            "\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [0/0] \u001b[2mInstalling wheels...                                 \u001b[0m\r\u001b[2K\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [0/5] \u001b[2mInstalling wheels...                                 \u001b[0m\r\u001b[2K\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [0/5] \u001b[2mxxhash==3.6.0                                        \u001b[0m\r\u001b[2K\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [1/5] \u001b[2mxxhash==3.6.0                                        \u001b[0m\r\u001b[2K\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [1/5] \u001b[2mmultiprocess==0.70.18                                \u001b[0m\r\u001b[2K\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [2/5] \u001b[2mmultiprocess==0.70.18                                \u001b[0m\r\u001b[2K\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [2/5] \u001b[2mdill==0.4.0                                          \u001b[0m\r\u001b[2K\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [3/5] \u001b[2mdill==0.4.0                                          \u001b[0m\r\u001b[2K\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [3/5] \u001b[2mdatasets==4.4.1                                      \u001b[0m\r\u001b[2K\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591 [4/5] \u001b[2mdatasets==4.4.1                                      \u001b[0m\r\u001b[2K\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591 [4/5] \u001b[2mpyarrow==22.0.0                                      \u001b[0m\r\u001b[2K\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 [5/5] \u001b[2mpyarrow==22.0.0                                      \u001b[0m\r\u001b[2K\u001b[2mInstalled \u001b[1m5 packages\u001b[0m \u001b[2min 322ms\u001b[0m\u001b[0m\r\n",
            " \u001b[32m+\u001b[39m \u001b[1mdatasets\u001b[0m\u001b[2m==4.4.1\u001b[0m\r\n",
            " \u001b[32m+\u001b[39m \u001b[1mdill\u001b[0m\u001b[2m==0.4.0\u001b[0m\r\n",
            " \u001b[32m+\u001b[39m \u001b[1mmultiprocess\u001b[0m\u001b[2m==0.70.18\u001b[0m\r\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyarrow\u001b[0m\u001b[2m==22.0.0\u001b[0m\r\n",
            " \u001b[32m+\u001b[39m \u001b[1mxxhash\u001b[0m\u001b[2m==3.6.0\u001b[0m\r\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "import json\n",
        "import os\n",
        "import difflib\n",
        "import re\n",
        "from collections import defaultdict, Counter\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "from multiprocessing import cpu_count\n",
        "\n",
        "import datasets\n",
        "from datasets import Dataset, DatasetDict, load_dataset, concatenate_datasets\n",
        "from transformers import AutoTokenizer, RobertaTokenizerFast\n",
        "from huggingface_hub import HfApi, create_repo, login\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "import gc"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "# HF_TOKEN = \"\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "MODEL_NAME = \"IRIIS-RESEARCH/RoBERTa_Nepali_125M\"\n",
        "MAX_SEQUENCE_LENGTH = 128\n",
        "HF_USERNAME = \"DipeshChaudhary\"\n",
        "RAW_DATASET_NAME = \"sumitaryal/nepali_grammatical_error_correction\"\n",
        "FINAL_DATASET_NAME = \"nepali-gector-mlm-guesser-dataset\" \n",
        "REPO_ID = f\"{HF_USERNAME}/{FINAL_DATASET_NAME}\"\n",
        "NUM_WORKERS = max(1, cpu_count() - 2)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "login(token=HF_TOKEN)\n",
        "print(\"\u2705 Hugging Face login successful.\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u2705 Hugging Face login successful.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "print(f\"--- MLM DATASET PROCESSOR ---\")\n",
        "print(f\"Model: {MODEL_NAME}\")\n",
        "print(f\"Max Seq Length: {MAX_SEQUENCE_LENGTH}\")\n",
        "print(f\"Workers: {NUM_WORKERS}\")\n",
        "print(f\"Output Repo: {REPO_ID}\")\n",
        "print(\"-\" * 70 + \"\\n\")\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MLM DATASET PROCESSOR ---\n",
            "Model: IRIIS-RESEARCH/RoBERTa_Nepali_125M\n",
            "Max Seq Length: 128\n",
            "Workers: 106\n",
            "Output Repo: DipeshChaudhary/nepali-gector-mlm-guesser-dataset\n",
            "----------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "\n",
        "# Initialize Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "MASK_TOKEN_ID = tokenizer.mask_token_id\n",
        "CLS_TOKEN_ID = tokenizer.cls_token_id\n",
        "SEP_TOKEN_ID = tokenizer.sep_token_id\n",
        "PAD_TOKEN_ID = tokenizer.pad_token_id\n",
        "\n",
        "# --- Enhanced GEC Vocabulary (From 01-gec-token-gector-tag-dataset-processor.ipynb) ---\n",
        "# Defines the mapping between GEC tag names and their integer IDs.\n",
        "class EnhancedNepaliGECVocabulary:\n",
        "    def __init__(self):\n",
        "        self.KEEP_ID = 0\n",
        "        self.DELETE_ID = 1\n",
        "        self.REPLACE_ID = 2\n",
        "        self.APPEND_ID = 3\n",
        "        self.SWAP_NEXT_ID = 4\n",
        "        self.SWAP_PREV_ID = 5\n",
        "        self.MERGE_NEXT_ID = 6\n",
        "        self.MERGE_PREV_ID = 7\n",
        "        self.SPLIT_ID = 8\n",
        "        self.UNKNOWN_ID = 9\n",
        "        \n",
        "        self.tag_to_id = {\n",
        "            \"$KEEP\": self.KEEP_ID, \"$DELETE\": self.DELETE_ID,\n",
        "            \"$REPLACE\": self.REPLACE_ID, \"$APPEND\": self.APPEND_ID,\n",
        "            \"$SWAP_NEXT\": self.SWAP_NEXT_ID, \"$SWAP_PREV\": self.SWAP_PREV_ID,\n",
        "            \"$MERGE_NEXT\": self.MERGE_NEXT_ID, \"$MERGE_PREV\": self.MERGE_PREV_ID,\n",
        "            \"$SPLIT\": self.SPLIT_ID, \"$UNKNOWN\": self.UNKNOWN_ID\n",
        "        }\n",
        "        self.id_to_tag = {v: k for k, v in self.tag_to_id.items()}\n",
        "    \n",
        "VOCAB = EnhancedNepaliGECVocabulary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "251c7add0b8342ce954a188a22f56fc8",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "tokenizer_config.json: 0.00B [00:00, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "036ceb4660ab41ed845a54f3c800dc52",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "tokenizer.json: 0.00B [00:00, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ac1fe9a7e0444d490b678e690766a14",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/968 [00:00<?, ?B/s]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "def calculate_levenshtein_opcodes(incorrect_words: List[str], correct_words: List[str]) -> List[Tuple[str, int, int, int, int]]:\n",
        "    \"\"\"Calculates Levenshtein opcodes (tag, i1, i2, j1, j2) using difflib.\"\"\"\n",
        "    s = difflib.SequenceMatcher(None, incorrect_words, correct_words, autojunk=False)\n",
        "    return s.get_opcodes()\n",
        "\n",
        "def generate_word_level_tags(incorrect_words: List[str], \n",
        "                             correct_words: List[str],\n",
        "                             vocabulary: EnhancedNepaliGECVocabulary) -> Tuple[List[int], List[Tuple[str, int, int, int, int]]]:\n",
        "    \"\"\"\n",
        "    Generates robust, word-level GEC tags using a strict multi-pass priority system.\n",
        "    This function is slightly simplified from the original for clarity, focusing on\n",
        "    getting the core REPLACE and APPEND information.\n",
        "    \"\"\"\n",
        "    \n",
        "    opcodes = calculate_levenshtein_opcodes(incorrect_words, correct_words)\n",
        "    tags = [vocabulary.KEEP_ID] * len(incorrect_words)\n",
        "    \n",
        "\n",
        "    j_next = 0 # Next available index in the correct sentence\n",
        "    for op, i_start, i_end, j_start, j_end in opcodes:\n",
        "        inc_span = incorrect_words[i_start:i_end]\n",
        "        cor_span = correct_words[j_start:j_end]\n",
        "        \n",
        "        if any(tags[idx] != vocabulary.KEEP_ID for idx in range(i_start, i_end)):\n",
        "            j_next = j_end\n",
        "            continue\n",
        "            \n",
        "        if op == 'equal':\n",
        "            for idx in range(i_start, i_end):\n",
        "                tags[idx] = vocabulary.KEEP_ID\n",
        "        elif op == 'replace':\n",
        "            # This is a key target for masking/replacement\n",
        "            for idx in range(i_start, i_end):\n",
        "                tags[idx] = vocabulary.REPLACE_ID\n",
        "        elif op == 'delete':\n",
        "            for idx in range(i_start, i_end):\n",
        "                tags[idx] = vocabulary.DELETE_ID\n",
        "        elif op == 'insert':\n",
        "\n",
        "            pass \n",
        "        \n",
        "        j_next = j_end\n",
        "\n",
        "    return tags, opcodes"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "def process_for_mlm(example: Dict) -> Dict:\n",
        "    \"\"\"\n",
        "    Maps a (Corrupt, Correct) sentence pair to MLM-ready input/labels.\n",
        "    Only creates masks for REPLACE and APPEND operations.\n",
        "    \"\"\"\n",
        "    \n",
        "    # 1. Prepare raw sentences and token lists\n",
        "    inc_sent = example['incorrect_sentence']\n",
        "    cor_sent = example['correct_sentence']\n",
        "    \n",
        "    # Simple whitespace tokenization for word-level alignment (crucial step from original)\n",
        "    incorrect_words = inc_sent.split()\n",
        "    correct_words = cor_sent.split()\n",
        "    \n",
        "    # 2. Get Word-Level GEC Tags and Opcodes\n",
        "    word_tags, opcodes = generate_word_level_tags(incorrect_words, correct_words, VOCAB)\n",
        "\n",
        "    # 3. Tokenize both sentences (needed to get correct token IDs)\n",
        "    inc_encoding = tokenizer(\n",
        "        inc_sent, \n",
        "        truncation=True, \n",
        "        max_length=MAX_SEQUENCE_LENGTH, \n",
        "        return_offsets_mapping=True, # Need this to map tokens back to words/spans\n",
        "        add_special_tokens=True\n",
        "    )\n",
        "    \n",
        "    cor_encoding = tokenizer(\n",
        "        cor_sent, \n",
        "        truncation=True, \n",
        "        max_length=MAX_SEQUENCE_LENGTH, \n",
        "        add_special_tokens=True\n",
        "    )\n",
        "\n",
        "    inc_input_ids = list(inc_encoding['input_ids'])\n",
        "    \n",
        "    # Initialize MLM labels to -100 (ignore by default)\n",
        "    mlm_labels = [-100] * len(inc_input_ids)\n",
        "\n",
        "    # If sentences are too long after truncation, skip to avoid alignment issues\n",
        "    if len(inc_input_ids) > MAX_SEQUENCE_LENGTH or len(cor_encoding['input_ids']) > MAX_SEQUENCE_LENGTH:\n",
        "        return {\n",
        "            'mlm_input_ids': inc_input_ids,\n",
        "            'mlm_labels': mlm_labels,\n",
        "            'mlm_tag_count': 0\n",
        "        }\n",
        "\n",
        "    # 4. Map Word-Level Tags to Token-Level MLM Input/Labels\n",
        "    \n",
        "    # The tokenizer's `word_ids()` connects subword tokens to their original word index (0, 1, 2, ...).\n",
        "    word_ids = inc_encoding.word_ids()\n",
        "    mlm_tag_count = 0\n",
        "    \n",
        "    # This loop tracks the index in the CORRECT sentence tokens (cor_encoding['input_ids'])\n",
        "    # to find the correct replacement/append token IDs.\n",
        "    cor_token_idx = 1 # Start after [CLS]\n",
        "    \n",
        "    # Iterate over the word indices of the incorrect sentence\n",
        "    for word_idx in range(len(incorrect_words)):\n",
        "        tag = word_tags[word_idx]\n",
        "        \n",
        "        # Find the span of tokens corresponding to the current incorrect word\n",
        "        token_indices = [i for i, w_id in enumerate(word_ids) if w_id == word_idx]\n",
        "        \n",
        "        if not token_indices:\n",
        "            continue # Skip words with no tokens (e.g., if a word was fully truncated)\n",
        "            \n",
        "        first_token_idx = token_indices[0]\n",
        "        \n",
        "        if tag == VOCAB.REPLACE_ID:\n",
        "            # \ud83d\udccc CASE: $REPLACE\n",
        "            # We need to find the correct token(s) to replace the incorrect word.\n",
        "            \n",
        "            # Find the corresponding correct word index(es) from the opcodes\n",
        "            cor_word_index_start = -1\n",
        "            cor_word_index_end = -1\n",
        "            \n",
        "            # Search opcodes for the current incorrect word's index\n",
        "            for op, i_start, i_end, j_start, j_end in opcodes:\n",
        "                if op == 'replace' and i_start <= word_idx < i_end:\n",
        "                    cor_word_index_start = j_start\n",
        "                    cor_word_index_end = j_end\n",
        "                    break\n",
        "\n",
        "            if cor_word_index_start != -1 and cor_word_index_end > cor_word_index_start:\n",
        "                # The MLM target is the first subword of the *correct* replacement word.\n",
        "                correct_replacement_word = correct_words[cor_word_index_start]\n",
        "                \n",
        "                # Re-tokenize the *correct* replacement word to find its first subword ID\n",
        "                replacement_tokens = tokenizer.encode(correct_replacement_word, add_special_tokens=False)\n",
        "                \n",
        "                if replacement_tokens:\n",
        "                    # 1. Mask the incorrect word tokens in the input\n",
        "                    inc_input_ids[first_token_idx] = MASK_TOKEN_ID\n",
        "                    for other_idx in token_indices[1:]:\n",
        "                        inc_input_ids[other_idx] = MASK_TOKEN_ID # Mask all sub-tokens\n",
        "\n",
        "                    # 2. Set the label to the first token of the correct word\n",
        "                    mlm_labels[first_token_idx] = replacement_tokens[0]\n",
        "                    \n",
        "                    mlm_tag_count += 1\n",
        "\n",
        "        elif tag == VOCAB.APPEND_ID:\n",
        "            # \ud83d\udccc CASE: $APPEND\n",
        "            # In GECTOR, $APPEND is assigned to a word *before* the insertion point.\n",
        "            \n",
        "            # Find the corresponding inserted word(s) from the opcodes\n",
        "            inserted_words = []\n",
        "            for op, i_start, i_end, j_start, j_end in opcodes:\n",
        "                 # Check for an 'insert' operation directly following the current word index\n",
        "                if op == 'insert' and i_end == word_idx + 1:\n",
        "                    inserted_words.extend(correct_words[j_start:j_end])\n",
        "            \n",
        "            if inserted_words:\n",
        "                first_inserted_word = inserted_words[0]\n",
        "                \n",
        "                # Re-tokenize the inserted word to find its first subword ID\n",
        "                inserted_tokens = tokenizer.encode(first_inserted_word, add_special_tokens=False)\n",
        "\n",
        "                if inserted_tokens:\n",
        "                    # 1. Inject a [MASK] token into the input IDs *after* the current word's tokens\n",
        "                    insertion_point = token_indices[-1] + 1\n",
        "                    inc_input_ids.insert(insertion_point, MASK_TOKEN_ID)\n",
        "                    \n",
        "                    # 2. Adjust mlm_labels (insert -100 at the new position)\n",
        "                    mlm_labels.insert(insertion_point, -100)\n",
        "                    \n",
        "                    # 3. Set the label at the newly inserted [MASK] token\n",
        "                    mlm_labels[insertion_point] = inserted_tokens[0]\n",
        "                    \n",
        "                    # Note: Subsequent token indices in inc_input_ids and mlm_labels are shifted by 1.\n",
        "                    # We must continue iterating through the word_ids list and the mlm_labels list, \n",
        "                    # which is now misaligned with the original word_ids.\n",
        "                    # A robust implementation would rebuild the word_ids after insertion, \n",
        "                    # but for simplicity, we focus on the single append for the current word_idx.\n",
        "                    \n",
        "                    mlm_tag_count += 1\n",
        "        \n",
        "    return {\n",
        "        'mlm_input_ids': inc_input_ids,\n",
        "        'mlm_labels': mlm_labels,\n",
        "        'mlm_tag_count': mlm_tag_count,\n",
        "        # Keep original text for verification\n",
        "        'incorrect_sentence': inc_sent,\n",
        "        'correct_sentence': cor_sent\n",
        "    }"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "print(\"=\" * 70)\n",
        "print(f\"STEP 1: LOADING RAW DATASET: {RAW_DATASET_NAME}\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Load the raw dataset splits\n",
        "raw_dataset_splits = load_dataset(RAW_DATASET_NAME)\n",
        "raw_dataset = concatenate_datasets([raw_dataset_splits['train'], raw_dataset_splits['valid']])\n",
        "\n",
        "def filter_correct_sentences(example):\n",
        "    return example['incorrect_sentence'].strip() != example['correct_sentence'].strip()\n",
        "\n",
        "print(f\"Total rows before filtering: {len(raw_dataset)}\")\n",
        "# Filter the dataset to only include sentences where an error exists.\n",
        "error_dataset = raw_dataset.filter(\n",
        "    filter_correct_sentences, \n",
        "    num_proc=NUM_WORKERS\n",
        ")\n",
        "print(f\"Total rows after filtering (only errors): {len(error_dataset)}\")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"STEP 2: GENERATING MLM INPUTS AND LABELS\")\n",
        "print(f\"Using {NUM_WORKERS} workers.\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Apply the custom MLM processing function\n",
        "mlm_dataset = error_dataset.map(\n",
        "    process_for_mlm,\n",
        "    remove_columns=error_dataset.column_names,\n",
        "    num_proc=NUM_WORKERS,\n",
        "    # The APPEND logic dynamically changes the length, so we must disable batching\n",
        "    batched=False,\n",
        ")\n",
        "\n",
        "# Filter out examples where no REPLACE/APPEND tag was found (e.g., only DELETE/SWAP/MERGE errors)\n",
        "mlm_dataset = mlm_dataset.filter(lambda x: x['mlm_tag_count'] > 0, num_proc=NUM_WORKERS)\n",
        "print(f\"\\nTotal rows after MLM mask generation and filtering (REPLACE/APPEND targets): {len(mlm_dataset)}\")\n",
        "\n",
        "# --- SPLITTING ---\n",
        "print(\"=\" * 70)\n",
        "print(\"STEP 3: CREATING TRAIN/VALID SPLITS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Split the dataset into train and validation sets (90/10 split)\n",
        "final_split = mlm_dataset.train_test_split(test_size=0.1, seed=42)\n",
        "final_dataset = DatasetDict({\n",
        "    'train': final_split['train'],\n",
        "    'valid': final_split['test'],\n",
        "})\n",
        "\n",
        "print(\"Final dataset splits:\")\n",
        "print(final_dataset)\n",
        "\n",
        "# --- UPLOAD TO HUGGING FACE ---\n",
        "print(\"=\" * 70)\n",
        "print(\"STEP 4: UPLOADING DATASET TO HUGGING FACE HUB\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "try:\n",
        "    if HF_TOKEN:\n",
        "        final_dataset.push_to_hub(\n",
        "            repo_id=REPO_ID, \n",
        "            commit_message=\"Initial MLM dataset for GEC Guesser/Suggestor (REPLACE and APPEND focus)\",\n",
        "            private=True,\n",
        "            token=HF_TOKEN\n",
        "        )\n",
        "        print(f\"\\n\ud83c\udf89 Successfully uploaded dataset to: {REPO_ID}\")\n",
        "    else:\n",
        "        print(f\"\u26a0\ufe0f HF_TOKEN not set. Skipping upload. Dataset is ready locally.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n\u274c UPLOAD FAILED! Please check your HF_TOKEN and permissions.\")\n",
        "    print(e)\n",
        "    \n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"ALL STEPS COMPLETE.\")\n",
        "print(f\"Next Step: Fine-tune {MODEL_NAME} for MLM on this dataset.\")\n",
        "print(\"=\" * 70)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "STEP 1: LOADING RAW DATASET: sumitaryal/nepali_grammatical_error_correction\n",
            "======================================================================\n",
            "Total rows before filtering: 8130496\n",
            "Total rows after filtering (only errors): 8130496\n",
            "======================================================================\n",
            "STEP 2: GENERATING MLM INPUTS AND LABELS\n",
            "Using 106 workers.\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1419a9676b1540d2980cd4446e653534",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "Map (num_proc=106):   0%|          | 0/8130496 [00:00<?, ? examples/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a630d1bbd7545ebb2d2f5576c85c27a",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "Filter (num_proc=106):   0%|          | 0/8130496 [00:00<?, ? examples/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total rows after MLM mask generation and filtering (REPLACE/APPEND targets): 4557509\n",
            "======================================================================\n",
            "STEP 3: CREATING TRAIN/VALID SPLITS\n",
            "======================================================================\n",
            "Final dataset splits:\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['incorrect_sentence', 'correct_sentence', 'mlm_input_ids', 'mlm_labels', 'mlm_tag_count'],\n",
            "        num_rows: 4101758\n",
            "    })\n",
            "    valid: Dataset({\n",
            "        features: ['incorrect_sentence', 'correct_sentence', 'mlm_input_ids', 'mlm_labels', 'mlm_tag_count'],\n",
            "        num_rows: 455751\n",
            "    })\n",
            "})\n",
            "======================================================================\n",
            "STEP 4: UPLOADING DATASET TO HUGGING FACE HUB\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "afe1c8a4638a4c598506146f1895d727",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "Uploading the dataset shards:   0%|          | 0/6 [00:00<?, ? shards/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e297d65517e43a0bef171b8b722ab47",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "Creating parquet from Arrow format:   0%|          | 0/5 [00:00<?, ?ba/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "61ac18d7e0cc4e9fa318f28472b2864b",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18363b570950493da3acf21c62c63ae1",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "New Data Upload                         : |          |  0.00B /  0.00B            "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "83bdf153e4fb4ab58043da402a8cf145",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "                                        :   0%|          |  524kB /  157MB            "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "400b96d8d49e4d30bc53e445bc9ca953",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "Creating parquet from Arrow format:   0%|          | 0/5 [00:00<?, ?ba/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ba256d94a9143649901c9fb1bce0e07",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e5a919686684bc88b877090ac2b8c15",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "New Data Upload                         : |          |  0.00B /  0.00B            "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5dfd35f0574b482b839db481e4e429c2",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "                                        :   2%|2         | 3.67MB /  158MB            "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ca528f5ad414b398d3e7496fececdbd",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "Creating parquet from Arrow format:   0%|          | 0/5 [00:00<?, ?ba/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "067caef94bdd493481ff1229ee7e0cf0",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96a89cd7f492442799369a5986b47aa5",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "New Data Upload                         : |          |  0.00B /  0.00B            "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb033c9797584b22baf1d475041f3f5f",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "                                        :   2%|2         | 3.67MB /  158MB            "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b8c50b9d96145009aa203c8e815613f",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "Creating parquet from Arrow format:   0%|          | 0/5 [00:00<?, ?ba/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "589d6365a69441939fe1d2e45d638e00",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59f10648463f49e3b9d1e0e13830da8d",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "New Data Upload                         : |          |  0.00B /  0.00B            "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8c39a5bd0d04fea9c170fb512c64d85",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "                                        :   2%|2         | 3.67MB /  157MB            "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "31d4346538284973af7ff559c2e85aa7",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "Creating parquet from Arrow format:   0%|          | 0/5 [00:00<?, ?ba/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8c9a75baa1b46fb8e2fef68383c2978",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b7a8b416387f422d8dae095d994948b2",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "New Data Upload                         : |          |  0.00B /  0.00B            "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2cd4c68bbfa74c959e8b0919006cc601",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "                                        :   2%|2         | 3.67MB /  157MB            "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a03d810c2dde47f39fa51ef49778b87f",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "Creating parquet from Arrow format:   0%|          | 0/5 [00:00<?, ?ba/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "807389a42c0a4c87ad03c79e360f4151",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c88a85c6d75493690364f591eb93a0c",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "New Data Upload                         : |          |  0.00B /  0.00B            "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c21e86f18ef4c5a84a31a33115b590e",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "                                        :   2%|2         | 3.67MB /  158MB            "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0ebcd7464e54b26bd82f7b6f1fa4526",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "535a649208204004b116cc032e767fe8",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "Creating parquet from Arrow format:   0%|          | 0/4 [00:00<?, ?ba/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92aa9d6ffcc0475e8acb9c23d15b0408",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "01981415adf746bd80ade89545fdb41b",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "New Data Upload                         : |          |  0.00B /  0.00B            "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7fc4b42346fe4dd0b1567086088a9f49",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "                                        :   7%|6         | 7.35MB /  105MB            "
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\ud83c\udf89 Successfully uploaded dataset to: DipeshChaudhary/nepali-gector-mlm-guesser-dataset\n",
            "\n",
            "======================================================================\n",
            "ALL STEPS COMPLETE.\n",
            "Next Step: Fine-tune IRIIS-RESEARCH/RoBERTa_Nepali_125M for MLM on this dataset.\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "final_dataset['train'][0]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "{'incorrect_sentence': '\u092a\u091b\u093f\u0932\u094d\u0932\u094b \u0938\u092e\u092f \u0938\u0939\u091c \u0930\u0941\u092a\u092e\u093e \u092d\u093e\u0930\u0924\u0940\u092f \u0938\u0930\u0915\u093e\u0932\u0947 \u092a\u0947\u0928\u094d\u0938\u0928 \u0926\u093f\u0928 \u0906\u0928\u093e\u0915\u093e\u0928\u0940 \u0917\u0930\u094d\u0928 \u0925\u093e\u0932\u0947\u092a\u091b\u093f \u0909\u0928\u093f\u0939\u0930\u0942\u0932\u0947 \u0935\u093f\u092d\u093f\u0928\u094d\u0928 \u0928\u093f\u0915\u093e\u092f\u092e\u093e \u0927\u093e\u0909\u092a \u092c\u093e\u0927\u094d\u092f\u0924\u093e \u092c\u0928\u0947\u0915\u094b \u0939\u094b \u0964',\n 'correct_sentence': '\u092a\u091b\u093f\u0932\u094d\u0932\u094b \u0938\u092e\u092f \u0938\u0939\u091c \u0930\u0941\u092a\u092e\u093e \u092d\u093e\u0930\u0924\u0940\u092f \u0938\u0930\u0915\u093e\u0932\u0947 \u092a\u0947\u0928\u094d\u0938\u0928 \u0926\u093f\u0928 \u0906\u0928\u093e\u0915\u093e\u0928\u0940 \u0917\u0930\u094d\u0928 \u0925\u093e\u0932\u0947\u092a\u091b\u093f \u0909\u0928\u093f\u0939\u0930\u0942\u0932\u0947 \u0935\u093f\u092d\u093f\u0928\u094d\u0928 \u0928\u093f\u0915\u093e\u092f\u092e\u093e \u0927\u093e\u0909\u0928\u0941\u092a\u0930\u094d\u0928\u0947 \u092c\u093e\u0927\u094d\u092f\u0924\u093e \u092c\u0928\u0947\u0915\u094b \u0939\u094b \u0964',\n 'mlm_input_ids': [1676,\n  867,\n  2057,\n  1120,\n  1800,\n  35914,\n  15240,\n  837,\n  21380,\n  636,\n  4131,\n  10315,\n  1198,\n  1149,\n  8240,\n  6,\n  6,\n  6,\n  5432,\n  1911,\n  586,\n  488],\n 'mlm_labels': [-100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  33713,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100,\n  -100],\n 'mlm_tag_count': 1}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}